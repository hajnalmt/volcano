2025/09/04 11:50:56 maxprocs: Leaving GOMAXPROCS=12: CPU quota undefined
I0904 11:50:56.218462       1 flags.go:57] FLAG: --add-dir-header="false"
I0904 11:50:56.218554       1 flags.go:57] FLAG: --alsologtostderr="false"
I0904 11:50:56.218557       1 flags.go:57] FLAG: --ca-cert-file=""
I0904 11:50:56.218565       1 flags.go:57] FLAG: --cache-dump-dir="/tmp"
I0904 11:50:56.218567       1 flags.go:57] FLAG: --cache-dumper="true"
I0904 11:50:56.218571       1 flags.go:57] FLAG: --csi-storage="false"
I0904 11:50:56.218572       1 flags.go:57] FLAG: --default-queue="default"
I0904 11:50:56.218628       1 flags.go:57] FLAG: --enable-healthz="true"
I0904 11:50:56.218632       1 flags.go:57] FLAG: --enable-metrics="true"
I0904 11:50:56.218633       1 flags.go:57] FLAG: --enable-pprof="false"
I0904 11:50:56.218636       1 flags.go:57] FLAG: --feature-gates=""
I0904 11:50:56.218658       1 flags.go:57] FLAG: --healthz-address=":11251"
I0904 11:50:56.218659       1 flags.go:57] FLAG: --ignored-provisioners="[]"
I0904 11:50:56.218664       1 flags.go:57] FLAG: --kube-api-burst="2000"
I0904 11:50:56.218669       1 flags.go:57] FLAG: --kube-api-qps="2000"
I0904 11:50:56.218674       1 flags.go:57] FLAG: --kubeconfig=""
I0904 11:50:56.218674       1 flags.go:57] FLAG: --leader-elect="false"
I0904 11:50:56.218675       1 flags.go:57] FLAG: --leader-elect-lease-duration="15s"
I0904 11:50:56.218679       1 flags.go:57] FLAG: --leader-elect-renew-deadline="10s"
I0904 11:50:56.218680       1 flags.go:57] FLAG: --leader-elect-resource-lock="leases"
I0904 11:50:56.218682       1 flags.go:57] FLAG: --leader-elect-resource-name="volcano"
I0904 11:50:56.218683       1 flags.go:57] FLAG: --leader-elect-resource-namespace="volcano-system"
I0904 11:50:56.218685       1 flags.go:57] FLAG: --leader-elect-retry-period="2s"
I0904 11:50:56.218686       1 flags.go:57] FLAG: --listen-address=":8080"
I0904 11:50:56.218687       1 flags.go:57] FLAG: --lock-object-namespace=""
I0904 11:50:56.218688       1 flags.go:57] FLAG: --log-backtrace-at=":0"
I0904 11:50:56.218694       1 flags.go:57] FLAG: --log-dir=""
I0904 11:50:56.218699       1 flags.go:57] FLAG: --log-file=""
I0904 11:50:56.218700       1 flags.go:57] FLAG: --log-file-max-size="1800"
I0904 11:50:56.218701       1 flags.go:57] FLAG: --log-flush-frequency="5s"
I0904 11:50:56.218702       1 flags.go:57] FLAG: --logtostderr="true"
I0904 11:50:56.218703       1 flags.go:57] FLAG: --master=""
I0904 11:50:56.218704       1 flags.go:57] FLAG: --minimum-feasible-nodes="100"
I0904 11:50:56.218713       1 flags.go:57] FLAG: --minimum-percentage-nodes-to-find="5"
I0904 11:50:56.218714       1 flags.go:57] FLAG: --node-selector="[]"
I0904 11:50:56.218793       1 flags.go:57] FLAG: --node-worker-threads="20"
I0904 11:50:56.218796       1 flags.go:57] FLAG: --one-output="false"
I0904 11:50:56.218797       1 flags.go:57] FLAG: --percentage-nodes-to-find="0"
I0904 11:50:56.218798       1 flags.go:57] FLAG: --plugins-dir=""
I0904 11:50:56.218799       1 flags.go:57] FLAG: --priority-class="true"
I0904 11:50:56.218803       1 flags.go:57] FLAG: --resync-period="0s"
I0904 11:50:56.218805       1 flags.go:57] FLAG: --schedule-period="10s"
I0904 11:50:56.218806       1 flags.go:57] FLAG: --scheduler-conf="/volcano.scheduler/volcano-scheduler-ci.conf"
I0904 11:50:56.218807       1 flags.go:57] FLAG: --scheduler-name="[volcano]"
I0904 11:50:56.218841       1 flags.go:57] FLAG: --skip-headers="false"
I0904 11:50:56.218843       1 flags.go:57] FLAG: --skip-log-headers="false"
I0904 11:50:56.218844       1 flags.go:57] FLAG: --stderrthreshold="2"
I0904 11:50:56.218845       1 flags.go:57] FLAG: --tls-cert-file=""
I0904 11:50:56.218846       1 flags.go:57] FLAG: --tls-private-key-file=""
I0904 11:50:56.218847       1 flags.go:57] FLAG: --v="5"
I0904 11:50:56.218848       1 flags.go:57] FLAG: --version="false"
I0904 11:50:56.218849       1 flags.go:57] FLAG: --vmodule=""
W0904 11:50:56.218988       1 client_config.go:667] Neither --kubeconfig nor --master was specified.  Using the inClusterConfig.  This might not work.
I0904 11:50:56.224318       1 cache.go:508] Creating default queue and root queue
I0904 11:51:27.316803       1 cache.go:558] no registered bind method, new a default one
I0904 11:51:27.348974       1 healthz.go:191] No default health checks specified. Installing the ping handler.
I0904 11:51:27.349014       1 healthz.go:195] Installing health checkers for (/healthz): "ping"
I0904 11:51:27.350075       1 scheduler.go:136] Start loadSchedulerConf ...
I0904 11:51:27.351022       1 scheduler.go:139] Successfully loaded Scheduler conf, actions: [allocate backfill reclaim preempt], plugins: [priority gang conformance sla overcommit drf predicates capacity nodeorder binpack network-topology-aware]
I0904 11:51:27.351545       1 reflector.go:357] "Starting reflector" type="*v1.PersistentVolumeClaim" resyncPeriod="0s" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.351606       1 reflector.go:403] "Listing and watching" type="*v1.PersistentVolumeClaim" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.351647       1 reflector.go:357] "Starting reflector" type="*v1.ReplicationController" resyncPeriod="0s" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.351655       1 reflector.go:403] "Listing and watching" type="*v1.ReplicationController" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.351682       1 reflector.go:357] "Starting reflector" type="*v1.StatefulSet" resyncPeriod="0s" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.351701       1 reflector.go:403] "Listing and watching" type="*v1.StatefulSet" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.351748       1 reflector.go:357] "Starting reflector" type="*v1beta1.Queue" resyncPeriod="0s" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145"
I0904 11:51:27.351767       1 reflector.go:403] "Listing and watching" type="*v1beta1.Queue" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145"
I0904 11:51:27.351897       1 reflector.go:357] "Starting reflector" type="*v1.Namespace" resyncPeriod="0s" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.351911       1 reflector.go:403] "Listing and watching" type="*v1.Namespace" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.351935       1 reflector.go:357] "Starting reflector" type="*v1.Pod" resyncPeriod="0s" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.351941       1 reflector.go:403] "Listing and watching" type="*v1.Pod" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.353531       1 reflector.go:357] "Starting reflector" type="*v1.StorageClass" resyncPeriod="0s" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.353627       1 reflector.go:403] "Listing and watching" type="*v1.StorageClass" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.353700       1 reflector.go:357] "Starting reflector" type="*v1.PodDisruptionBudget" resyncPeriod="0s" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.353718       1 reflector.go:403] "Listing and watching" type="*v1.PodDisruptionBudget" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.354417       1 reflector.go:357] "Starting reflector" type="*v1alpha1.Numatopology" resyncPeriod="0s" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145"
I0904 11:51:27.354447       1 reflector.go:403] "Listing and watching" type="*v1alpha1.Numatopology" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145"
I0904 11:51:27.354857       1 reflector.go:357] "Starting reflector" type="*v1.CSINode" resyncPeriod="0s" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.354865       1 reflector.go:403] "Listing and watching" type="*v1.CSINode" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.351557       1 reflector.go:357] "Starting reflector" type="*v1.Node" resyncPeriod="0s" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.354992       1 reflector.go:357] "Starting reflector" type="*v1.PersistentVolume" resyncPeriod="0s" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.355008       1 reflector.go:403] "Listing and watching" type="*v1.PersistentVolume" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.355007       1 reflector.go:403] "Listing and watching" type="*v1.Node" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.353575       1 reflector.go:357] "Starting reflector" type="*v1beta1.PodGroup" resyncPeriod="0s" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145"
I0904 11:51:27.355278       1 reflector.go:403] "Listing and watching" type="*v1beta1.PodGroup" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145"
I0904 11:51:27.355946       1 reflector.go:357] "Starting reflector" type="*v1.Service" resyncPeriod="0s" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.355990       1 reflector.go:403] "Listing and watching" type="*v1.Service" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.356033       1 reflector.go:357] "Starting reflector" type="*v1.PriorityClass" resyncPeriod="0s" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.356039       1 reflector.go:403] "Listing and watching" type="*v1.PriorityClass" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.360380       1 reflector.go:357] "Starting reflector" type="*v1.ResourceQuota" resyncPeriod="0s" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.360431       1 reflector.go:403] "Listing and watching" type="*v1.ResourceQuota" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.360444       1 reflector.go:357] "Starting reflector" type="*v1.ReplicaSet" resyncPeriod="0s" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.360459       1 reflector.go:403] "Listing and watching" type="*v1.ReplicaSet" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.360505       1 reflector.go:357] "Starting reflector" type="*v1alpha1.HyperNode" resyncPeriod="0s" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145"
I0904 11:51:27.360516       1 reflector.go:403] "Listing and watching" type="*v1alpha1.HyperNode" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145"
I0904 11:51:27.362718       1 reflector.go:430] "Caches populated" type="*v1.CSINode" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.362778       1 reflector.go:430] "Caches populated" type="*v1.StorageClass" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.363543       1 reflector.go:430] "Caches populated" type="*v1.Namespace" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.364287       1 reflector.go:430] "Caches populated" type="*v1.PriorityClass" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.364545       1 reflector.go:430] "Caches populated" type="*v1.PersistentVolumeClaim" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.364561       1 reflector.go:430] "Caches populated" type="*v1.ResourceQuota" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.364693       1 reflector.go:430] "Caches populated" type="*v1.PodDisruptionBudget" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.367598       1 reflector.go:430] "Caches populated" type="*v1.ReplicationController" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.367827       1 reflector.go:430] "Caches populated" type="*v1.Node" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.368013       1 reflector.go:430] "Caches populated" type="*v1.Service" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.368453       1 reflector.go:430] "Caches populated" type="*v1alpha1.Numatopology" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145"
I0904 11:51:27.368476       1 reflector.go:430] "Caches populated" type="*v1.PersistentVolume" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.368687       1 reflector.go:430] "Caches populated" type="*v1beta1.PodGroup" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145"
I0904 11:51:27.368941       1 util.go:101] schedulerPodName  is responsible to PodGroup qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6
I0904 11:51:27.369448       1 event_handlers.go:835] Add PodGroup(podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6) into cache, spec(v1beta1.PodGroupSpec{MinMember:1, MinTaskMember:map[string]int32(nil), Queue:"q1", PriorityClassName:"", MinResources:(*v1.ResourceList)(0xc00012e3b8), NetworkTopology:(*v1beta1.NetworkTopologySpec)(nil)})
I0904 11:51:27.369534       1 reflector.go:430] "Caches populated" type="*v1alpha1.HyperNode" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145"
I0904 11:51:27.370232       1 reflector.go:430] "Caches populated" type="*v1beta1.Queue" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145"
I0904 11:51:27.372802       1 event_handlers.go:928] Add Queue(default) into cache, spec(v1beta1.QueueSpec{Weight:1, Capability:v1.ResourceList(nil), Reclaimable:(*bool)(0xc0008a4960), ExtendClusters:[]v1beta1.Cluster(nil), Guarantee:v1beta1.Guarantee{Resource:v1.ResourceList(nil)}, Affinity:(*v1beta1.Affinity)(nil), Type:"", Parent:"root", Deserved:v1.ResourceList(nil), Priority:0})
I0904 11:51:27.373049       1 event_handlers.go:928] Add Queue(parent-a) into cache, spec(v1beta1.QueueSpec{Weight:1, Capability:v1.ResourceList(nil), Reclaimable:(*bool)(0xc0008a4a3c), ExtendClusters:[]v1beta1.Cluster(nil), Guarantee:v1beta1.Guarantee{Resource:v1.ResourceList(nil)}, Affinity:(*v1beta1.Affinity)(nil), Type:"", Parent:"root", Deserved:v1.ResourceList{"nvidia.com/A100":resource.Quantity{i:resource.int64Amount{value:9, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"9", Format:"DecimalSI"}}, Priority:0})
I0904 11:51:27.373190       1 event_handlers.go:928] Add Queue(q1) into cache, spec(v1beta1.QueueSpec{Weight:1, Capability:v1.ResourceList(nil), Reclaimable:(*bool)(0xc0008a4b60), ExtendClusters:[]v1beta1.Cluster(nil), Guarantee:v1beta1.Guarantee{Resource:v1.ResourceList(nil)}, Affinity:(*v1beta1.Affinity)(nil), Type:"", Parent:"parent-a", Deserved:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:4, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"4", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:4294967296, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"4Gi", Format:"BinarySI"}, "nvidia.com/A100":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}}, Priority:0})
I0904 11:51:27.373237       1 event_handlers.go:928] Add Queue(q2) into cache, spec(v1beta1.QueueSpec{Weight:1, Capability:v1.ResourceList(nil), Reclaimable:(*bool)(0xc0008a4c60), ExtendClusters:[]v1beta1.Cluster(nil), Guarantee:v1beta1.Guarantee{Resource:v1.ResourceList(nil)}, Affinity:(*v1beta1.Affinity)(nil), Type:"", Parent:"parent-a", Deserved:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:4, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"4", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:4294967296, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"4Gi", Format:"BinarySI"}, "nvidia.com/A100":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}}, Priority:0})
I0904 11:51:27.373276       1 event_handlers.go:928] Add Queue(root) into cache, spec(v1beta1.QueueSpec{Weight:1, Capability:v1.ResourceList(nil), Reclaimable:(*bool)(0xc0008a4d30), ExtendClusters:[]v1beta1.Cluster(nil), Guarantee:v1beta1.Guarantee{Resource:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}, Affinity:(*v1beta1.Affinity)(nil), Type:"", Parent:"", Deserved:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}, Priority:0})
I0904 11:51:27.374229       1 reflector.go:430] "Caches populated" type="*v1.StatefulSet" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.375841       1 reflector.go:430] "Caches populated" type="*v1.ReplicaSet" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.376546       1 reflector.go:430] "Caches populated" type="*v1.Pod" reflector="k8s.io/client-go/informers/factory.go:160"
I0904 11:51:27.376697       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
W0904 11:51:27.377324       1 node_info.go:346] received argument of nil node, no need to set other resources for 
W0904 11:51:27.377344       1 node_info.go:241] the argument node is null.
I0904 11:51:27.377360       1 event_handlers.go:71] Pod kube-system/coredns-674b8bbfcf-k2tdr will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377386       1 event_handlers.go:398] Added pod <kube-system/coredns-674b8bbfcf-k2tdr> into cache.
I0904 11:51:27.377401       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:51:27.377406       1 event_handlers.go:71] Pod kube-system/coredns-674b8bbfcf-lpf8m will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377409       1 event_handlers.go:398] Added pod <kube-system/coredns-674b8bbfcf-lpf8m> into cache.
I0904 11:51:27.377413       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:51:27.377417       1 event_handlers.go:71] Pod kube-system/etcd-integration-control-plane will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377420       1 event_handlers.go:398] Added pod <kube-system/etcd-integration-control-plane> into cache.
I0904 11:51:27.377422       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-0
W0904 11:51:27.377425       1 node_info.go:346] received argument of nil node, no need to set other resources for 
W0904 11:51:27.377426       1 node_info.go:241] the argument node is null.
I0904 11:51:27.377429       1 event_handlers.go:71] Pod kube-system/kindnet-5hnqk will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377431       1 event_handlers.go:398] Added pod <kube-system/kindnet-5hnqk> into cache.
I0904 11:51:27.377434       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-a100-mate-0
W0904 11:51:27.377436       1 node_info.go:346] received argument of nil node, no need to set other resources for 
W0904 11:51:27.377438       1 node_info.go:241] the argument node is null.
I0904 11:51:27.377440       1 event_handlers.go:71] Pod kube-system/kindnet-9vg9h will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377442       1 event_handlers.go:398] Added pod <kube-system/kindnet-9vg9h> into cache.
I0904 11:51:27.377444       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-2
W0904 11:51:27.377446       1 node_info.go:346] received argument of nil node, no need to set other resources for 
W0904 11:51:27.377447       1 node_info.go:241] the argument node is null.
I0904 11:51:27.377450       1 event_handlers.go:71] Pod kube-system/kindnet-lpbc4 will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377452       1 event_handlers.go:398] Added pod <kube-system/kindnet-lpbc4> into cache.
I0904 11:51:27.377454       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:51:27.377458       1 event_handlers.go:71] Pod kube-system/kindnet-ntjvr will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377460       1 event_handlers.go:398] Added pod <kube-system/kindnet-ntjvr> into cache.
I0904 11:51:27.377470       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-1
W0904 11:51:27.377474       1 node_info.go:346] received argument of nil node, no need to set other resources for 
W0904 11:51:27.377475       1 node_info.go:241] the argument node is null.
I0904 11:51:27.377479       1 event_handlers.go:71] Pod kube-system/kindnet-wr98b will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377481       1 event_handlers.go:398] Added pod <kube-system/kindnet-wr98b> into cache.
I0904 11:51:27.377483       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:51:27.377487       1 event_handlers.go:71] Pod kube-system/kube-apiserver-integration-control-plane will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377489       1 event_handlers.go:398] Added pod <kube-system/kube-apiserver-integration-control-plane> into cache.
I0904 11:51:27.377491       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:51:27.377494       1 event_handlers.go:71] Pod kube-system/kube-controller-manager-integration-control-plane will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377496       1 event_handlers.go:398] Added pod <kube-system/kube-controller-manager-integration-control-plane> into cache.
I0904 11:51:27.377498       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:51:27.377502       1 event_handlers.go:71] Pod kube-system/kube-proxy-4fg7x will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377504       1 event_handlers.go:398] Added pod <kube-system/kube-proxy-4fg7x> into cache.
I0904 11:51:27.377505       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-a100-mate-0
I0904 11:51:27.377508       1 event_handlers.go:71] Pod kube-system/kube-proxy-5v27l will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377510       1 event_handlers.go:398] Added pod <kube-system/kube-proxy-5v27l> into cache.
I0904 11:51:27.377512       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-2
I0904 11:51:27.377516       1 event_handlers.go:71] Pod kube-system/kube-proxy-nsh6t will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377518       1 event_handlers.go:398] Added pod <kube-system/kube-proxy-nsh6t> into cache.
I0904 11:51:27.377519       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-1
I0904 11:51:27.377522       1 event_handlers.go:71] Pod kube-system/kube-proxy-tr26s will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377524       1 event_handlers.go:398] Added pod <kube-system/kube-proxy-tr26s> into cache.
I0904 11:51:27.377526       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-0
I0904 11:51:27.377529       1 event_handlers.go:71] Pod kube-system/kube-proxy-wzql4 will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377531       1 event_handlers.go:398] Added pod <kube-system/kube-proxy-wzql4> into cache.
I0904 11:51:27.377533       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:51:27.377536       1 event_handlers.go:71] Pod kube-system/kube-scheduler-integration-control-plane will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377538       1 event_handlers.go:398] Added pod <kube-system/kube-scheduler-integration-control-plane> into cache.
I0904 11:51:27.377541       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:51:27.377545       1 event_handlers.go:71] Pod kube-system/kwok-controller-c988d7986-x9n82 will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377549       1 event_handlers.go:398] Added pod <kube-system/kwok-controller-c988d7986-x9n82> into cache.
I0904 11:51:27.377550       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:51:27.377554       1 event_handlers.go:71] Pod local-path-storage/local-path-provisioner-7dc846544d-kbltj will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377558       1 event_handlers.go:398] Added pod <local-path-storage/local-path-provisioner-7dc846544d-kbltj> into cache.
I0904 11:51:27.377560       1 util.go:63] schedulerPodName  is responsible to Pod qkzxnakm/q1-twsxj
I0904 11:51:27.377581       1 event_handlers.go:398] Added pod <qkzxnakm/q1-twsxj> into cache.
I0904 11:51:27.377592       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:51:27.377596       1 event_handlers.go:71] Pod volcano-monitoring/grafana-5f588b4ffd-k9fb2 will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377598       1 event_handlers.go:398] Added pod <volcano-monitoring/grafana-5f588b4ffd-k9fb2> into cache.
I0904 11:51:27.377600       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:51:27.377603       1 event_handlers.go:71] Pod volcano-monitoring/kube-state-metrics-5b659f7c5-94dff will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377605       1 event_handlers.go:398] Added pod <volcano-monitoring/kube-state-metrics-5b659f7c5-94dff> into cache.
I0904 11:51:27.377607       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:51:27.377610       1 event_handlers.go:71] Pod volcano-monitoring/prometheus-deployment-84957786d-kpf8n will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377612       1 event_handlers.go:398] Added pod <volcano-monitoring/prometheus-deployment-84957786d-kpf8n> into cache.
I0904 11:51:27.377614       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:51:27.377618       1 event_handlers.go:71] Pod volcano-system/integration-admission-78bfb84969-cz7xr will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377620       1 event_handlers.go:398] Added pod <volcano-system/integration-admission-78bfb84969-cz7xr> into cache.
I0904 11:51:27.377624       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:51:27.377630       1 event_handlers.go:71] Pod volcano-system/integration-controllers-64fdf8ff8c-8cgs9 will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377633       1 event_handlers.go:398] Added pod <volcano-system/integration-controllers-64fdf8ff8c-8cgs9> into cache.
I0904 11:51:27.377636       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:51:27.377640       1 event_handlers.go:71] Pod volcano-system/integration-scheduler-6ddf9959f9-52g5q will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 11:51:27.377643       1 event_handlers.go:398] Added pod <volcano-system/integration-scheduler-6ddf9959f9-52g5q> into cache.
I0904 11:51:27.461656       1 cache.go:808] Start metrics collection, metricsConf is map[]
I0904 11:51:27.461685       1 cache.go:813] The interval for querying metrics data is 30s
I0904 11:51:27.461694       1 scheduler.go:95] Scheduler completes Initialization and start to run
I0904 11:51:27.461705       1 cache.go:1179] started sync node integration-control-plane
I0904 11:51:27.461730       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:51:27.461760       1 cache.go:1179] started sync node kwok-node-0
I0904 11:51:27.461769       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-0
W0904 11:51:27.461782       1 node_info.go:346] received argument of nil node, no need to set other resources for 
W0904 11:51:27.461787       1 node_info.go:241] the argument node is null.
I0904 11:51:27.461790       1 cache.go:1179] started sync node kwok-node-1
I0904 11:51:27.461792       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-1
I0904 11:51:27.461818       1 cache.go:1179] started sync node kwok-node-2
I0904 11:51:27.461821       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-2
I0904 11:51:27.461827       1 cache.go:1179] started sync node kwok-node-a100-mate-0
I0904 11:51:27.461829       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-a100-mate-0
I0904 11:51:27.461829       1 node_info.go:227] imageStates is map[]
I0904 11:51:27.461899       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:51:27.461924       1 cache.go:1199] started sync hyperNode node/integration-control-plane
I0904 11:51:27.461925       1 scheduler.go:106] Start scheduling ...
W0904 11:51:27.462165       1 node_info.go:346] received argument of nil node, no need to set other resources for 
W0904 11:51:27.462181       1 node_info.go:241] the argument node is null.
I0904 11:51:27.462189       1 node_info.go:227] imageStates is map[]
I0904 11:51:27.462187       1 event_handlers.go:734] "No need to update hyperNode cache when node added or deleted"
I0904 11:51:27.462207       1 cache.go:1199] started sync hyperNode node/kwok-node-0
I0904 11:51:27.462214       1 event_handlers.go:734] "No need to update hyperNode cache when node added or deleted"
I0904 11:51:27.462217       1 cache.go:1199] started sync hyperNode node/kwok-node-1
I0904 11:51:27.462221       1 event_handlers.go:734] "No need to update hyperNode cache when node added or deleted"
I0904 11:51:27.462224       1 cache.go:1199] started sync hyperNode node/kwok-node-2
I0904 11:51:27.462227       1 event_handlers.go:734] "No need to update hyperNode cache when node added or deleted"
W0904 11:51:27.462227       1 node_info.go:346] received argument of nil node, no need to set other resources for 
I0904 11:51:27.462230       1 cache.go:1199] started sync hyperNode node/kwok-node-a100-mate-0
W0904 11:51:27.462231       1 node_info.go:241] the argument node is null.
I0904 11:51:27.462233       1 event_handlers.go:734] "No need to update hyperNode cache when node added or deleted"
I0904 11:51:27.462237       1 node_info.go:227] imageStates is map[]
W0904 11:51:27.462257       1 node_info.go:346] received argument of nil node, no need to set other resources for 
W0904 11:51:27.462258       1 node_info.go:241] the argument node is null.
I0904 11:51:27.462265       1 node_info.go:227] imageStates is map[]
W0904 11:51:27.462283       1 node_info.go:346] received argument of nil node, no need to set other resources for 
W0904 11:51:27.462295       1 node_info.go:241] the argument node is null.
I0904 11:51:27.462299       1 node_info.go:227] imageStates is map[]
I0904 11:51:27.462362       1 node_info.go:227] imageStates is map[]
I0904 11:51:27.462395       1 node_info.go:227] imageStates is map[]
I0904 11:51:27.462403       1 node_info.go:227] imageStates is map[]
I0904 11:51:27.462412       1 node_info.go:227] imageStates is map[]
I0904 11:51:27.462420       1 node_info.go:227] imageStates is map[]
I0904 11:51:27.462438       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:51:27.462472       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:51:27.462514       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:51:27.462530       1 session.go:230] Open Session bfb523ab-f1f3-497b-878e-435876935bca with <1> Job and <5> Queues
I0904 11:51:27.462547       1 session.go:233] Session bfb523ab-f1f3-497b-878e-435876935bca operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:51:27.462690       1 sla.go:85] Enter sla plugin ...
I0904 11:51:27.462706       1 sla.go:154] Leaving sla plugin.
I0904 11:51:27.462717       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:51:27.462728       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:51:27.462739       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00
I0904 11:51:27.463141       1 factory.go:59] Register preBinder predicates successfully
I0904 11:51:27.463170       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 11:51:27.463199       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:51:27.463216       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:51:27.463232       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:51:27.463264       1 binpack.go:165] Enter binpack plugin ...
I0904 11:51:27.463267       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:51:27.463271       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:51:27.463279       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:51:27.463282       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:51:27.463290       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:27.463310       1 allocate.go:62] Enter Allocate ...
I0904 11:51:27.463312       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:27.463317       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:51:27.463320       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:51:27.463987       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:51:27.464009       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:51:27.464012       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:51:27.464015       1 allocate.go:83] Leaving Allocate ...
I0904 11:51:27.464024       1 backfill.go:59] Enter Backfill ...
I0904 11:51:27.464030       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:27.464037       1 backfill.go:110] Leaving Backfill ...
I0904 11:51:27.464046       1 reclaim.go:47] Enter Reclaim ...
I0904 11:51:27.464048       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:51:27.464051       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:27.464057       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:51:27.464062       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:51:27.464065       1 preempt.go:103] Enter Preempt ...
I0904 11:51:27.464067       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:27.464071       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:51:27.464077       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:51:27.464079       1 preempt.go:270] Leaving Preempt ...
I0904 11:51:27.464265       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:51:27.464290       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:51:27.464395       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:51:27.464401       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:51:27.464406       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:51:27.464410       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:51:27.464417       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:51:27.464421       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:51:27.464428       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:51:27.464435       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:51:27.464440       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:51:27.464451       1 session.go:361] Session bfb523ab-f1f3-497b-878e-435876935bca operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:51:27.464455       1 session.go:375] Close Session bfb523ab-f1f3-497b-878e-435876935bca
I0904 11:51:27.464460       1 scheduler.go:133] End scheduling ...
I0904 11:51:37.464930       1 scheduler.go:106] Start scheduling ...
I0904 11:51:37.465036       1 node_info.go:227] imageStates is map[]
I0904 11:51:37.465111       1 node_info.go:227] imageStates is map[]
I0904 11:51:37.465124       1 node_info.go:227] imageStates is map[]
I0904 11:51:37.465136       1 node_info.go:227] imageStates is map[]
I0904 11:51:37.465144       1 node_info.go:227] imageStates is map[]
I0904 11:51:37.465184       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:51:37.465222       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:51:37.465234       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:51:37.465252       1 session.go:230] Open Session da66bb5e-4a4f-4e95-a017-24ea481c4078 with <1> Job and <5> Queues
I0904 11:51:37.465274       1 session.go:233] Session da66bb5e-4a4f-4e95-a017-24ea481c4078 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:51:37.465431       1 sla.go:85] Enter sla plugin ...
I0904 11:51:37.465447       1 sla.go:154] Leaving sla plugin.
I0904 11:51:37.465452       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:51:37.465464       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:51:37.465469       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 11:51:37.465524       1 factory.go:59] Register preBinder predicates successfully
I0904 11:51:37.465530       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 11:51:37.465547       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:51:37.465563       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:51:37.465579       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:51:37.465612       1 binpack.go:165] Enter binpack plugin ...
I0904 11:51:37.465615       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:51:37.465620       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:51:37.465624       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:51:37.465627       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:51:37.465632       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:37.465645       1 allocate.go:62] Enter Allocate ...
I0904 11:51:37.465648       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:37.465653       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:51:37.465656       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:51:37.465659       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:51:37.465661       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:51:37.465663       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:51:37.465666       1 allocate.go:83] Leaving Allocate ...
I0904 11:51:37.465669       1 backfill.go:59] Enter Backfill ...
I0904 11:51:37.465672       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:37.465675       1 backfill.go:110] Leaving Backfill ...
I0904 11:51:37.465679       1 reclaim.go:47] Enter Reclaim ...
I0904 11:51:37.465681       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:51:37.465684       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:37.465687       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:51:37.465692       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:51:37.465696       1 preempt.go:103] Enter Preempt ...
I0904 11:51:37.465698       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:37.465702       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:51:37.465707       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:51:37.465710       1 preempt.go:270] Leaving Preempt ...
I0904 11:51:37.465791       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:51:37.465814       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:51:37.465819       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:51:37.465824       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:51:37.465827       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:51:37.465834       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:51:37.465857       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:51:37.465859       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:51:37.465863       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:51:37.465867       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:51:37.465873       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:51:37.465881       1 session.go:361] Session da66bb5e-4a4f-4e95-a017-24ea481c4078 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:51:37.465884       1 session.go:375] Close Session da66bb5e-4a4f-4e95-a017-24ea481c4078
I0904 11:51:37.465888       1 scheduler.go:133] End scheduling ...
I0904 11:51:47.466355       1 scheduler.go:106] Start scheduling ...
I0904 11:51:47.466700       1 node_info.go:227] imageStates is map[]
I0904 11:51:47.466876       1 node_info.go:227] imageStates is map[]
I0904 11:51:47.466906       1 node_info.go:227] imageStates is map[]
I0904 11:51:47.466938       1 node_info.go:227] imageStates is map[]
I0904 11:51:47.466962       1 node_info.go:227] imageStates is map[]
I0904 11:51:47.467018       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:51:47.467116       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:51:47.467189       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:51:47.467213       1 session.go:230] Open Session f5b7b145-2398-4405-a8ff-9e06e225e499 with <1> Job and <5> Queues
I0904 11:51:47.467242       1 session.go:233] Session f5b7b145-2398-4405-a8ff-9e06e225e499 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:51:47.467537       1 sla.go:85] Enter sla plugin ...
I0904 11:51:47.467561       1 sla.go:154] Leaving sla plugin.
I0904 11:51:47.467572       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:51:47.467601       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:51:47.467615       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 11:51:47.467849       1 factory.go:59] Register preBinder predicates successfully
I0904 11:51:47.467923       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>
I0904 11:51:47.467976       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:51:47.468026       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:51:47.468073       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:51:47.468114       1 binpack.go:165] Enter binpack plugin ...
I0904 11:51:47.468123       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:51:47.468133       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:51:47.468143       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:51:47.468148       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:51:47.468161       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:47.468177       1 allocate.go:62] Enter Allocate ...
I0904 11:51:47.468183       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:47.468195       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:51:47.468202       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:51:47.468210       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:51:47.468217       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:51:47.468224       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:51:47.468231       1 allocate.go:83] Leaving Allocate ...
I0904 11:51:47.468240       1 backfill.go:59] Enter Backfill ...
I0904 11:51:47.468248       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:47.468259       1 backfill.go:110] Leaving Backfill ...
I0904 11:51:47.468266       1 reclaim.go:47] Enter Reclaim ...
I0904 11:51:47.468273       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:51:47.468280       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:47.468290       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:51:47.468304       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:51:47.468311       1 preempt.go:103] Enter Preempt ...
I0904 11:51:47.468317       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:47.468327       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:51:47.468338       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:51:47.468355       1 preempt.go:270] Leaving Preempt ...
I0904 11:51:47.468552       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:51:47.468610       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:51:47.468622       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:51:47.468640       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:51:47.468655       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:51:47.468675       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:51:47.468687       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:51:47.468700       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:51:47.468708       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:51:47.468723       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:51:47.468762       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:51:47.468784       1 session.go:361] Session f5b7b145-2398-4405-a8ff-9e06e225e499 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:51:47.468793       1 session.go:375] Close Session f5b7b145-2398-4405-a8ff-9e06e225e499
I0904 11:51:47.468803       1 scheduler.go:133] End scheduling ...
I0904 11:51:57.462442       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:51:57.469576       1 scheduler.go:106] Start scheduling ...
I0904 11:51:57.469742       1 node_info.go:227] imageStates is map[]
I0904 11:51:57.469797       1 node_info.go:227] imageStates is map[]
I0904 11:51:57.469830       1 node_info.go:227] imageStates is map[]
I0904 11:51:57.469915       1 node_info.go:227] imageStates is map[]
I0904 11:51:57.469986       1 node_info.go:227] imageStates is map[]
I0904 11:51:57.470036       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:51:57.470179       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:51:57.470211       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:51:57.470235       1 session.go:230] Open Session 8c3eeb91-783d-44c0-9e75-c94d4b75b45d with <1> Job and <5> Queues
I0904 11:51:57.470267       1 session.go:233] Session 8c3eeb91-783d-44c0-9e75-c94d4b75b45d operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:51:57.470871       1 sla.go:85] Enter sla plugin ...
I0904 11:51:57.470923       1 sla.go:154] Leaving sla plugin.
I0904 11:51:57.470934       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:51:57.470964       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:51:57.470977       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 11:51:57.471087       1 factory.go:59] Register preBinder predicates successfully
I0904 11:51:57.471136       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 11:51:57.471184       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:51:57.471231       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:51:57.471308       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:51:57.471352       1 binpack.go:165] Enter binpack plugin ...
I0904 11:51:57.471393       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:51:57.471404       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:51:57.471415       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:51:57.471421       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:51:57.471435       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:57.471454       1 allocate.go:62] Enter Allocate ...
I0904 11:51:57.471461       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:57.471474       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:51:57.471482       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:51:57.471492       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:51:57.471498       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:51:57.471505       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:51:57.471511       1 allocate.go:83] Leaving Allocate ...
I0904 11:51:57.471519       1 backfill.go:59] Enter Backfill ...
I0904 11:51:57.471526       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:57.471537       1 backfill.go:110] Leaving Backfill ...
I0904 11:51:57.471544       1 reclaim.go:47] Enter Reclaim ...
I0904 11:51:57.471551       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:51:57.471559       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:57.471571       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:51:57.471585       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:51:57.471601       1 preempt.go:103] Enter Preempt ...
I0904 11:51:57.471607       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:51:57.471618       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:51:57.471633       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:51:57.471641       1 preempt.go:270] Leaving Preempt ...
I0904 11:51:57.471823       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:51:57.471903       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:51:57.471918       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:51:57.471933       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:51:57.471943       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:51:57.471961       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:51:57.472007       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:51:57.472015       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:51:57.472028       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:51:57.472039       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:51:57.472057       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:51:57.472081       1 session.go:361] Session 8c3eeb91-783d-44c0-9e75-c94d4b75b45d operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:51:57.472091       1 session.go:375] Close Session 8c3eeb91-783d-44c0-9e75-c94d4b75b45d
I0904 11:51:57.472105       1 scheduler.go:133] End scheduling ...
I0904 11:52:07.473119       1 scheduler.go:106] Start scheduling ...
I0904 11:52:07.473224       1 node_info.go:227] imageStates is map[]
I0904 11:52:07.473258       1 node_info.go:227] imageStates is map[]
I0904 11:52:07.473271       1 node_info.go:227] imageStates is map[]
I0904 11:52:07.473308       1 node_info.go:227] imageStates is map[]
I0904 11:52:07.473326       1 node_info.go:227] imageStates is map[]
I0904 11:52:07.473354       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:52:07.473387       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:52:07.473411       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:52:07.473424       1 session.go:230] Open Session e40f1732-b83d-44ae-a3d0-10536b41168d with <1> Job and <5> Queues
I0904 11:52:07.473470       1 session.go:233] Session e40f1732-b83d-44ae-a3d0-10536b41168d operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:52:07.473619       1 sla.go:85] Enter sla plugin ...
I0904 11:52:07.473639       1 sla.go:154] Leaving sla plugin.
I0904 11:52:07.473645       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:52:07.473660       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:52:07.473666       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 11:52:07.473719       1 factory.go:59] Register preBinder predicates successfully
I0904 11:52:07.473738       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 11:52:07.473762       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:52:07.473781       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:52:07.473801       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:52:07.473824       1 binpack.go:165] Enter binpack plugin ...
I0904 11:52:07.473828       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:52:07.473833       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:52:07.473838       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:52:07.473842       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:52:07.473849       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:07.473863       1 allocate.go:62] Enter Allocate ...
I0904 11:52:07.473866       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:07.473872       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:52:07.473876       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:52:07.473880       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:52:07.473882       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:52:07.473885       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:52:07.473888       1 allocate.go:83] Leaving Allocate ...
I0904 11:52:07.473892       1 backfill.go:59] Enter Backfill ...
I0904 11:52:07.473895       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:07.473900       1 backfill.go:110] Leaving Backfill ...
I0904 11:52:07.473904       1 reclaim.go:47] Enter Reclaim ...
I0904 11:52:07.473906       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:52:07.473909       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:07.473914       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:52:07.473920       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:52:07.473923       1 preempt.go:103] Enter Preempt ...
I0904 11:52:07.473926       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:07.473930       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:52:07.473934       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:52:07.473938       1 preempt.go:270] Leaving Preempt ...
I0904 11:52:07.473994       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:07.474009       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:52:07.474018       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:07.474026       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:52:07.474031       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:52:07.474037       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:52:07.474041       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:07.474047       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:52:07.474065       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:52:07.474068       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:52:07.474074       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:52:07.474082       1 session.go:361] Session e40f1732-b83d-44ae-a3d0-10536b41168d operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:52:07.474086       1 session.go:375] Close Session e40f1732-b83d-44ae-a3d0-10536b41168d
I0904 11:52:07.474091       1 scheduler.go:133] End scheduling ...
I0904 11:52:17.474754       1 scheduler.go:106] Start scheduling ...
I0904 11:52:17.474989       1 node_info.go:227] imageStates is map[]
I0904 11:52:17.475055       1 node_info.go:227] imageStates is map[]
I0904 11:52:17.475084       1 node_info.go:227] imageStates is map[]
I0904 11:52:17.475116       1 node_info.go:227] imageStates is map[]
I0904 11:52:17.475173       1 node_info.go:227] imageStates is map[]
I0904 11:52:17.475225       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:52:17.475276       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:52:17.475301       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:52:17.475323       1 session.go:230] Open Session f27dda5e-ec1f-476c-abfb-e0919e2d907e with <1> Job and <5> Queues
I0904 11:52:17.475350       1 session.go:233] Session f27dda5e-ec1f-476c-abfb-e0919e2d907e operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:52:17.475680       1 sla.go:85] Enter sla plugin ...
I0904 11:52:17.475719       1 sla.go:154] Leaving sla plugin.
I0904 11:52:17.475730       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:52:17.475757       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:52:17.475769       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00
I0904 11:52:17.475858       1 factory.go:59] Register preBinder predicates successfully
I0904 11:52:17.475869       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
I0904 11:52:17.475913       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:52:17.475955       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:52:17.475997       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:52:17.476045       1 binpack.go:165] Enter binpack plugin ...
I0904 11:52:17.476053       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:52:17.476062       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:52:17.476071       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:52:17.476076       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:52:17.476088       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:17.476105       1 allocate.go:62] Enter Allocate ...
I0904 11:52:17.476111       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:17.476125       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:52:17.476131       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:52:17.476138       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:52:17.476144       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:52:17.476149       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:52:17.476155       1 allocate.go:83] Leaving Allocate ...
I0904 11:52:17.476162       1 backfill.go:59] Enter Backfill ...
I0904 11:52:17.476168       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:17.476178       1 backfill.go:110] Leaving Backfill ...
I0904 11:52:17.476184       1 reclaim.go:47] Enter Reclaim ...
I0904 11:52:17.476189       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:52:17.476195       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:17.476204       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:52:17.476216       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:52:17.476221       1 preempt.go:103] Enter Preempt ...
I0904 11:52:17.476227       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:17.476235       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:52:17.476250       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:52:17.476257       1 preempt.go:270] Leaving Preempt ...
I0904 11:52:17.476388       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:52:17.476439       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:52:17.476450       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:17.476462       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:52:17.476498       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:52:17.476505       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:52:17.476516       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:52:17.476525       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:17.476539       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:52:17.476550       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:17.476565       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:52:17.476585       1 session.go:361] Session f27dda5e-ec1f-476c-abfb-e0919e2d907e operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:52:17.476607       1 session.go:375] Close Session f27dda5e-ec1f-476c-abfb-e0919e2d907e
I0904 11:52:17.476619       1 scheduler.go:133] End scheduling ...
I0904 11:52:27.463343       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:52:27.477555       1 scheduler.go:106] Start scheduling ...
I0904 11:52:27.477742       1 node_info.go:227] imageStates is map[]
I0904 11:52:27.477823       1 node_info.go:227] imageStates is map[]
I0904 11:52:27.477842       1 node_info.go:227] imageStates is map[]
I0904 11:52:27.477865       1 node_info.go:227] imageStates is map[]
I0904 11:52:27.477880       1 node_info.go:227] imageStates is map[]
I0904 11:52:27.477913       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:52:27.477971       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:52:27.477989       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:52:27.478005       1 session.go:230] Open Session b4a4e059-e342-4c7d-ac52-2d1cd3e87444 with <1> Job and <5> Queues
I0904 11:52:27.478066       1 session.go:233] Session b4a4e059-e342-4c7d-ac52-2d1cd3e87444 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:52:27.478301       1 sla.go:85] Enter sla plugin ...
I0904 11:52:27.478329       1 sla.go:154] Leaving sla plugin.
I0904 11:52:27.478336       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:52:27.478356       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:52:27.478364       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 11:52:27.478430       1 factory.go:59] Register preBinder predicates successfully
I0904 11:52:27.478439       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 11:52:27.478466       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:52:27.478495       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:52:27.478523       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:52:27.478552       1 binpack.go:165] Enter binpack plugin ...
I0904 11:52:27.478557       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:52:27.478566       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:52:27.478572       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:52:27.478576       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:52:27.478585       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:27.478595       1 allocate.go:62] Enter Allocate ...
I0904 11:52:27.478601       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:27.478609       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:52:27.478614       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:52:27.478619       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:52:27.478622       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:52:27.478626       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:52:27.478630       1 allocate.go:83] Leaving Allocate ...
I0904 11:52:27.478635       1 backfill.go:59] Enter Backfill ...
I0904 11:52:27.478639       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:27.478646       1 backfill.go:110] Leaving Backfill ...
I0904 11:52:27.478651       1 reclaim.go:47] Enter Reclaim ...
I0904 11:52:27.478655       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:52:27.478660       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:27.478667       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:52:27.478675       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:52:27.478680       1 preempt.go:103] Enter Preempt ...
I0904 11:52:27.478684       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:27.478691       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:52:27.478699       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:52:27.478704       1 preempt.go:270] Leaving Preempt ...
I0904 11:52:27.478820       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:52:27.478839       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:52:27.478845       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:27.478859       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:52:27.478867       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:27.478877       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:52:27.478885       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:52:27.478892       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:52:27.478898       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:27.478907       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:52:27.478932       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:52:27.478942       1 session.go:361] Session b4a4e059-e342-4c7d-ac52-2d1cd3e87444 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:52:27.478947       1 session.go:375] Close Session b4a4e059-e342-4c7d-ac52-2d1cd3e87444
I0904 11:52:27.478953       1 scheduler.go:133] End scheduling ...
I0904 11:52:37.479913       1 scheduler.go:106] Start scheduling ...
I0904 11:52:37.480153       1 node_info.go:227] imageStates is map[]
I0904 11:52:37.480192       1 node_info.go:227] imageStates is map[]
I0904 11:52:37.480265       1 node_info.go:227] imageStates is map[]
I0904 11:52:37.480391       1 node_info.go:227] imageStates is map[]
I0904 11:52:37.480400       1 node_info.go:227] imageStates is map[]
I0904 11:52:37.480435       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:52:37.480468       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:52:37.480481       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:52:37.480496       1 session.go:230] Open Session 16ebd721-c5e0-496a-b6f3-565ec173008f with <1> Job and <5> Queues
I0904 11:52:37.480518       1 session.go:233] Session 16ebd721-c5e0-496a-b6f3-565ec173008f operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:52:37.480648       1 sla.go:85] Enter sla plugin ...
I0904 11:52:37.480665       1 sla.go:154] Leaving sla plugin.
I0904 11:52:37.480670       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:52:37.480681       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:52:37.480686       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 11:52:37.480738       1 factory.go:59] Register preBinder predicates successfully
I0904 11:52:37.480744       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
I0904 11:52:37.480761       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:52:37.480776       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:52:37.480794       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:52:37.480815       1 binpack.go:165] Enter binpack plugin ...
I0904 11:52:37.480849       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:52:37.480858       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:52:37.480866       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:52:37.480871       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:52:37.480881       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:37.480896       1 allocate.go:62] Enter Allocate ...
I0904 11:52:37.480901       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:37.480911       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:52:37.480917       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:52:37.480924       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:52:37.480930       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:52:37.480935       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:52:37.480940       1 allocate.go:83] Leaving Allocate ...
I0904 11:52:37.480947       1 backfill.go:59] Enter Backfill ...
I0904 11:52:37.480954       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:37.480964       1 backfill.go:110] Leaving Backfill ...
I0904 11:52:37.480971       1 reclaim.go:47] Enter Reclaim ...
I0904 11:52:37.480978       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:52:37.480985       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:37.480995       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:52:37.481007       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:52:37.481014       1 preempt.go:103] Enter Preempt ...
I0904 11:52:37.481020       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:37.481030       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:52:37.481062       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:52:37.481110       1 preempt.go:270] Leaving Preempt ...
I0904 11:52:37.481315       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:37.481362       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:52:37.481375       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:52:37.481390       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:52:37.481401       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:37.481424       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:52:37.481469       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:52:37.481476       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:52:37.481489       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:52:37.481512       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:37.481534       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:52:37.481595       1 session.go:361] Session 16ebd721-c5e0-496a-b6f3-565ec173008f operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:52:37.481606       1 session.go:375] Close Session 16ebd721-c5e0-496a-b6f3-565ec173008f
I0904 11:52:37.481620       1 scheduler.go:133] End scheduling ...
I0904 11:52:44.813762       1 cache.go:1179] started sync node integration-control-plane
I0904 11:52:44.813831       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:52:44.814100       1 node_info.go:227] imageStates is map[]
I0904 11:52:47.481932       1 scheduler.go:106] Start scheduling ...
I0904 11:52:47.482123       1 node_info.go:227] imageStates is map[]
I0904 11:52:47.482137       1 node_info.go:227] imageStates is map[]
I0904 11:52:47.482166       1 node_info.go:227] imageStates is map[]
I0904 11:52:47.482181       1 node_info.go:227] imageStates is map[]
I0904 11:52:47.482210       1 node_info.go:227] imageStates is map[]
I0904 11:52:47.482245       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:52:47.482278       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:52:47.482298       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:52:47.482310       1 session.go:230] Open Session 805b5da0-7e3e-422f-8db0-b976ea55d37a with <1> Job and <5> Queues
I0904 11:52:47.482323       1 session.go:233] Session 805b5da0-7e3e-422f-8db0-b976ea55d37a operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:52:47.482451       1 sla.go:85] Enter sla plugin ...
I0904 11:52:47.482470       1 sla.go:154] Leaving sla plugin.
I0904 11:52:47.482475       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:52:47.482486       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:52:47.482491       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00
I0904 11:52:47.482539       1 factory.go:59] Register preBinder predicates successfully
I0904 11:52:47.482545       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>
I0904 11:52:47.482561       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:52:47.482588       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:52:47.482606       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:52:47.482637       1 binpack.go:165] Enter binpack plugin ...
I0904 11:52:47.482641       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:52:47.482645       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:52:47.482649       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:52:47.482652       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:52:47.482657       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:47.482666       1 allocate.go:62] Enter Allocate ...
I0904 11:52:47.482669       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:47.482674       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:52:47.482676       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:52:47.482679       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:52:47.482683       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:52:47.482685       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:52:47.482687       1 allocate.go:83] Leaving Allocate ...
I0904 11:52:47.482691       1 backfill.go:59] Enter Backfill ...
I0904 11:52:47.482693       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:47.482697       1 backfill.go:110] Leaving Backfill ...
I0904 11:52:47.482700       1 reclaim.go:47] Enter Reclaim ...
I0904 11:52:47.482702       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:52:47.482705       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:47.482708       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:52:47.482713       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:52:47.482715       1 preempt.go:103] Enter Preempt ...
I0904 11:52:47.482717       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:47.482720       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:52:47.482724       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:52:47.482727       1 preempt.go:270] Leaving Preempt ...
I0904 11:52:47.482798       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:47.482818       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:52:47.482865       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:52:47.482869       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:52:47.482873       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:52:47.482877       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:47.482884       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:52:47.482889       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:47.482896       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:52:47.482901       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:52:47.482905       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:52:47.482913       1 session.go:361] Session 805b5da0-7e3e-422f-8db0-b976ea55d37a operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:52:47.482917       1 session.go:375] Close Session 805b5da0-7e3e-422f-8db0-b976ea55d37a
I0904 11:52:47.482922       1 scheduler.go:133] End scheduling ...
I0904 11:52:55.031691       1 cache.go:1179] started sync node integration-control-plane
I0904 11:52:55.031766       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:52:55.031949       1 node_info.go:227] imageStates is map[]
I0904 11:52:57.463836       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:52:57.483048       1 scheduler.go:106] Start scheduling ...
I0904 11:52:57.483309       1 node_info.go:227] imageStates is map[]
I0904 11:52:57.483381       1 node_info.go:227] imageStates is map[]
I0904 11:52:57.483399       1 node_info.go:227] imageStates is map[]
I0904 11:52:57.483419       1 node_info.go:227] imageStates is map[]
I0904 11:52:57.483437       1 node_info.go:227] imageStates is map[]
I0904 11:52:57.483476       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:52:57.483543       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:52:57.483561       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:52:57.483577       1 session.go:230] Open Session 4d4e4f39-ef19-4481-b8ae-486bdd7d4f5d with <1> Job and <5> Queues
I0904 11:52:57.483602       1 session.go:233] Session 4d4e4f39-ef19-4481-b8ae-486bdd7d4f5d operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:52:57.483841       1 sla.go:85] Enter sla plugin ...
I0904 11:52:57.483870       1 sla.go:154] Leaving sla plugin.
I0904 11:52:57.483877       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:52:57.483898       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:52:57.483906       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00
I0904 11:52:57.483978       1 factory.go:59] Register preBinder predicates successfully
I0904 11:52:57.483987       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>
I0904 11:52:57.484021       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:52:57.484053       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:52:57.484083       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:52:57.484113       1 binpack.go:165] Enter binpack plugin ...
I0904 11:52:57.484119       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:52:57.484126       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:52:57.484133       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:52:57.484138       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:52:57.484147       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:57.484159       1 allocate.go:62] Enter Allocate ...
I0904 11:52:57.484166       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:57.484175       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:52:57.484181       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:52:57.484187       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:52:57.484191       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:52:57.484196       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:52:57.484200       1 allocate.go:83] Leaving Allocate ...
I0904 11:52:57.484206       1 backfill.go:59] Enter Backfill ...
I0904 11:52:57.484210       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:57.484218       1 backfill.go:110] Leaving Backfill ...
I0904 11:52:57.484223       1 reclaim.go:47] Enter Reclaim ...
I0904 11:52:57.484227       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:52:57.484231       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:57.484238       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:52:57.484247       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:52:57.484252       1 preempt.go:103] Enter Preempt ...
I0904 11:52:57.484255       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:52:57.484262       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:52:57.484272       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:52:57.484277       1 preempt.go:270] Leaving Preempt ...
I0904 11:52:57.484370       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:57.484417       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:52:57.484498       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:52:57.484507       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:52:57.484521       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:52:57.484700       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:57.484717       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:52:57.484726       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:52:57.484742       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:52:57.484752       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:52:57.484764       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:52:57.484785       1 session.go:361] Session 4d4e4f39-ef19-4481-b8ae-486bdd7d4f5d operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:52:57.484793       1 session.go:375] Close Session 4d4e4f39-ef19-4481-b8ae-486bdd7d4f5d
I0904 11:52:57.484804       1 scheduler.go:133] End scheduling ...
I0904 11:53:07.485946       1 scheduler.go:106] Start scheduling ...
I0904 11:53:07.486071       1 node_info.go:227] imageStates is map[]
I0904 11:53:07.486119       1 node_info.go:227] imageStates is map[]
I0904 11:53:07.486144       1 node_info.go:227] imageStates is map[]
I0904 11:53:07.486155       1 node_info.go:227] imageStates is map[]
I0904 11:53:07.486166       1 node_info.go:227] imageStates is map[]
I0904 11:53:07.486190       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:53:07.486227       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:53:07.486239       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:53:07.486249       1 session.go:230] Open Session 627c7834-80fd-49fa-a599-f94e5a1d1572 with <1> Job and <5> Queues
I0904 11:53:07.486261       1 session.go:233] Session 627c7834-80fd-49fa-a599-f94e5a1d1572 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:53:07.486376       1 sla.go:85] Enter sla plugin ...
I0904 11:53:07.486391       1 sla.go:154] Leaving sla plugin.
I0904 11:53:07.486396       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:53:07.486407       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:53:07.486412       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 11:53:07.486461       1 factory.go:59] Register preBinder predicates successfully
I0904 11:53:07.486476       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 11:53:07.486493       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:53:07.486508       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:53:07.486525       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:53:07.486554       1 binpack.go:165] Enter binpack plugin ...
I0904 11:53:07.486557       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:53:07.486561       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:53:07.486566       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:53:07.486568       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:53:07.486575       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:07.486584       1 allocate.go:62] Enter Allocate ...
I0904 11:53:07.486596       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:07.486602       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:53:07.486605       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:53:07.486608       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:53:07.486611       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:53:07.486613       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:53:07.486616       1 allocate.go:83] Leaving Allocate ...
I0904 11:53:07.486620       1 backfill.go:59] Enter Backfill ...
I0904 11:53:07.486622       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:07.486626       1 backfill.go:110] Leaving Backfill ...
I0904 11:53:07.486630       1 reclaim.go:47] Enter Reclaim ...
I0904 11:53:07.486632       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:53:07.486634       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:07.486638       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:53:07.486643       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:53:07.486645       1 preempt.go:103] Enter Preempt ...
I0904 11:53:07.486647       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:07.486651       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:53:07.486654       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:53:07.486657       1 preempt.go:270] Leaving Preempt ...
I0904 11:53:07.486713       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:53:07.486735       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:53:07.486739       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:07.486744       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:53:07.486759       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:53:07.486762       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:53:07.486766       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:53:07.486770       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:07.486775       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:53:07.486780       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:07.486787       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:53:07.486795       1 session.go:361] Session 627c7834-80fd-49fa-a599-f94e5a1d1572 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:53:07.486819       1 session.go:375] Close Session 627c7834-80fd-49fa-a599-f94e5a1d1572
I0904 11:53:07.486835       1 scheduler.go:133] End scheduling ...
I0904 11:53:17.487394       1 scheduler.go:106] Start scheduling ...
I0904 11:53:17.487518       1 node_info.go:227] imageStates is map[]
I0904 11:53:17.487559       1 node_info.go:227] imageStates is map[]
I0904 11:53:17.487582       1 node_info.go:227] imageStates is map[]
I0904 11:53:17.487607       1 node_info.go:227] imageStates is map[]
I0904 11:53:17.487630       1 node_info.go:227] imageStates is map[]
I0904 11:53:17.487666       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:53:17.487698       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:53:17.487709       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:53:17.487720       1 session.go:230] Open Session 82079db6-ca6f-440d-b391-234dc26407f1 with <1> Job and <5> Queues
I0904 11:53:17.487753       1 session.go:233] Session 82079db6-ca6f-440d-b391-234dc26407f1 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:53:17.488140       1 sla.go:85] Enter sla plugin ...
I0904 11:53:17.488161       1 sla.go:154] Leaving sla plugin.
I0904 11:53:17.488166       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:53:17.488186       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:53:17.488192       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00
I0904 11:53:17.488251       1 factory.go:59] Register preBinder predicates successfully
I0904 11:53:17.488259       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>
I0904 11:53:17.488277       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:53:17.488297       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:53:17.488316       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:53:17.488338       1 binpack.go:165] Enter binpack plugin ...
I0904 11:53:17.488341       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:53:17.488346       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:53:17.488351       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:53:17.488354       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:53:17.488360       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:17.488370       1 allocate.go:62] Enter Allocate ...
I0904 11:53:17.488373       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:17.488381       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:53:17.488384       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:53:17.488387       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:53:17.488390       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:53:17.488392       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:53:17.488395       1 allocate.go:83] Leaving Allocate ...
I0904 11:53:17.488398       1 backfill.go:59] Enter Backfill ...
I0904 11:53:17.488401       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:17.488405       1 backfill.go:110] Leaving Backfill ...
I0904 11:53:17.488409       1 reclaim.go:47] Enter Reclaim ...
I0904 11:53:17.488411       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:53:17.488414       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:17.488418       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:53:17.488424       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:53:17.488427       1 preempt.go:103] Enter Preempt ...
I0904 11:53:17.488430       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:17.488434       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:53:17.488439       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:53:17.488442       1 preempt.go:270] Leaving Preempt ...
I0904 11:53:17.488521       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:53:17.488549       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:53:17.488556       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:17.488563       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:53:17.488586       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:53:17.488591       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:53:17.488598       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:53:17.488605       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:17.488616       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:53:17.488623       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:17.488632       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:53:17.488644       1 session.go:361] Session 82079db6-ca6f-440d-b391-234dc26407f1 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:53:17.488649       1 session.go:375] Close Session 82079db6-ca6f-440d-b391-234dc26407f1
I0904 11:53:17.488655       1 scheduler.go:133] End scheduling ...
I0904 11:53:25.708299       1 cache.go:1179] started sync node integration-control-plane
I0904 11:53:25.708322       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:53:25.708390       1 node_info.go:227] imageStates is map[]
I0904 11:53:27.464220       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:53:27.489264       1 scheduler.go:106] Start scheduling ...
I0904 11:53:27.489436       1 node_info.go:227] imageStates is map[]
I0904 11:53:27.489525       1 node_info.go:227] imageStates is map[]
I0904 11:53:27.489549       1 node_info.go:227] imageStates is map[]
I0904 11:53:27.489571       1 node_info.go:227] imageStates is map[]
I0904 11:53:27.489591       1 node_info.go:227] imageStates is map[]
I0904 11:53:27.489611       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:53:27.489661       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:53:27.489684       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:53:27.489702       1 session.go:230] Open Session a8a2b02a-2ff0-49f5-8c4e-1160455b9011 with <1> Job and <5> Queues
I0904 11:53:27.489726       1 session.go:233] Session a8a2b02a-2ff0-49f5-8c4e-1160455b9011 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:53:27.490025       1 sla.go:85] Enter sla plugin ...
I0904 11:53:27.490060       1 sla.go:154] Leaving sla plugin.
I0904 11:53:27.490068       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:53:27.490091       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:53:27.490101       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 11:53:27.490255       1 factory.go:59] Register preBinder predicates successfully
I0904 11:53:27.490266       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>
I0904 11:53:27.490302       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:53:27.490337       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:53:27.490372       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:53:27.490405       1 binpack.go:165] Enter binpack plugin ...
I0904 11:53:27.490412       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:53:27.490420       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 11:53:27.490428       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:53:27.490433       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:53:27.490445       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:27.490461       1 allocate.go:62] Enter Allocate ...
I0904 11:53:27.490466       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:27.490477       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:53:27.490483       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:53:27.490489       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:53:27.490494       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:53:27.490499       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:53:27.490504       1 allocate.go:83] Leaving Allocate ...
I0904 11:53:27.490510       1 backfill.go:59] Enter Backfill ...
I0904 11:53:27.490515       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:27.490524       1 backfill.go:110] Leaving Backfill ...
I0904 11:53:27.490529       1 reclaim.go:47] Enter Reclaim ...
I0904 11:53:27.490535       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:53:27.490541       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:27.490549       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:53:27.490559       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:53:27.490563       1 preempt.go:103] Enter Preempt ...
I0904 11:53:27.490572       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:27.490579       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:53:27.490587       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:53:27.490593       1 preempt.go:270] Leaving Preempt ...
I0904 11:53:27.490730       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:27.490758       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:53:27.490773       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:53:27.490785       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:53:27.490793       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:27.490804       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:53:27.490834       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:53:27.490840       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:53:27.490849       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:53:27.490856       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:27.490867       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:53:27.490886       1 session.go:361] Session a8a2b02a-2ff0-49f5-8c4e-1160455b9011 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:53:27.490892       1 session.go:375] Close Session a8a2b02a-2ff0-49f5-8c4e-1160455b9011
I0904 11:53:27.490900       1 scheduler.go:133] End scheduling ...
I0904 11:53:35.804794       1 cache.go:1179] started sync node integration-control-plane
I0904 11:53:35.804829       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:53:35.804909       1 node_info.go:227] imageStates is map[]
I0904 11:53:37.492039       1 scheduler.go:106] Start scheduling ...
I0904 11:53:37.492194       1 node_info.go:227] imageStates is map[]
I0904 11:53:37.492241       1 node_info.go:227] imageStates is map[]
I0904 11:53:37.492259       1 node_info.go:227] imageStates is map[]
I0904 11:53:37.492282       1 node_info.go:227] imageStates is map[]
I0904 11:53:37.492298       1 node_info.go:227] imageStates is map[]
I0904 11:53:37.492341       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:53:37.492393       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:53:37.492413       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:53:37.492433       1 session.go:230] Open Session 886f0200-d030-4c9b-acd1-291cd130e197 with <1> Job and <5> Queues
I0904 11:53:37.492459       1 session.go:233] Session 886f0200-d030-4c9b-acd1-291cd130e197 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:53:37.492868       1 sla.go:85] Enter sla plugin ...
I0904 11:53:37.492910       1 sla.go:154] Leaving sla plugin.
I0904 11:53:37.492921       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:53:37.492945       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:53:37.492956       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 11:53:37.493048       1 factory.go:59] Register preBinder predicates successfully
I0904 11:53:37.493063       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 11:53:37.493089       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:53:37.493120       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:53:37.493149       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:53:37.493184       1 binpack.go:165] Enter binpack plugin ...
I0904 11:53:37.493209       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:53:37.493216       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:53:37.493224       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:53:37.493229       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:53:37.493239       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:37.493253       1 allocate.go:62] Enter Allocate ...
I0904 11:53:37.493258       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:37.493266       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:53:37.493274       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:53:37.493280       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:53:37.493287       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:53:37.493291       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:53:37.493294       1 allocate.go:83] Leaving Allocate ...
I0904 11:53:37.493301       1 backfill.go:59] Enter Backfill ...
I0904 11:53:37.493305       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:37.493312       1 backfill.go:110] Leaving Backfill ...
I0904 11:53:37.493317       1 reclaim.go:47] Enter Reclaim ...
I0904 11:53:37.493322       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:53:37.493326       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:37.493333       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:53:37.493344       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:53:37.493349       1 preempt.go:103] Enter Preempt ...
I0904 11:53:37.493352       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:37.493359       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:53:37.493368       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:53:37.493373       1 preempt.go:270] Leaving Preempt ...
I0904 11:53:37.493494       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:37.493535       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:53:37.493544       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:53:37.493552       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:53:37.493559       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:37.493568       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:53:37.493592       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:53:37.493618       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:53:37.493627       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:53:37.493659       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:37.493687       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:53:37.493702       1 session.go:361] Session 886f0200-d030-4c9b-acd1-291cd130e197 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:53:37.493724       1 session.go:375] Close Session 886f0200-d030-4c9b-acd1-291cd130e197
I0904 11:53:37.493731       1 scheduler.go:133] End scheduling ...
I0904 11:53:47.493900       1 scheduler.go:106] Start scheduling ...
I0904 11:53:47.494116       1 node_info.go:227] imageStates is map[]
I0904 11:53:47.494212       1 node_info.go:227] imageStates is map[]
I0904 11:53:47.494267       1 node_info.go:227] imageStates is map[]
I0904 11:53:47.494307       1 node_info.go:227] imageStates is map[]
I0904 11:53:47.494327       1 node_info.go:227] imageStates is map[]
I0904 11:53:47.494369       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:53:47.494414       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:53:47.494457       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:53:47.494476       1 session.go:230] Open Session 14412ecf-76c4-45e2-9bc3-6c8c5ed12b1b with <1> Job and <5> Queues
I0904 11:53:47.494521       1 session.go:233] Session 14412ecf-76c4-45e2-9bc3-6c8c5ed12b1b operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:53:47.494689       1 sla.go:85] Enter sla plugin ...
I0904 11:53:47.494704       1 sla.go:154] Leaving sla plugin.
I0904 11:53:47.494709       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:53:47.494720       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:53:47.494726       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00
I0904 11:53:47.494782       1 factory.go:59] Register preBinder predicates successfully
I0904 11:53:47.494799       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>
I0904 11:53:47.494817       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:53:47.494834       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:53:47.494848       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:53:47.494871       1 binpack.go:165] Enter binpack plugin ...
I0904 11:53:47.494874       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:53:47.494878       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 11:53:47.494882       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:53:47.494885       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:53:47.494891       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:47.494901       1 allocate.go:62] Enter Allocate ...
I0904 11:53:47.494903       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:47.494908       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:53:47.494911       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:53:47.494914       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:53:47.494916       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:53:47.494918       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:53:47.494920       1 allocate.go:83] Leaving Allocate ...
I0904 11:53:47.494925       1 backfill.go:59] Enter Backfill ...
I0904 11:53:47.494927       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:47.494931       1 backfill.go:110] Leaving Backfill ...
I0904 11:53:47.494934       1 reclaim.go:47] Enter Reclaim ...
I0904 11:53:47.494936       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:53:47.494938       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:47.494942       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:53:47.494947       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:53:47.494949       1 preempt.go:103] Enter Preempt ...
I0904 11:53:47.494951       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:47.494955       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:53:47.494958       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:53:47.494961       1 preempt.go:270] Leaving Preempt ...
I0904 11:53:47.495024       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:47.495047       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:53:47.495054       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:47.495060       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:53:47.495064       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:53:47.495068       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:53:47.495114       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:47.495120       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:53:47.495135       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:53:47.495138       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:53:47.495142       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:53:47.495158       1 session.go:361] Session 14412ecf-76c4-45e2-9bc3-6c8c5ed12b1b operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:53:47.495171       1 session.go:375] Close Session 14412ecf-76c4-45e2-9bc3-6c8c5ed12b1b
I0904 11:53:47.495175       1 scheduler.go:133] End scheduling ...
I0904 11:53:57.465214       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:53:57.495596       1 scheduler.go:106] Start scheduling ...
I0904 11:53:57.495829       1 node_info.go:227] imageStates is map[]
I0904 11:53:57.495893       1 node_info.go:227] imageStates is map[]
I0904 11:53:57.495919       1 node_info.go:227] imageStates is map[]
I0904 11:53:57.495949       1 node_info.go:227] imageStates is map[]
I0904 11:53:57.495975       1 node_info.go:227] imageStates is map[]
I0904 11:53:57.496060       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:53:57.496208       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:53:57.496236       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:53:57.496263       1 session.go:230] Open Session f792f4c5-06cf-4eee-b4c2-a8a29b01936c with <1> Job and <5> Queues
I0904 11:53:57.496293       1 session.go:233] Session f792f4c5-06cf-4eee-b4c2-a8a29b01936c operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:53:57.496624       1 sla.go:85] Enter sla plugin ...
I0904 11:53:57.496666       1 sla.go:154] Leaving sla plugin.
I0904 11:53:57.496678       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:53:57.496712       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:53:57.496722       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00
I0904 11:53:57.497314       1 factory.go:59] Register preBinder predicates successfully
I0904 11:53:57.497348       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>
I0904 11:53:57.497381       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:53:57.497411       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:53:57.497519       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:53:57.497553       1 binpack.go:165] Enter binpack plugin ...
I0904 11:53:57.497558       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:53:57.497565       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:53:57.497575       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:53:57.497579       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:53:57.497587       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:57.497633       1 allocate.go:62] Enter Allocate ...
I0904 11:53:57.497638       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:57.497646       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:53:57.497650       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:53:57.497655       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:53:57.497658       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:53:57.497662       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:53:57.497666       1 allocate.go:83] Leaving Allocate ...
I0904 11:53:57.497672       1 backfill.go:59] Enter Backfill ...
I0904 11:53:57.497675       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:57.497681       1 backfill.go:110] Leaving Backfill ...
I0904 11:53:57.497686       1 reclaim.go:47] Enter Reclaim ...
I0904 11:53:57.497690       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:53:57.497695       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:57.497701       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:53:57.497709       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:53:57.497714       1 preempt.go:103] Enter Preempt ...
I0904 11:53:57.497717       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:53:57.497723       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:53:57.497729       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:53:57.497734       1 preempt.go:270] Leaving Preempt ...
I0904 11:53:57.497847       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:57.497885       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:53:57.497916       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:53:57.497921       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:53:57.497929       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:53:57.497937       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:57.497948       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:53:57.497956       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:53:57.497967       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:53:57.497974       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:53:57.498037       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:53:57.498068       1 session.go:361] Session f792f4c5-06cf-4eee-b4c2-a8a29b01936c operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:53:57.498076       1 session.go:375] Close Session f792f4c5-06cf-4eee-b4c2-a8a29b01936c
I0904 11:53:57.498083       1 scheduler.go:133] End scheduling ...
I0904 11:54:07.498882       1 scheduler.go:106] Start scheduling ...
I0904 11:54:07.499278       1 node_info.go:227] imageStates is map[]
I0904 11:54:07.499426       1 node_info.go:227] imageStates is map[]
I0904 11:54:07.499516       1 node_info.go:227] imageStates is map[]
I0904 11:54:07.499548       1 node_info.go:227] imageStates is map[]
I0904 11:54:07.499584       1 node_info.go:227] imageStates is map[]
I0904 11:54:07.499648       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:54:07.499724       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:54:07.499788       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:54:07.499817       1 session.go:230] Open Session fa2d79f5-c890-4ec9-8436-7ba5126f812f with <1> Job and <5> Queues
I0904 11:54:07.499852       1 session.go:233] Session fa2d79f5-c890-4ec9-8436-7ba5126f812f operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:54:07.500334       1 sla.go:85] Enter sla plugin ...
I0904 11:54:07.500354       1 sla.go:154] Leaving sla plugin.
I0904 11:54:07.500366       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:54:07.500400       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:54:07.500413       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00
I0904 11:54:07.500520       1 factory.go:59] Register preBinder predicates successfully
I0904 11:54:07.500569       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>
I0904 11:54:07.500620       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:54:07.500673       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:54:07.500722       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:54:07.500844       1 binpack.go:165] Enter binpack plugin ...
I0904 11:54:07.500854       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:54:07.500866       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 11:54:07.500877       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:54:07.500885       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:54:07.500899       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:07.500949       1 allocate.go:62] Enter Allocate ...
I0904 11:54:07.500957       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:07.500973       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:54:07.500982       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:54:07.500991       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:54:07.500997       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:54:07.501005       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:54:07.501011       1 allocate.go:83] Leaving Allocate ...
I0904 11:54:07.501020       1 backfill.go:59] Enter Backfill ...
I0904 11:54:07.501027       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:07.501040       1 backfill.go:110] Leaving Backfill ...
I0904 11:54:07.501047       1 reclaim.go:47] Enter Reclaim ...
I0904 11:54:07.501054       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:54:07.501061       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:07.501072       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:54:07.501087       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:54:07.501094       1 preempt.go:103] Enter Preempt ...
I0904 11:54:07.501100       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:07.501111       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:54:07.501123       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:54:07.501132       1 preempt.go:270] Leaving Preempt ...
I0904 11:54:07.501283       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:54:07.501339       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:54:07.501353       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:07.501367       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:54:07.501436       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:54:07.501446       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:54:07.501460       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:54:07.501472       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:07.501488       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:54:07.501501       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:07.501519       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:54:07.501544       1 session.go:361] Session fa2d79f5-c890-4ec9-8436-7ba5126f812f operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:54:07.501555       1 session.go:375] Close Session fa2d79f5-c890-4ec9-8436-7ba5126f812f
I0904 11:54:07.501566       1 scheduler.go:133] End scheduling ...
I0904 11:54:17.502054       1 scheduler.go:106] Start scheduling ...
I0904 11:54:17.502163       1 node_info.go:227] imageStates is map[]
I0904 11:54:17.502200       1 node_info.go:227] imageStates is map[]
I0904 11:54:17.502215       1 node_info.go:227] imageStates is map[]
I0904 11:54:17.502231       1 node_info.go:227] imageStates is map[]
I0904 11:54:17.502245       1 node_info.go:227] imageStates is map[]
I0904 11:54:17.502258       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:54:17.502294       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:54:17.502325       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:54:17.502341       1 session.go:230] Open Session 6d5727d2-13cb-4cb1-b947-9644ef335aa7 with <1> Job and <5> Queues
I0904 11:54:17.502359       1 session.go:233] Session 6d5727d2-13cb-4cb1-b947-9644ef335aa7 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:54:17.502529       1 sla.go:85] Enter sla plugin ...
I0904 11:54:17.502552       1 sla.go:154] Leaving sla plugin.
I0904 11:54:17.502558       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:54:17.502573       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:54:17.502579       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00
I0904 11:54:17.502633       1 factory.go:59] Register preBinder predicates successfully
I0904 11:54:17.502640       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 11:54:17.502661       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:54:17.502685       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:54:17.502721       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:54:17.502744       1 binpack.go:165] Enter binpack plugin ...
I0904 11:54:17.502748       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:54:17.502753       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 11:54:17.502759       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:54:17.502762       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:54:17.502770       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:17.502780       1 allocate.go:62] Enter Allocate ...
I0904 11:54:17.502783       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:17.502789       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:54:17.502793       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:54:17.502797       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:54:17.502799       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:54:17.502803       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:54:17.502805       1 allocate.go:83] Leaving Allocate ...
I0904 11:54:17.502810       1 backfill.go:59] Enter Backfill ...
I0904 11:54:17.502813       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:17.502818       1 backfill.go:110] Leaving Backfill ...
I0904 11:54:17.502822       1 reclaim.go:47] Enter Reclaim ...
I0904 11:54:17.502825       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:54:17.502828       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:17.502833       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:54:17.502839       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:54:17.502843       1 preempt.go:103] Enter Preempt ...
I0904 11:54:17.502846       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:17.502850       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:54:17.502855       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:54:17.502859       1 preempt.go:270] Leaving Preempt ...
I0904 11:54:17.502931       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:17.502959       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:54:17.502969       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:54:17.502975       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:54:17.502980       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:17.502988       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:54:17.503011       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:54:17.503017       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:54:17.503023       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:54:17.503034       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:17.503043       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:54:17.503066       1 session.go:361] Session 6d5727d2-13cb-4cb1-b947-9644ef335aa7 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:54:17.503070       1 session.go:375] Close Session 6d5727d2-13cb-4cb1-b947-9644ef335aa7
I0904 11:54:17.503075       1 scheduler.go:133] End scheduling ...
I0904 11:54:27.465332       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:54:27.504079       1 scheduler.go:106] Start scheduling ...
I0904 11:54:27.504201       1 node_info.go:227] imageStates is map[]
I0904 11:54:27.504227       1 node_info.go:227] imageStates is map[]
I0904 11:54:27.504269       1 node_info.go:227] imageStates is map[]
I0904 11:54:27.504294       1 node_info.go:227] imageStates is map[]
I0904 11:54:27.504315       1 node_info.go:227] imageStates is map[]
I0904 11:54:27.504335       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:54:27.504379       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:54:27.504399       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:54:27.504410       1 session.go:230] Open Session 4bd94b83-5d1f-422b-adad-362f09f31ad8 with <1> Job and <5> Queues
I0904 11:54:27.504421       1 session.go:233] Session 4bd94b83-5d1f-422b-adad-362f09f31ad8 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:54:27.504555       1 sla.go:85] Enter sla plugin ...
I0904 11:54:27.504570       1 sla.go:154] Leaving sla plugin.
I0904 11:54:27.504575       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:54:27.504587       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:54:27.504593       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00
I0904 11:54:27.504651       1 factory.go:59] Register preBinder predicates successfully
I0904 11:54:27.504668       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 11:54:27.504685       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:54:27.504700       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:54:27.504727       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:54:27.504755       1 binpack.go:165] Enter binpack plugin ...
I0904 11:54:27.504767       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:54:27.504772       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:54:27.504776       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:54:27.504779       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:54:27.504785       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:27.504793       1 allocate.go:62] Enter Allocate ...
I0904 11:54:27.504795       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:27.504800       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:54:27.504805       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:54:27.504808       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:54:27.504811       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:54:27.504813       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:54:27.504815       1 allocate.go:83] Leaving Allocate ...
I0904 11:54:27.504819       1 backfill.go:59] Enter Backfill ...
I0904 11:54:27.504824       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:27.504828       1 backfill.go:110] Leaving Backfill ...
I0904 11:54:27.504832       1 reclaim.go:47] Enter Reclaim ...
I0904 11:54:27.504834       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:54:27.504837       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:27.504841       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:54:27.504846       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:54:27.504850       1 preempt.go:103] Enter Preempt ...
I0904 11:54:27.504852       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:27.504856       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:54:27.504859       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:54:27.504862       1 preempt.go:270] Leaving Preempt ...
I0904 11:54:27.504930       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:27.504949       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:54:27.504967       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:54:27.504969       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:54:27.504973       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:54:27.504978       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:27.504983       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:54:27.504987       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:27.504993       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:54:27.504997       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:54:27.505001       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:54:27.505007       1 session.go:361] Session 4bd94b83-5d1f-422b-adad-362f09f31ad8 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:54:27.505010       1 session.go:375] Close Session 4bd94b83-5d1f-422b-adad-362f09f31ad8
I0904 11:54:27.505014       1 scheduler.go:133] End scheduling ...
I0904 11:54:37.505882       1 scheduler.go:106] Start scheduling ...
I0904 11:54:37.506095       1 node_info.go:227] imageStates is map[]
I0904 11:54:37.506160       1 node_info.go:227] imageStates is map[]
I0904 11:54:37.506186       1 node_info.go:227] imageStates is map[]
I0904 11:54:37.506216       1 node_info.go:227] imageStates is map[]
I0904 11:54:37.506244       1 node_info.go:227] imageStates is map[]
I0904 11:54:37.506332       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:54:37.506415       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:54:37.506441       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:54:37.506463       1 session.go:230] Open Session 84a7839f-f86c-47ab-b0dc-f5ef9e526af2 with <1> Job and <5> Queues
I0904 11:54:37.506491       1 session.go:233] Session 84a7839f-f86c-47ab-b0dc-f5ef9e526af2 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:54:37.506776       1 sla.go:85] Enter sla plugin ...
I0904 11:54:37.506824       1 sla.go:154] Leaving sla plugin.
I0904 11:54:37.506836       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:54:37.506865       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:54:37.506879       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00
I0904 11:54:37.506980       1 factory.go:59] Register preBinder predicates successfully
I0904 11:54:37.506994       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 11:54:37.507044       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:54:37.507126       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:54:37.507168       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:54:37.507240       1 binpack.go:165] Enter binpack plugin ...
I0904 11:54:37.507248       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:54:37.507260       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:54:37.507270       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:54:37.507276       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:54:37.507288       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:37.507305       1 allocate.go:62] Enter Allocate ...
I0904 11:54:37.507311       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:37.507324       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:54:37.507331       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:54:37.507339       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:54:37.507345       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:54:37.507351       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:54:37.507357       1 allocate.go:83] Leaving Allocate ...
I0904 11:54:37.507365       1 backfill.go:59] Enter Backfill ...
I0904 11:54:37.507371       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:37.507381       1 backfill.go:110] Leaving Backfill ...
I0904 11:54:37.507388       1 reclaim.go:47] Enter Reclaim ...
I0904 11:54:37.507393       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:54:37.507399       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:37.507409       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:54:37.507421       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:54:37.507427       1 preempt.go:103] Enter Preempt ...
I0904 11:54:37.507432       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:37.507441       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:54:37.507451       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:54:37.507459       1 preempt.go:270] Leaving Preempt ...
I0904 11:54:37.507591       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:54:37.507644       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:54:37.507657       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:37.507734       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:54:37.507759       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:37.507788       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:54:37.507800       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:54:37.507813       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:54:37.507824       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:37.507841       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:54:37.507915       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:54:37.507935       1 session.go:361] Session 84a7839f-f86c-47ab-b0dc-f5ef9e526af2 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:54:37.507943       1 session.go:375] Close Session 84a7839f-f86c-47ab-b0dc-f5ef9e526af2
I0904 11:54:37.507954       1 scheduler.go:133] End scheduling ...
I0904 11:54:47.508338       1 scheduler.go:106] Start scheduling ...
I0904 11:54:47.508457       1 node_info.go:227] imageStates is map[]
I0904 11:54:47.508563       1 node_info.go:227] imageStates is map[]
I0904 11:54:47.508605       1 node_info.go:227] imageStates is map[]
I0904 11:54:47.508618       1 node_info.go:227] imageStates is map[]
I0904 11:54:47.508631       1 node_info.go:227] imageStates is map[]
I0904 11:54:47.508657       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:54:47.508692       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:54:47.508704       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:54:47.508714       1 session.go:230] Open Session 07fdebc0-b139-42f8-9f06-63a19066bb6e with <1> Job and <5> Queues
I0904 11:54:47.508726       1 session.go:233] Session 07fdebc0-b139-42f8-9f06-63a19066bb6e operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:54:47.508848       1 sla.go:85] Enter sla plugin ...
I0904 11:54:47.508865       1 sla.go:154] Leaving sla plugin.
I0904 11:54:47.508870       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:54:47.508880       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:54:47.508885       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00
I0904 11:54:47.508938       1 factory.go:59] Register preBinder predicates successfully
I0904 11:54:47.508945       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 11:54:47.508962       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:54:47.508976       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:54:47.508992       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:54:47.509010       1 binpack.go:165] Enter binpack plugin ...
I0904 11:54:47.509013       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:54:47.509016       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:54:47.509020       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:54:47.509024       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:54:47.509029       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:47.509037       1 allocate.go:62] Enter Allocate ...
I0904 11:54:47.509040       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:47.509044       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:54:47.509047       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:54:47.509050       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:54:47.509052       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:54:47.509054       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:54:47.509056       1 allocate.go:83] Leaving Allocate ...
I0904 11:54:47.509059       1 backfill.go:59] Enter Backfill ...
I0904 11:54:47.509062       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:47.509066       1 backfill.go:110] Leaving Backfill ...
I0904 11:54:47.509069       1 reclaim.go:47] Enter Reclaim ...
I0904 11:54:47.509071       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:54:47.509074       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:47.509078       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:54:47.509082       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:54:47.509085       1 preempt.go:103] Enter Preempt ...
I0904 11:54:47.509088       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:47.509098       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:54:47.509101       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:54:47.509104       1 preempt.go:270] Leaving Preempt ...
I0904 11:54:47.509161       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:47.509170       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:54:47.509191       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:54:47.509193       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:54:47.509198       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:54:47.509201       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:47.509207       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:54:47.509211       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:47.509218       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:54:47.509222       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:54:47.509226       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:54:47.509233       1 session.go:361] Session 07fdebc0-b139-42f8-9f06-63a19066bb6e operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:54:47.509236       1 session.go:375] Close Session 07fdebc0-b139-42f8-9f06-63a19066bb6e
I0904 11:54:47.509239       1 scheduler.go:133] End scheduling ...
I0904 11:54:57.465777       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:54:57.509648       1 scheduler.go:106] Start scheduling ...
I0904 11:54:57.509760       1 node_info.go:227] imageStates is map[]
I0904 11:54:57.509782       1 node_info.go:227] imageStates is map[]
I0904 11:54:57.509798       1 node_info.go:227] imageStates is map[]
I0904 11:54:57.509814       1 node_info.go:227] imageStates is map[]
I0904 11:54:57.509856       1 node_info.go:227] imageStates is map[]
I0904 11:54:57.509893       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:54:57.509942       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:54:57.509971       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:54:57.509998       1 session.go:230] Open Session 86e4e630-5020-44b2-b851-4e526d8313ad with <1> Job and <5> Queues
I0904 11:54:57.510015       1 session.go:233] Session 86e4e630-5020-44b2-b851-4e526d8313ad operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:54:57.510177       1 sla.go:85] Enter sla plugin ...
I0904 11:54:57.510192       1 sla.go:154] Leaving sla plugin.
I0904 11:54:57.510197       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:54:57.510211       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:54:57.510218       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 11:54:57.510269       1 factory.go:59] Register preBinder predicates successfully
I0904 11:54:57.510286       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 11:54:57.510307       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:54:57.510325       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:54:57.510353       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:54:57.510375       1 binpack.go:165] Enter binpack plugin ...
I0904 11:54:57.510378       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:54:57.510382       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:54:57.510386       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:54:57.510389       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:54:57.510395       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:57.510412       1 allocate.go:62] Enter Allocate ...
I0904 11:54:57.510415       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:57.510420       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:54:57.510424       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:54:57.510427       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:54:57.510430       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:54:57.510432       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:54:57.510435       1 allocate.go:83] Leaving Allocate ...
I0904 11:54:57.510438       1 backfill.go:59] Enter Backfill ...
I0904 11:54:57.510441       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:57.510445       1 backfill.go:110] Leaving Backfill ...
I0904 11:54:57.510448       1 reclaim.go:47] Enter Reclaim ...
I0904 11:54:57.510450       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:54:57.510453       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:57.510457       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:54:57.510462       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:54:57.510464       1 preempt.go:103] Enter Preempt ...
I0904 11:54:57.510467       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:54:57.510470       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:54:57.510474       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:54:57.510477       1 preempt.go:270] Leaving Preempt ...
I0904 11:54:57.510545       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:57.510568       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:54:57.510574       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:57.510581       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:54:57.510586       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:54:57.510591       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:54:57.510594       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:54:57.510599       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:54:57.510626       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:54:57.510630       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:54:57.510635       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:54:57.510642       1 session.go:361] Session 86e4e630-5020-44b2-b851-4e526d8313ad operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:54:57.510646       1 session.go:375] Close Session 86e4e630-5020-44b2-b851-4e526d8313ad
I0904 11:54:57.510650       1 scheduler.go:133] End scheduling ...
I0904 11:55:07.510942       1 scheduler.go:106] Start scheduling ...
I0904 11:55:07.511191       1 node_info.go:227] imageStates is map[]
I0904 11:55:07.511296       1 node_info.go:227] imageStates is map[]
I0904 11:55:07.511368       1 node_info.go:227] imageStates is map[]
I0904 11:55:07.511464       1 node_info.go:227] imageStates is map[]
I0904 11:55:07.511496       1 node_info.go:227] imageStates is map[]
I0904 11:55:07.511626       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:55:07.511687       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:55:07.511711       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:55:07.511738       1 session.go:230] Open Session 86653418-c2d9-44c0-9cce-d3d6d7f21410 with <1> Job and <5> Queues
I0904 11:55:07.511811       1 session.go:233] Session 86653418-c2d9-44c0-9cce-d3d6d7f21410 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:55:07.512259       1 sla.go:85] Enter sla plugin ...
I0904 11:55:07.512304       1 sla.go:154] Leaving sla plugin.
I0904 11:55:07.512314       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:55:07.512341       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:55:07.512351       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00
I0904 11:55:07.512460       1 factory.go:59] Register preBinder predicates successfully
I0904 11:55:07.512492       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>
I0904 11:55:07.512528       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:55:07.512563       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:55:07.512603       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> deserved resources <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> are less than the sum of its child queues' deserved resources <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>
I0904 11:55:07.512637       1 binpack.go:165] Enter binpack plugin ...
I0904 11:55:07.512664       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:55:07.512674       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 11:55:07.512682       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:55:07.512688       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:55:07.512698       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:07.512714       1 allocate.go:62] Enter Allocate ...
I0904 11:55:07.512719       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:07.512731       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:55:07.512737       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:55:07.512743       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:55:07.512748       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:55:07.512753       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:55:07.512758       1 allocate.go:83] Leaving Allocate ...
I0904 11:55:07.512765       1 backfill.go:59] Enter Backfill ...
I0904 11:55:07.512770       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:07.512778       1 backfill.go:110] Leaving Backfill ...
I0904 11:55:07.512784       1 reclaim.go:47] Enter Reclaim ...
I0904 11:55:07.512789       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:55:07.512794       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:07.512802       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:55:07.512815       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:55:07.512823       1 preempt.go:103] Enter Preempt ...
I0904 11:55:07.512828       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:07.512836       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:55:07.512848       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:55:07.512856       1 preempt.go:270] Leaving Preempt ...
I0904 11:55:07.512972       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:07.513014       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:55:07.513055       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:55:07.513062       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:55:07.513073       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:55:07.513084       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:07.513101       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:55:07.513134       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:07.513151       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:55:07.513162       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:55:07.513172       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:55:07.513189       1 session.go:361] Session 86653418-c2d9-44c0-9cce-d3d6d7f21410 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:55:07.513196       1 session.go:375] Close Session 86653418-c2d9-44c0-9cce-d3d6d7f21410
I0904 11:55:07.513204       1 scheduler.go:133] End scheduling ...
I0904 11:55:17.514141       1 scheduler.go:106] Start scheduling ...
I0904 11:55:17.514285       1 node_info.go:227] imageStates is map[]
I0904 11:55:17.514315       1 node_info.go:227] imageStates is map[]
I0904 11:55:17.514339       1 node_info.go:227] imageStates is map[]
I0904 11:55:17.514358       1 node_info.go:227] imageStates is map[]
I0904 11:55:17.514413       1 node_info.go:227] imageStates is map[]
I0904 11:55:17.514474       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:55:17.514524       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:55:17.514569       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:55:17.514588       1 session.go:230] Open Session f594108b-8348-402f-8f2f-ec7a7b4964cc with <1> Job and <5> Queues
I0904 11:55:17.514608       1 session.go:233] Session f594108b-8348-402f-8f2f-ec7a7b4964cc operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:55:17.514818       1 sla.go:85] Enter sla plugin ...
I0904 11:55:17.514853       1 sla.go:154] Leaving sla plugin.
I0904 11:55:17.514862       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:55:17.514884       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:55:17.514905       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 11:55:17.514977       1 factory.go:59] Register preBinder predicates successfully
I0904 11:55:17.515010       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>
I0904 11:55:17.515044       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:55:17.515072       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:55:17.515087       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:55:17.515096       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:55:17.515110       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:55:17.515120       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:55:17.515152       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:55:17.515162       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:55:17.515172       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:55:17.515207       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:55:17.515224       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:55:17.515267       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:55:17.515284       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:55:17.515321       1 binpack.go:165] Enter binpack plugin ...
I0904 11:55:17.515324       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:55:17.515328       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:55:17.515333       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:55:17.515335       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:55:17.515341       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:17.515351       1 allocate.go:62] Enter Allocate ...
I0904 11:55:17.515353       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:17.515358       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:55:17.515361       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:55:17.515364       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:55:17.515366       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:55:17.515369       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:55:17.515371       1 allocate.go:83] Leaving Allocate ...
I0904 11:55:17.515375       1 backfill.go:59] Enter Backfill ...
I0904 11:55:17.515379       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:17.515384       1 backfill.go:110] Leaving Backfill ...
I0904 11:55:17.515387       1 reclaim.go:47] Enter Reclaim ...
I0904 11:55:17.515389       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:55:17.515391       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:17.515395       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:55:17.515400       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:55:17.515403       1 preempt.go:103] Enter Preempt ...
I0904 11:55:17.515405       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:17.515409       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:55:17.515412       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:55:17.515417       1 preempt.go:270] Leaving Preempt ...
I0904 11:55:17.515490       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:17.515514       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:55:17.515520       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:55:17.515525       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:55:17.515529       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:17.515534       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:55:17.515552       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:55:17.515555       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:55:17.515559       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:55:17.515562       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:17.515567       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:55:17.515576       1 session.go:361] Session f594108b-8348-402f-8f2f-ec7a7b4964cc operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:55:17.515580       1 session.go:375] Close Session f594108b-8348-402f-8f2f-ec7a7b4964cc
I0904 11:55:17.515584       1 scheduler.go:133] End scheduling ...
I0904 11:55:27.466871       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:55:27.515998       1 scheduler.go:106] Start scheduling ...
I0904 11:55:27.516093       1 node_info.go:227] imageStates is map[]
I0904 11:55:27.516186       1 node_info.go:227] imageStates is map[]
I0904 11:55:27.516208       1 node_info.go:227] imageStates is map[]
I0904 11:55:27.516220       1 node_info.go:227] imageStates is map[]
I0904 11:55:27.516269       1 node_info.go:227] imageStates is map[]
I0904 11:55:27.516281       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:55:27.516317       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:55:27.516327       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:55:27.516336       1 session.go:230] Open Session 56fb0c4c-d687-4fbd-80f1-f0d1f10f7254 with <1> Job and <5> Queues
I0904 11:55:27.516346       1 session.go:233] Session 56fb0c4c-d687-4fbd-80f1-f0d1f10f7254 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:55:27.516479       1 sla.go:85] Enter sla plugin ...
I0904 11:55:27.516496       1 sla.go:154] Leaving sla plugin.
I0904 11:55:27.516501       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:55:27.516512       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:55:27.516517       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00
I0904 11:55:27.516564       1 factory.go:59] Register preBinder predicates successfully
I0904 11:55:27.516569       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 11:55:27.516587       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:55:27.516602       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:55:27.516618       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:55:27.516625       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:55:27.516646       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:55:27.516654       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:55:27.516665       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:55:27.516672       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:55:27.516684       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:55:27.516698       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:55:27.516721       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:55:27.516732       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:55:27.516740       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:55:27.516769       1 binpack.go:165] Enter binpack plugin ...
I0904 11:55:27.516772       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:55:27.516776       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:55:27.516780       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:55:27.516783       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:55:27.516788       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:27.516796       1 allocate.go:62] Enter Allocate ...
I0904 11:55:27.516799       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:27.516804       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:55:27.516809       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:55:27.516812       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:55:27.516814       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:55:27.516817       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:55:27.516819       1 allocate.go:83] Leaving Allocate ...
I0904 11:55:27.516822       1 backfill.go:59] Enter Backfill ...
I0904 11:55:27.516829       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:27.516833       1 backfill.go:110] Leaving Backfill ...
I0904 11:55:27.516836       1 reclaim.go:47] Enter Reclaim ...
I0904 11:55:27.516838       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:55:27.516840       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:27.516844       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:55:27.516849       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:55:27.516852       1 preempt.go:103] Enter Preempt ...
I0904 11:55:27.516854       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:27.516857       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:55:27.516862       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:55:27.516865       1 preempt.go:270] Leaving Preempt ...
I0904 11:55:27.516925       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:55:27.516945       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:55:27.516949       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:27.516955       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:55:27.516960       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:27.516966       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:55:27.516971       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:55:27.516974       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:55:27.516977       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:27.516982       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:55:27.516997       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:55:27.517005       1 session.go:361] Session 56fb0c4c-d687-4fbd-80f1-f0d1f10f7254 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:55:27.517008       1 session.go:375] Close Session 56fb0c4c-d687-4fbd-80f1-f0d1f10f7254
I0904 11:55:27.517012       1 scheduler.go:133] End scheduling ...
I0904 11:55:37.517304       1 scheduler.go:106] Start scheduling ...
I0904 11:55:37.517454       1 node_info.go:227] imageStates is map[]
I0904 11:55:37.517491       1 node_info.go:227] imageStates is map[]
I0904 11:55:37.517521       1 node_info.go:227] imageStates is map[]
I0904 11:55:37.517587       1 node_info.go:227] imageStates is map[]
I0904 11:55:37.517650       1 node_info.go:227] imageStates is map[]
I0904 11:55:37.517699       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:55:37.517747       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:55:37.517770       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:55:37.517794       1 session.go:230] Open Session fb29cd81-f017-40d6-922a-3ebddade809d with <1> Job and <5> Queues
I0904 11:55:37.517845       1 session.go:233] Session fb29cd81-f017-40d6-922a-3ebddade809d operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:55:37.518154       1 sla.go:85] Enter sla plugin ...
I0904 11:55:37.518198       1 sla.go:154] Leaving sla plugin.
I0904 11:55:37.518209       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:55:37.518240       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:55:37.518252       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00
I0904 11:55:37.518342       1 factory.go:59] Register preBinder predicates successfully
I0904 11:55:37.518382       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>
I0904 11:55:37.518429       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:55:37.518475       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:55:37.518520       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:55:37.518537       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:55:37.518590       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:55:37.518716       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:55:37.518759       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:55:37.518785       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:55:37.518815       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:55:37.518874       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:55:37.518905       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:55:37.518930       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:55:37.518950       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:55:37.519042       1 binpack.go:165] Enter binpack plugin ...
I0904 11:55:37.519051       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:55:37.519062       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:55:37.519073       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:55:37.519078       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:55:37.519092       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:37.519111       1 allocate.go:62] Enter Allocate ...
I0904 11:55:37.519125       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:37.519137       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:55:37.519144       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:55:37.519151       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:55:37.519161       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:55:37.519166       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:55:37.519175       1 allocate.go:83] Leaving Allocate ...
I0904 11:55:37.519181       1 backfill.go:59] Enter Backfill ...
I0904 11:55:37.519188       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:37.519199       1 backfill.go:110] Leaving Backfill ...
I0904 11:55:37.519206       1 reclaim.go:47] Enter Reclaim ...
I0904 11:55:37.519212       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:55:37.519219       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:37.519228       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:55:37.519240       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:55:37.519271       1 preempt.go:103] Enter Preempt ...
I0904 11:55:37.519277       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:37.519286       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:55:37.519295       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:55:37.519301       1 preempt.go:270] Leaving Preempt ...
I0904 11:55:37.519423       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:55:37.519467       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:55:37.519481       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:37.519496       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:55:37.519509       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:37.519523       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:55:37.519532       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:55:37.519545       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:55:37.519553       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:37.519566       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:55:37.519604       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:55:37.519622       1 session.go:361] Session fb29cd81-f017-40d6-922a-3ebddade809d operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:55:37.519630       1 session.go:375] Close Session fb29cd81-f017-40d6-922a-3ebddade809d
I0904 11:55:37.519638       1 scheduler.go:133] End scheduling ...
I0904 11:55:47.519792       1 scheduler.go:106] Start scheduling ...
I0904 11:55:47.519872       1 node_info.go:227] imageStates is map[]
I0904 11:55:47.519889       1 node_info.go:227] imageStates is map[]
I0904 11:55:47.519899       1 node_info.go:227] imageStates is map[]
I0904 11:55:47.519929       1 node_info.go:227] imageStates is map[]
I0904 11:55:47.519943       1 node_info.go:227] imageStates is map[]
I0904 11:55:47.519969       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:55:47.519994       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:55:47.520013       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:55:47.520024       1 session.go:230] Open Session dd137064-f969-45a0-b9d6-37be453883ae with <1> Job and <5> Queues
I0904 11:55:47.520035       1 session.go:233] Session dd137064-f969-45a0-b9d6-37be453883ae operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:55:47.520467       1 sla.go:85] Enter sla plugin ...
I0904 11:55:47.520486       1 sla.go:154] Leaving sla plugin.
I0904 11:55:47.520491       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:55:47.520508       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:55:47.520515       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00
I0904 11:55:47.520589       1 factory.go:59] Register preBinder predicates successfully
I0904 11:55:47.520597       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>
I0904 11:55:47.520627       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:55:47.521005       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:55:47.521700       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:55:47.521786       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:55:47.521905       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:55:47.521973       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:55:47.522014       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:55:47.522091       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:55:47.522138       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:55:47.522173       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:55:47.522211       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:55:47.522242       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:55:47.522364       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:55:47.522495       1 binpack.go:165] Enter binpack plugin ...
I0904 11:55:47.522580       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:55:47.522977       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:55:47.523044       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:55:47.523057       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:55:47.523084       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:47.523116       1 allocate.go:62] Enter Allocate ...
I0904 11:55:47.523127       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:47.523142       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:55:47.523152       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:55:47.523162       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:55:47.523171       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:55:47.523179       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:55:47.523187       1 allocate.go:83] Leaving Allocate ...
I0904 11:55:47.523198       1 backfill.go:59] Enter Backfill ...
I0904 11:55:47.523207       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:47.523220       1 backfill.go:110] Leaving Backfill ...
I0904 11:55:47.523228       1 reclaim.go:47] Enter Reclaim ...
I0904 11:55:47.523235       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:55:47.523243       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:47.523255       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:55:47.523269       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:55:47.523276       1 preempt.go:103] Enter Preempt ...
I0904 11:55:47.523281       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:47.523289       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:55:47.523300       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:55:47.523306       1 preempt.go:270] Leaving Preempt ...
I0904 11:55:47.523423       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:55:47.523455       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:55:47.523461       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:47.523470       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:55:47.523494       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:55:47.523500       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:55:47.523508       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:55:47.523513       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:47.523520       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:55:47.523527       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:47.523534       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:55:47.523553       1 session.go:361] Session dd137064-f969-45a0-b9d6-37be453883ae operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:55:47.523557       1 session.go:375] Close Session dd137064-f969-45a0-b9d6-37be453883ae
I0904 11:55:47.523564       1 scheduler.go:133] End scheduling ...
I0904 11:55:57.467879       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:55:57.523919       1 scheduler.go:106] Start scheduling ...
I0904 11:55:57.524050       1 node_info.go:227] imageStates is map[]
I0904 11:55:57.524108       1 node_info.go:227] imageStates is map[]
I0904 11:55:57.524123       1 node_info.go:227] imageStates is map[]
I0904 11:55:57.524141       1 node_info.go:227] imageStates is map[]
I0904 11:55:57.524156       1 node_info.go:227] imageStates is map[]
I0904 11:55:57.524189       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:55:57.524249       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:55:57.524265       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:55:57.524281       1 session.go:230] Open Session dc7b7aa2-c159-4c03-a7c3-d5794f6e418c with <1> Job and <5> Queues
I0904 11:55:57.524314       1 session.go:233] Session dc7b7aa2-c159-4c03-a7c3-d5794f6e418c operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:55:57.524510       1 sla.go:85] Enter sla plugin ...
I0904 11:55:57.524535       1 sla.go:154] Leaving sla plugin.
I0904 11:55:57.524541       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:55:57.524560       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:55:57.524567       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00
I0904 11:55:57.524633       1 factory.go:59] Register preBinder predicates successfully
I0904 11:55:57.524663       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
I0904 11:55:57.524693       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:55:57.524723       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:55:57.524769       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:55:57.524780       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:55:57.524801       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:55:57.524815       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:55:57.524832       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:55:57.524843       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:55:57.524863       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:55:57.524886       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:55:57.524907       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:55:57.524926       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:55:57.524940       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:55:57.524978       1 binpack.go:165] Enter binpack plugin ...
I0904 11:55:57.524984       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:55:57.524993       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:55:57.524999       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:55:57.525003       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:55:57.525011       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:57.525022       1 allocate.go:62] Enter Allocate ...
I0904 11:55:57.525026       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:57.525034       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:55:57.525039       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:55:57.525044       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:55:57.525048       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:55:57.525051       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:55:57.525055       1 allocate.go:83] Leaving Allocate ...
I0904 11:55:57.525059       1 backfill.go:59] Enter Backfill ...
I0904 11:55:57.525063       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:57.525070       1 backfill.go:110] Leaving Backfill ...
I0904 11:55:57.525074       1 reclaim.go:47] Enter Reclaim ...
I0904 11:55:57.525078       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:55:57.525081       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:57.525089       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:55:57.525097       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:55:57.525101       1 preempt.go:103] Enter Preempt ...
I0904 11:55:57.525104       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:55:57.525111       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:55:57.525117       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:55:57.525129       1 preempt.go:270] Leaving Preempt ...
I0904 11:55:57.525217       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:57.525235       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:55:57.525268       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:55:57.525273       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:55:57.525282       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:55:57.525289       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:57.525299       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:55:57.525334       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:55:57.525354       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:55:57.525362       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:55:57.525370       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:55:57.525384       1 session.go:361] Session dc7b7aa2-c159-4c03-a7c3-d5794f6e418c operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:55:57.525390       1 session.go:375] Close Session dc7b7aa2-c159-4c03-a7c3-d5794f6e418c
I0904 11:55:57.525397       1 scheduler.go:133] End scheduling ...
I0904 11:56:07.525887       1 scheduler.go:106] Start scheduling ...
I0904 11:56:07.526171       1 node_info.go:227] imageStates is map[]
I0904 11:56:07.526256       1 node_info.go:227] imageStates is map[]
I0904 11:56:07.526295       1 node_info.go:227] imageStates is map[]
I0904 11:56:07.526421       1 node_info.go:227] imageStates is map[]
I0904 11:56:07.526465       1 node_info.go:227] imageStates is map[]
I0904 11:56:07.526576       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:56:07.526673       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:56:07.526710       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:56:07.526742       1 session.go:230] Open Session c13b28ed-0f3f-4134-afc4-390eb898f324 with <1> Job and <5> Queues
I0904 11:56:07.526857       1 session.go:233] Session c13b28ed-0f3f-4134-afc4-390eb898f324 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:56:07.527227       1 sla.go:85] Enter sla plugin ...
I0904 11:56:07.527317       1 sla.go:154] Leaving sla plugin.
I0904 11:56:07.527338       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:56:07.527381       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:56:07.527399       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00
I0904 11:56:07.527534       1 factory.go:59] Register preBinder predicates successfully
I0904 11:56:07.527551       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 11:56:07.527613       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:56:07.527671       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:56:07.527808       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:56:07.527837       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:56:07.527984       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:56:07.528033       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:56:07.528124       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:56:07.528215       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:56:07.528250       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:56:07.528296       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:56:07.528341       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:56:07.528373       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:56:07.528415       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:56:07.528520       1 binpack.go:165] Enter binpack plugin ...
I0904 11:56:07.528533       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:56:07.528549       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:56:07.528563       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:56:07.528574       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:56:07.528592       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:07.528618       1 allocate.go:62] Enter Allocate ...
I0904 11:56:07.528627       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:07.528645       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:56:07.528656       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:56:07.528667       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:56:07.528676       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:56:07.528687       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:56:07.528699       1 allocate.go:83] Leaving Allocate ...
I0904 11:56:07.528714       1 backfill.go:59] Enter Backfill ...
I0904 11:56:07.528726       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:07.528746       1 backfill.go:110] Leaving Backfill ...
I0904 11:56:07.528760       1 reclaim.go:47] Enter Reclaim ...
I0904 11:56:07.528935       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:56:07.528978       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:07.529015       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:56:07.529038       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:56:07.529055       1 preempt.go:103] Enter Preempt ...
I0904 11:56:07.529066       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:07.529100       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:56:07.529117       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:56:07.529129       1 preempt.go:270] Leaving Preempt ...
I0904 11:56:07.529574       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:56:07.529740       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:56:07.529777       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:07.529810       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:56:07.529832       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:07.529861       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:56:07.529964       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:56:07.530004       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:56:07.530032       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:07.530056       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:56:07.530262       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:56:07.530368       1 session.go:361] Session c13b28ed-0f3f-4134-afc4-390eb898f324 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:56:07.530389       1 session.go:375] Close Session c13b28ed-0f3f-4134-afc4-390eb898f324
I0904 11:56:07.530411       1 scheduler.go:133] End scheduling ...
I0904 11:56:17.531155       1 scheduler.go:106] Start scheduling ...
I0904 11:56:17.531283       1 node_info.go:227] imageStates is map[]
I0904 11:56:17.531318       1 node_info.go:227] imageStates is map[]
I0904 11:56:17.531330       1 node_info.go:227] imageStates is map[]
I0904 11:56:17.531346       1 node_info.go:227] imageStates is map[]
I0904 11:56:17.531357       1 node_info.go:227] imageStates is map[]
I0904 11:56:17.531389       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:56:17.531422       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:56:17.531437       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:56:17.531451       1 session.go:230] Open Session ebda3fa3-6b03-4bd8-b755-83b7dce8af00 with <1> Job and <5> Queues
I0904 11:56:17.531467       1 session.go:233] Session ebda3fa3-6b03-4bd8-b755-83b7dce8af00 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:56:17.531695       1 sla.go:85] Enter sla plugin ...
I0904 11:56:17.531721       1 sla.go:154] Leaving sla plugin.
I0904 11:56:17.531727       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:56:17.531743       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:56:17.531749       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 11:56:17.531804       1 factory.go:59] Register preBinder predicates successfully
I0904 11:56:17.531811       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 11:56:17.531835       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:56:17.531857       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:56:17.531892       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:56:17.531901       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:56:17.531917       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:56:17.531946       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:56:17.531960       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:56:17.531970       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:56:17.531982       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:56:17.532001       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:56:17.532013       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:56:17.532031       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:56:17.532044       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:56:17.532076       1 binpack.go:165] Enter binpack plugin ...
I0904 11:56:17.532079       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:56:17.532085       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:56:17.532090       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:56:17.532093       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:56:17.532100       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:17.532113       1 allocate.go:62] Enter Allocate ...
I0904 11:56:17.532118       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:17.532125       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:56:17.532142       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:56:17.532147       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:56:17.532150       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:56:17.532153       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:56:17.532156       1 allocate.go:83] Leaving Allocate ...
I0904 11:56:17.532160       1 backfill.go:59] Enter Backfill ...
I0904 11:56:17.532164       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:17.532169       1 backfill.go:110] Leaving Backfill ...
I0904 11:56:17.532173       1 reclaim.go:47] Enter Reclaim ...
I0904 11:56:17.532176       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:56:17.532179       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:17.532184       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:56:17.532191       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:56:17.532195       1 preempt.go:103] Enter Preempt ...
I0904 11:56:17.532198       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:17.532202       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:56:17.532207       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:56:17.532211       1 preempt.go:270] Leaving Preempt ...
I0904 11:56:17.532275       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:56:17.532288       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:56:17.532294       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:17.532302       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:56:17.532307       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:17.532316       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:56:17.532321       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:56:17.532327       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:56:17.532333       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:17.532340       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:56:17.532378       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:56:17.532388       1 session.go:361] Session ebda3fa3-6b03-4bd8-b755-83b7dce8af00 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:56:17.532392       1 session.go:375] Close Session ebda3fa3-6b03-4bd8-b755-83b7dce8af00
I0904 11:56:17.532397       1 scheduler.go:133] End scheduling ...
I0904 11:56:27.468238       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:56:27.533215       1 scheduler.go:106] Start scheduling ...
I0904 11:56:27.533312       1 node_info.go:227] imageStates is map[]
I0904 11:56:27.533381       1 node_info.go:227] imageStates is map[]
I0904 11:56:27.533401       1 node_info.go:227] imageStates is map[]
I0904 11:56:27.533412       1 node_info.go:227] imageStates is map[]
I0904 11:56:27.533424       1 node_info.go:227] imageStates is map[]
I0904 11:56:27.533450       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:56:27.533494       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:56:27.533518       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:56:27.533529       1 session.go:230] Open Session 169b94b3-20d9-4a24-97fa-2eba3f80cd0c with <1> Job and <5> Queues
I0904 11:56:27.533541       1 session.go:233] Session 169b94b3-20d9-4a24-97fa-2eba3f80cd0c operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:56:27.533735       1 sla.go:85] Enter sla plugin ...
I0904 11:56:27.533757       1 sla.go:154] Leaving sla plugin.
I0904 11:56:27.533762       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:56:27.533777       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:56:27.533784       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00
I0904 11:56:27.533839       1 factory.go:59] Register preBinder predicates successfully
I0904 11:56:27.533846       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 11:56:27.533890       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:56:27.533950       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:56:27.533973       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:56:27.533984       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:56:27.534003       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:56:27.534013       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:56:27.534021       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:56:27.534034       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:56:27.534049       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:56:27.534068       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:56:27.534108       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:56:27.534119       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:56:27.534131       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:56:27.534176       1 binpack.go:165] Enter binpack plugin ...
I0904 11:56:27.534180       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:56:27.534186       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:56:27.534191       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:56:27.534194       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:56:27.534201       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:27.534224       1 allocate.go:62] Enter Allocate ...
I0904 11:56:27.534227       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:27.534235       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:56:27.534238       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:56:27.534243       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:56:27.534245       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:56:27.534248       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:56:27.534251       1 allocate.go:83] Leaving Allocate ...
I0904 11:56:27.534255       1 backfill.go:59] Enter Backfill ...
I0904 11:56:27.534258       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:27.534262       1 backfill.go:110] Leaving Backfill ...
I0904 11:56:27.534267       1 reclaim.go:47] Enter Reclaim ...
I0904 11:56:27.534270       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:56:27.534272       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:27.534277       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:56:27.534283       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:56:27.534286       1 preempt.go:103] Enter Preempt ...
I0904 11:56:27.534289       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:27.534293       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:56:27.534297       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:56:27.534301       1 preempt.go:270] Leaving Preempt ...
I0904 11:56:27.534375       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:27.534387       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:56:27.534409       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:56:27.534413       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:56:27.534419       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:56:27.534424       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:27.534431       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:56:27.534436       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:27.534443       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:56:27.534451       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:56:27.534456       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:56:27.534467       1 session.go:361] Session 169b94b3-20d9-4a24-97fa-2eba3f80cd0c operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:56:27.534485       1 session.go:375] Close Session 169b94b3-20d9-4a24-97fa-2eba3f80cd0c
I0904 11:56:27.534491       1 scheduler.go:133] End scheduling ...
I0904 11:56:37.535048       1 scheduler.go:106] Start scheduling ...
I0904 11:56:37.535133       1 node_info.go:227] imageStates is map[]
I0904 11:56:37.535179       1 node_info.go:227] imageStates is map[]
I0904 11:56:37.535194       1 node_info.go:227] imageStates is map[]
I0904 11:56:37.535204       1 node_info.go:227] imageStates is map[]
I0904 11:56:37.535214       1 node_info.go:227] imageStates is map[]
I0904 11:56:37.535237       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:56:37.535274       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:56:37.535286       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:56:37.535296       1 session.go:230] Open Session 5733d103-83e7-4931-a6c2-9a3e3488a46a with <1> Job and <5> Queues
I0904 11:56:37.535316       1 session.go:233] Session 5733d103-83e7-4931-a6c2-9a3e3488a46a operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:56:37.535437       1 sla.go:85] Enter sla plugin ...
I0904 11:56:37.535452       1 sla.go:154] Leaving sla plugin.
I0904 11:56:37.535457       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:56:37.535467       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:56:37.535473       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00
I0904 11:56:37.535519       1 factory.go:59] Register preBinder predicates successfully
I0904 11:56:37.535524       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
I0904 11:56:37.535545       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:56:37.535561       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:56:37.535587       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:56:37.535604       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:56:37.535615       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:56:37.535624       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:56:37.535646       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:56:37.535656       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:56:37.535668       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:56:37.535682       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:56:37.535694       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:56:37.535705       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:56:37.535712       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:56:37.535744       1 binpack.go:165] Enter binpack plugin ...
I0904 11:56:37.535758       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:56:37.535762       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:56:37.535767       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:56:37.535770       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:56:37.535775       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:37.535783       1 allocate.go:62] Enter Allocate ...
I0904 11:56:37.535787       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:37.535792       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:56:37.535795       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:56:37.535798       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:56:37.535800       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:56:37.535803       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:56:37.535805       1 allocate.go:83] Leaving Allocate ...
I0904 11:56:37.535808       1 backfill.go:59] Enter Backfill ...
I0904 11:56:37.535811       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:37.535815       1 backfill.go:110] Leaving Backfill ...
I0904 11:56:37.535820       1 reclaim.go:47] Enter Reclaim ...
I0904 11:56:37.535823       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:56:37.535825       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:37.535829       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:56:37.535835       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:56:37.535849       1 preempt.go:103] Enter Preempt ...
I0904 11:56:37.535852       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:37.535856       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:56:37.535860       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:56:37.535864       1 preempt.go:270] Leaving Preempt ...
I0904 11:56:37.535923       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:56:37.535944       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:56:37.535949       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:37.535955       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:56:37.535960       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:37.535966       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:56:37.535970       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:56:37.535975       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:56:37.535979       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:37.535983       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:56:37.535999       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:56:37.536006       1 session.go:361] Session 5733d103-83e7-4931-a6c2-9a3e3488a46a operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:56:37.536010       1 session.go:375] Close Session 5733d103-83e7-4931-a6c2-9a3e3488a46a
I0904 11:56:37.536014       1 scheduler.go:133] End scheduling ...
I0904 11:56:46.366828       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ResourceQuota" totalItems=7
I0904 11:56:47.536495       1 scheduler.go:106] Start scheduling ...
I0904 11:56:47.536578       1 node_info.go:227] imageStates is map[]
I0904 11:56:47.536627       1 node_info.go:227] imageStates is map[]
I0904 11:56:47.536644       1 node_info.go:227] imageStates is map[]
I0904 11:56:47.536656       1 node_info.go:227] imageStates is map[]
I0904 11:56:47.536667       1 node_info.go:227] imageStates is map[]
I0904 11:56:47.536698       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:56:47.536728       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:56:47.536750       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:56:47.536760       1 session.go:230] Open Session ca87da5f-9d5e-473d-bad6-0ddeb593f4a5 with <1> Job and <5> Queues
I0904 11:56:47.536771       1 session.go:233] Session ca87da5f-9d5e-473d-bad6-0ddeb593f4a5 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:56:47.536902       1 sla.go:85] Enter sla plugin ...
I0904 11:56:47.536920       1 sla.go:154] Leaving sla plugin.
I0904 11:56:47.536925       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:56:47.536937       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:56:47.536942       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 11:56:47.536994       1 factory.go:59] Register preBinder predicates successfully
I0904 11:56:47.537012       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>
I0904 11:56:47.537033       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:56:47.537050       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:56:47.537080       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:56:47.537098       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:56:47.537113       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:56:47.537124       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:56:47.537133       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:56:47.537140       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:56:47.537149       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:56:47.537163       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:56:47.537184       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:56:47.537195       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:56:47.537207       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:56:47.537237       1 binpack.go:165] Enter binpack plugin ...
I0904 11:56:47.537242       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:56:47.537247       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:56:47.537252       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:56:47.537257       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:56:47.537263       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:47.537283       1 allocate.go:62] Enter Allocate ...
I0904 11:56:47.537286       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:47.537292       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:56:47.537296       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:56:47.537300       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:56:47.537302       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:56:47.537305       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:56:47.537307       1 allocate.go:83] Leaving Allocate ...
I0904 11:56:47.537311       1 backfill.go:59] Enter Backfill ...
I0904 11:56:47.537314       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:47.537318       1 backfill.go:110] Leaving Backfill ...
I0904 11:56:47.537322       1 reclaim.go:47] Enter Reclaim ...
I0904 11:56:47.537325       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:56:47.537327       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:47.537332       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:56:47.537338       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:56:47.537341       1 preempt.go:103] Enter Preempt ...
I0904 11:56:47.537344       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:47.537350       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:56:47.537355       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:56:47.537360       1 preempt.go:270] Leaving Preempt ...
I0904 11:56:47.537428       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:47.537455       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:56:47.537461       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:56:47.537467       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:56:47.537471       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:47.537477       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:56:47.537494       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:56:47.537497       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:56:47.537502       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:56:47.537505       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:47.537512       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:56:47.537521       1 session.go:361] Session ca87da5f-9d5e-473d-bad6-0ddeb593f4a5 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:56:47.537525       1 session.go:375] Close Session ca87da5f-9d5e-473d-bad6-0ddeb593f4a5
I0904 11:56:47.537530       1 scheduler.go:133] End scheduling ...
I0904 11:56:57.469331       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:56:57.538722       1 scheduler.go:106] Start scheduling ...
I0904 11:56:57.538889       1 node_info.go:227] imageStates is map[]
I0904 11:56:57.538962       1 node_info.go:227] imageStates is map[]
I0904 11:56:57.538997       1 node_info.go:227] imageStates is map[]
I0904 11:56:57.539019       1 node_info.go:227] imageStates is map[]
I0904 11:56:57.539042       1 node_info.go:227] imageStates is map[]
I0904 11:56:57.539073       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:56:57.539126       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:56:57.539150       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:56:57.539214       1 session.go:230] Open Session d9a014f4-353f-4c83-9023-d2aa274c487c with <1> Job and <5> Queues
I0904 11:56:57.539241       1 session.go:233] Session d9a014f4-353f-4c83-9023-d2aa274c487c operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:56:57.539522       1 sla.go:85] Enter sla plugin ...
I0904 11:56:57.539573       1 sla.go:154] Leaving sla plugin.
I0904 11:56:57.539583       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:56:57.539608       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:56:57.539618       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 11:56:57.539701       1 factory.go:59] Register preBinder predicates successfully
I0904 11:56:57.539712       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>
I0904 11:56:57.539752       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:56:57.539788       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:56:57.539832       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:56:57.539875       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:56:57.539931       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:56:57.539992       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:56:57.540041       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:56:57.540060       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:56:57.540090       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:56:57.540208       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:56:57.540233       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:56:57.540258       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:56:57.540287       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:56:57.540365       1 binpack.go:165] Enter binpack plugin ...
I0904 11:56:57.540374       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:56:57.540385       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:56:57.540399       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:56:57.540405       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:56:57.540416       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:57.540433       1 allocate.go:62] Enter Allocate ...
I0904 11:56:57.540440       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:57.540451       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:56:57.540458       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:56:57.540494       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:56:57.540499       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:56:57.540505       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:56:57.540539       1 allocate.go:83] Leaving Allocate ...
I0904 11:56:57.540546       1 backfill.go:59] Enter Backfill ...
I0904 11:56:57.540552       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:57.540588       1 backfill.go:110] Leaving Backfill ...
I0904 11:56:57.540595       1 reclaim.go:47] Enter Reclaim ...
I0904 11:56:57.540600       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:56:57.540606       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:57.540616       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:56:57.540652       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:56:57.540658       1 preempt.go:103] Enter Preempt ...
I0904 11:56:57.540664       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:56:57.540673       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:56:57.540682       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:56:57.540690       1 preempt.go:270] Leaving Preempt ...
I0904 11:56:57.540812       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:56:57.540865       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:56:57.540876       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:57.540891       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:56:57.540902       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:57.540918       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:56:57.540934       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:56:57.540945       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:56:57.540958       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:56:57.540971       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:56:57.541034       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:56:57.541051       1 session.go:361] Session d9a014f4-353f-4c83-9023-d2aa274c487c operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:56:57.541059       1 session.go:375] Close Session d9a014f4-353f-4c83-9023-d2aa274c487c
I0904 11:56:57.541068       1 scheduler.go:133] End scheduling ...
I0904 11:56:58.367233       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PriorityClass" totalItems=6
I0904 11:57:07.541511       1 scheduler.go:106] Start scheduling ...
I0904 11:57:07.541604       1 node_info.go:227] imageStates is map[]
I0904 11:57:07.541637       1 node_info.go:227] imageStates is map[]
I0904 11:57:07.541652       1 node_info.go:227] imageStates is map[]
I0904 11:57:07.541663       1 node_info.go:227] imageStates is map[]
I0904 11:57:07.541701       1 node_info.go:227] imageStates is map[]
I0904 11:57:07.541736       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:57:07.541780       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:57:07.541806       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:57:07.541818       1 session.go:230] Open Session 4fc9a8f4-1ce4-4c57-a0fa-f5e8ae59c92f with <1> Job and <5> Queues
I0904 11:57:07.541831       1 session.go:233] Session 4fc9a8f4-1ce4-4c57-a0fa-f5e8ae59c92f operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:57:07.541985       1 sla.go:85] Enter sla plugin ...
I0904 11:57:07.542006       1 sla.go:154] Leaving sla plugin.
I0904 11:57:07.542013       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:57:07.542027       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:57:07.542034       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 11:57:07.542103       1 factory.go:59] Register preBinder predicates successfully
I0904 11:57:07.542110       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>
I0904 11:57:07.542135       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:57:07.542173       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:57:07.542194       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:57:07.542214       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:57:07.542230       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:57:07.542239       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:57:07.542252       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:57:07.542264       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:57:07.542279       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:57:07.542307       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:57:07.542320       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:57:07.542333       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:57:07.542343       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:57:07.542375       1 binpack.go:165] Enter binpack plugin ...
I0904 11:57:07.542379       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:57:07.542384       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:57:07.542390       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:57:07.542393       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:57:07.542400       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:07.542421       1 allocate.go:62] Enter Allocate ...
I0904 11:57:07.542424       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:07.542431       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:57:07.542434       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:57:07.542438       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:57:07.542442       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:57:07.542445       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:57:07.542448       1 allocate.go:83] Leaving Allocate ...
I0904 11:57:07.542452       1 backfill.go:59] Enter Backfill ...
I0904 11:57:07.542455       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:07.542461       1 backfill.go:110] Leaving Backfill ...
I0904 11:57:07.542468       1 reclaim.go:47] Enter Reclaim ...
I0904 11:57:07.542471       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:57:07.542474       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:07.542479       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:57:07.542485       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:57:07.542489       1 preempt.go:103] Enter Preempt ...
I0904 11:57:07.542491       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:07.542496       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:57:07.542501       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:57:07.542504       1 preempt.go:270] Leaving Preempt ...
I0904 11:57:07.542573       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:07.542600       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:57:07.542607       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:57:07.542614       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:57:07.542618       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:07.542627       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:57:07.542661       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:57:07.542664       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:57:07.542671       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:57:07.542692       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:07.542701       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:57:07.542723       1 session.go:361] Session 4fc9a8f4-1ce4-4c57-a0fa-f5e8ae59c92f operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:57:07.542727       1 session.go:375] Close Session 4fc9a8f4-1ce4-4c57-a0fa-f5e8ae59c92f
I0904 11:57:07.542732       1 scheduler.go:133] End scheduling ...
I0904 11:57:09.370403       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Node" totalItems=10
I0904 11:57:17.543891       1 scheduler.go:106] Start scheduling ...
I0904 11:57:17.544499       1 node_info.go:227] imageStates is map[]
I0904 11:57:17.544621       1 node_info.go:227] imageStates is map[]
I0904 11:57:17.544704       1 node_info.go:227] imageStates is map[]
I0904 11:57:17.544748       1 node_info.go:227] imageStates is map[]
I0904 11:57:17.544846       1 node_info.go:227] imageStates is map[]
I0904 11:57:17.544979       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:57:17.545074       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:57:17.545185       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:57:17.545217       1 session.go:230] Open Session 33a23551-5e1a-46a4-a53a-6f43eec5c0fa with <1> Job and <5> Queues
I0904 11:57:17.545261       1 session.go:233] Session 33a23551-5e1a-46a4-a53a-6f43eec5c0fa operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:57:17.545721       1 sla.go:85] Enter sla plugin ...
I0904 11:57:17.545784       1 sla.go:154] Leaving sla plugin.
I0904 11:57:17.545798       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:57:17.545835       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:57:17.545849       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00
I0904 11:57:17.545983       1 factory.go:59] Register preBinder predicates successfully
I0904 11:57:17.546002       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 11:57:17.546067       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:57:17.546292       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:57:17.546360       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:57:17.546385       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:57:17.546458       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:57:17.546503       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:57:17.546530       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:57:17.546566       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:57:17.546617       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:57:17.546659       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:57:17.546704       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:57:17.546746       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:57:17.546835       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:57:17.546970       1 binpack.go:165] Enter binpack plugin ...
I0904 11:57:17.546985       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:57:17.547000       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:57:17.547014       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:57:17.547021       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:57:17.547039       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:17.547066       1 allocate.go:62] Enter Allocate ...
I0904 11:57:17.547076       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:17.547092       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:57:17.547112       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:57:17.547123       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:57:17.547132       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:57:17.547140       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:57:17.547148       1 allocate.go:83] Leaving Allocate ...
I0904 11:57:17.547158       1 backfill.go:59] Enter Backfill ...
I0904 11:57:17.547167       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:17.547182       1 backfill.go:110] Leaving Backfill ...
I0904 11:57:17.547191       1 reclaim.go:47] Enter Reclaim ...
I0904 11:57:17.547199       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:57:17.547207       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:17.547220       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:57:17.547234       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:57:17.547243       1 preempt.go:103] Enter Preempt ...
I0904 11:57:17.547251       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:17.547263       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:57:17.547279       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:57:17.547289       1 preempt.go:270] Leaving Preempt ...
I0904 11:57:17.547488       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:57:17.547562       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:57:17.547577       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:17.547598       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:57:17.547754       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:57:17.547771       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:57:17.547792       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:57:17.547808       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:17.547833       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:57:17.547849       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:17.547877       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:57:17.547914       1 session.go:361] Session 33a23551-5e1a-46a4-a53a-6f43eec5c0fa operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:57:17.547926       1 session.go:375] Close Session 33a23551-5e1a-46a4-a53a-6f43eec5c0fa
I0904 11:57:17.547940       1 scheduler.go:133] End scheduling ...
I0904 11:57:27.470321       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:57:27.548197       1 scheduler.go:106] Start scheduling ...
I0904 11:57:27.548412       1 node_info.go:227] imageStates is map[]
I0904 11:57:27.548477       1 node_info.go:227] imageStates is map[]
I0904 11:57:27.548510       1 node_info.go:227] imageStates is map[]
I0904 11:57:27.548530       1 node_info.go:227] imageStates is map[]
I0904 11:57:27.548549       1 node_info.go:227] imageStates is map[]
I0904 11:57:27.548579       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:57:27.548754       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:57:27.548790       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:57:27.548806       1 session.go:230] Open Session f481dae7-6919-4e68-a355-d85e08f2f155 with <1> Job and <5> Queues
I0904 11:57:27.548825       1 session.go:233] Session f481dae7-6919-4e68-a355-d85e08f2f155 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:57:27.549006       1 sla.go:85] Enter sla plugin ...
I0904 11:57:27.549030       1 sla.go:154] Leaving sla plugin.
I0904 11:57:27.549038       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:57:27.549056       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:57:27.549064       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00
I0904 11:57:27.549129       1 factory.go:59] Register preBinder predicates successfully
I0904 11:57:27.549153       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 11:57:27.549187       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:57:27.549233       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:57:27.549261       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:57:27.549271       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:57:27.549291       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:57:27.549312       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:57:27.549344       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:57:27.549373       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:57:27.549424       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:57:27.549450       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:57:27.549464       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:57:27.549479       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:57:27.549497       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:57:27.549535       1 binpack.go:165] Enter binpack plugin ...
I0904 11:57:27.549541       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:57:27.549549       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:57:27.549556       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:57:27.549575       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:57:27.549585       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:27.549597       1 allocate.go:62] Enter Allocate ...
I0904 11:57:27.549601       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:27.549609       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:57:27.549614       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:57:27.549619       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:57:27.549623       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:57:27.549627       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:57:27.549631       1 allocate.go:83] Leaving Allocate ...
I0904 11:57:27.549635       1 backfill.go:59] Enter Backfill ...
I0904 11:57:27.549640       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:27.549646       1 backfill.go:110] Leaving Backfill ...
I0904 11:57:27.549651       1 reclaim.go:47] Enter Reclaim ...
I0904 11:57:27.549654       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:57:27.549658       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:27.549665       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:57:27.549674       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:57:27.549679       1 preempt.go:103] Enter Preempt ...
I0904 11:57:27.549683       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:27.549704       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:57:27.549711       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:57:27.549716       1 preempt.go:270] Leaving Preempt ...
I0904 11:57:27.549802       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:27.549837       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:57:27.549846       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:27.549858       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:57:27.549865       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:57:27.549873       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:57:27.549881       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:27.549890       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:57:27.549916       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:57:27.549920       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:57:27.549928       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:57:27.549940       1 session.go:361] Session f481dae7-6919-4e68-a355-d85e08f2f155 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:57:27.549946       1 session.go:375] Close Session f481dae7-6919-4e68-a355-d85e08f2f155
I0904 11:57:27.549952       1 scheduler.go:133] End scheduling ...
I0904 11:57:37.550267       1 scheduler.go:106] Start scheduling ...
I0904 11:57:37.550408       1 node_info.go:227] imageStates is map[]
I0904 11:57:37.550442       1 node_info.go:227] imageStates is map[]
I0904 11:57:37.550493       1 node_info.go:227] imageStates is map[]
I0904 11:57:37.550543       1 node_info.go:227] imageStates is map[]
I0904 11:57:37.550594       1 node_info.go:227] imageStates is map[]
I0904 11:57:37.550665       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:57:37.550756       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:57:37.550799       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:57:37.550814       1 session.go:230] Open Session 363e213c-c9f5-46c8-b8f2-311b9eb5be23 with <1> Job and <5> Queues
I0904 11:57:37.550857       1 session.go:233] Session 363e213c-c9f5-46c8-b8f2-311b9eb5be23 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:57:37.551102       1 sla.go:85] Enter sla plugin ...
I0904 11:57:37.551144       1 sla.go:154] Leaving sla plugin.
I0904 11:57:37.551152       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:57:37.551169       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:57:37.551205       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00
I0904 11:57:37.551324       1 factory.go:59] Register preBinder predicates successfully
I0904 11:57:37.551360       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>
I0904 11:57:37.551391       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:57:37.551449       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:57:37.551504       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:57:37.551543       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:57:37.551587       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:57:37.551633       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:57:37.551702       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:57:37.551721       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:57:37.551763       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:57:37.551793       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:57:37.551807       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:57:37.551862       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:57:37.551908       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:57:37.552047       1 binpack.go:165] Enter binpack plugin ...
I0904 11:57:37.552126       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:57:37.552146       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:57:37.552224       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:57:37.552238       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:57:37.552255       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:37.552340       1 allocate.go:62] Enter Allocate ...
I0904 11:57:37.552356       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:37.552439       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:57:37.552456       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:57:37.552528       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:57:37.552607       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:57:37.552681       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:57:37.552695       1 allocate.go:83] Leaving Allocate ...
I0904 11:57:37.552707       1 backfill.go:59] Enter Backfill ...
I0904 11:57:37.552781       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:37.552805       1 backfill.go:110] Leaving Backfill ...
I0904 11:57:37.552877       1 reclaim.go:47] Enter Reclaim ...
I0904 11:57:37.552890       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:57:37.552903       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:37.552919       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:57:37.552936       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:57:37.552945       1 preempt.go:103] Enter Preempt ...
I0904 11:57:37.552953       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:37.552965       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:57:37.552977       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:57:37.552987       1 preempt.go:270] Leaving Preempt ...
I0904 11:57:37.553324       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:57:37.553392       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:57:37.553406       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:37.553422       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:57:37.553427       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:37.553433       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:57:37.553459       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:57:37.553477       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:57:37.553481       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:37.553498       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:57:37.553516       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:57:37.553525       1 session.go:361] Session 363e213c-c9f5-46c8-b8f2-311b9eb5be23 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:57:37.553529       1 session.go:375] Close Session 363e213c-c9f5-46c8-b8f2-311b9eb5be23
I0904 11:57:37.553534       1 scheduler.go:133] End scheduling ...
I0904 11:57:40.531455       1 cache.go:1179] started sync node integration-control-plane
I0904 11:57:40.531482       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:57:40.531567       1 node_info.go:227] imageStates is map[]
I0904 11:57:45.364350       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSINode" totalItems=7
I0904 11:57:47.554148       1 scheduler.go:106] Start scheduling ...
I0904 11:57:47.554256       1 node_info.go:227] imageStates is map[]
I0904 11:57:47.554282       1 node_info.go:227] imageStates is map[]
I0904 11:57:47.554313       1 node_info.go:227] imageStates is map[]
I0904 11:57:47.554338       1 node_info.go:227] imageStates is map[]
I0904 11:57:47.554358       1 node_info.go:227] imageStates is map[]
I0904 11:57:47.554381       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:57:47.554421       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:57:47.554442       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:57:47.554461       1 session.go:230] Open Session be91bcb8-43e7-4d74-8140-e8f6069e67a9 with <1> Job and <5> Queues
I0904 11:57:47.554480       1 session.go:233] Session be91bcb8-43e7-4d74-8140-e8f6069e67a9 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:57:47.554607       1 sla.go:85] Enter sla plugin ...
I0904 11:57:47.554619       1 sla.go:154] Leaving sla plugin.
I0904 11:57:47.554624       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:57:47.554635       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:57:47.554640       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 11:57:47.554684       1 factory.go:59] Register preBinder predicates successfully
I0904 11:57:47.554689       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 11:57:47.554708       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:57:47.554724       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:57:47.554739       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:57:47.554746       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:57:47.554758       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:57:47.554766       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:57:47.554772       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:57:47.554782       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:57:47.554793       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:57:47.554821       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:57:47.554831       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:57:47.554850       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:57:47.554871       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:57:47.554896       1 binpack.go:165] Enter binpack plugin ...
I0904 11:57:47.554899       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:57:47.554904       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:57:47.554909       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:57:47.554911       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:57:47.554916       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:47.554924       1 allocate.go:62] Enter Allocate ...
I0904 11:57:47.554927       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:47.554932       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:57:47.554936       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:57:47.554939       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:57:47.554941       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:57:47.554944       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:57:47.554946       1 allocate.go:83] Leaving Allocate ...
I0904 11:57:47.554949       1 backfill.go:59] Enter Backfill ...
I0904 11:57:47.554953       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:47.554957       1 backfill.go:110] Leaving Backfill ...
I0904 11:57:47.554959       1 reclaim.go:47] Enter Reclaim ...
I0904 11:57:47.554963       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:57:47.554995       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:47.555015       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:57:47.555020       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:57:47.555024       1 preempt.go:103] Enter Preempt ...
I0904 11:57:47.555026       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:47.555030       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:57:47.555033       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:57:47.555036       1 preempt.go:270] Leaving Preempt ...
I0904 11:57:47.555105       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:57:47.555116       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:57:47.555120       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:47.555126       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:57:47.555130       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:47.555136       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:57:47.555140       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:57:47.555144       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:57:47.555148       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:47.555153       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:57:47.555168       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:57:47.555176       1 session.go:361] Session be91bcb8-43e7-4d74-8140-e8f6069e67a9 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:57:47.555179       1 session.go:375] Close Session be91bcb8-43e7-4d74-8140-e8f6069e67a9
I0904 11:57:47.555182       1 scheduler.go:133] End scheduling ...
I0904 11:57:50.574457       1 cache.go:1179] started sync node integration-control-plane
I0904 11:57:50.574487       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 11:57:50.574561       1 node_info.go:227] imageStates is map[]
I0904 11:57:57.471200       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:57:57.556135       1 scheduler.go:106] Start scheduling ...
I0904 11:57:57.556288       1 node_info.go:227] imageStates is map[]
I0904 11:57:57.556348       1 node_info.go:227] imageStates is map[]
I0904 11:57:57.556367       1 node_info.go:227] imageStates is map[]
I0904 11:57:57.556390       1 node_info.go:227] imageStates is map[]
I0904 11:57:57.556405       1 node_info.go:227] imageStates is map[]
I0904 11:57:57.556436       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:57:57.556475       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:57:57.556493       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:57:57.556523       1 session.go:230] Open Session 082448f9-05d5-48fe-b4c4-e2d4cf8bb4dc with <1> Job and <5> Queues
I0904 11:57:57.556541       1 session.go:233] Session 082448f9-05d5-48fe-b4c4-e2d4cf8bb4dc operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:57:57.556751       1 sla.go:85] Enter sla plugin ...
I0904 11:57:57.556781       1 sla.go:154] Leaving sla plugin.
I0904 11:57:57.556788       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:57:57.556806       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:57:57.556814       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00
I0904 11:57:57.556877       1 factory.go:59] Register preBinder predicates successfully
I0904 11:57:57.556886       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>
I0904 11:57:57.556917       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:57:57.556946       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:57:57.556974       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:57:57.557002       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:57:57.557023       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:57:57.557040       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:57:57.557057       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:57:57.557070       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:57:57.557128       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:57:57.557154       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:57:57.557172       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:57:57.557190       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:57:57.557206       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:57:57.557250       1 binpack.go:165] Enter binpack plugin ...
I0904 11:57:57.557255       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:57:57.557262       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 11:57:57.557273       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:57:57.557295       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:57:57.557304       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:57.557315       1 allocate.go:62] Enter Allocate ...
I0904 11:57:57.557320       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:57.557328       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:57:57.557333       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:57:57.557338       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:57:57.557341       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:57:57.557345       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:57:57.557349       1 allocate.go:83] Leaving Allocate ...
I0904 11:57:57.557353       1 backfill.go:59] Enter Backfill ...
I0904 11:57:57.557357       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:57.557364       1 backfill.go:110] Leaving Backfill ...
I0904 11:57:57.557368       1 reclaim.go:47] Enter Reclaim ...
I0904 11:57:57.557371       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:57:57.557375       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:57.557381       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:57:57.557389       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:57:57.557393       1 preempt.go:103] Enter Preempt ...
I0904 11:57:57.557396       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:57:57.557402       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:57:57.557408       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:57:57.557414       1 preempt.go:270] Leaving Preempt ...
I0904 11:57:57.557499       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:57:57.557534       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:57:57.557542       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:57.557553       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:57:57.557561       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:57.557573       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:57:57.557579       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:57:57.557588       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:57:57.557595       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:57:57.557603       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:57:57.557630       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:57:57.557641       1 session.go:361] Session 082448f9-05d5-48fe-b4c4-e2d4cf8bb4dc operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:57:57.557646       1 session.go:375] Close Session 082448f9-05d5-48fe-b4c4-e2d4cf8bb4dc
I0904 11:57:57.557652       1 scheduler.go:133] End scheduling ...
I0904 11:58:07.558292       1 scheduler.go:106] Start scheduling ...
I0904 11:58:07.558516       1 node_info.go:227] imageStates is map[]
I0904 11:58:07.558588       1 node_info.go:227] imageStates is map[]
I0904 11:58:07.558617       1 node_info.go:227] imageStates is map[]
I0904 11:58:07.558647       1 node_info.go:227] imageStates is map[]
I0904 11:58:07.558671       1 node_info.go:227] imageStates is map[]
I0904 11:58:07.558726       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:58:07.558823       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:58:07.558849       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:58:07.558881       1 session.go:230] Open Session 308bd13e-3213-4330-a5c3-10896e700e83 with <1> Job and <5> Queues
I0904 11:58:07.558933       1 session.go:233] Session 308bd13e-3213-4330-a5c3-10896e700e83 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:58:07.559234       1 sla.go:85] Enter sla plugin ...
I0904 11:58:07.559276       1 sla.go:154] Leaving sla plugin.
I0904 11:58:07.559288       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:58:07.559316       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:58:07.559327       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00
I0904 11:58:07.559425       1 factory.go:59] Register preBinder predicates successfully
I0904 11:58:07.559437       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>
I0904 11:58:07.559485       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:58:07.559531       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:58:07.559576       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:58:07.559590       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:58:07.559616       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:58:07.559647       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:58:07.559673       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:58:07.559697       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:58:07.559722       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:58:07.559758       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:58:07.559786       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:58:07.559850       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:58:07.559872       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:58:07.559958       1 binpack.go:165] Enter binpack plugin ...
I0904 11:58:07.559992       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:58:07.560002       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:58:07.560011       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:58:07.560017       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:58:07.560029       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:07.560044       1 allocate.go:62] Enter Allocate ...
I0904 11:58:07.560050       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:07.560062       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:58:07.560068       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:58:07.560075       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:58:07.560081       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:58:07.560087       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:58:07.560093       1 allocate.go:83] Leaving Allocate ...
I0904 11:58:07.560100       1 backfill.go:59] Enter Backfill ...
I0904 11:58:07.560107       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:07.560185       1 backfill.go:110] Leaving Backfill ...
I0904 11:58:07.560192       1 reclaim.go:47] Enter Reclaim ...
I0904 11:58:07.560198       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:58:07.560204       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:07.560213       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:58:07.560225       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:58:07.560231       1 preempt.go:103] Enter Preempt ...
I0904 11:58:07.560237       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:07.560246       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:58:07.560257       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:58:07.560265       1 preempt.go:270] Leaving Preempt ...
I0904 11:58:07.560393       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:58:07.560443       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:58:07.560454       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:07.560471       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:58:07.560481       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:07.560498       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:58:07.560507       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:58:07.560519       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:58:07.560528       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:07.560540       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:58:07.560578       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:58:07.560594       1 session.go:361] Session 308bd13e-3213-4330-a5c3-10896e700e83 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:58:07.560606       1 session.go:375] Close Session 308bd13e-3213-4330-a5c3-10896e700e83
I0904 11:58:07.560615       1 scheduler.go:133] End scheduling ...
I0904 11:58:17.561387       1 scheduler.go:106] Start scheduling ...
I0904 11:58:17.561466       1 node_info.go:227] imageStates is map[]
I0904 11:58:17.561492       1 node_info.go:227] imageStates is map[]
I0904 11:58:17.561504       1 node_info.go:227] imageStates is map[]
I0904 11:58:17.561512       1 node_info.go:227] imageStates is map[]
I0904 11:58:17.561550       1 node_info.go:227] imageStates is map[]
I0904 11:58:17.561583       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:58:17.561608       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:58:17.561628       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:58:17.561637       1 session.go:230] Open Session 0b9d6ccc-ebb0-4519-a404-4c5846175556 with <1> Job and <5> Queues
I0904 11:58:17.561650       1 session.go:233] Session 0b9d6ccc-ebb0-4519-a404-4c5846175556 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:58:17.561784       1 sla.go:85] Enter sla plugin ...
I0904 11:58:17.561788       1 sla.go:154] Leaving sla plugin.
I0904 11:58:17.561793       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:58:17.561802       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:58:17.561807       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00
I0904 11:58:17.561854       1 factory.go:59] Register preBinder predicates successfully
I0904 11:58:17.561860       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 11:58:17.561876       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:58:17.561893       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:58:17.561911       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:58:17.561930       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:58:17.561942       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:58:17.561951       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:58:17.561957       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:58:17.561966       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:58:17.561975       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:58:17.561990       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:58:17.562007       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:58:17.562015       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:58:17.562024       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:58:17.562049       1 binpack.go:165] Enter binpack plugin ...
I0904 11:58:17.562060       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:58:17.562064       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:58:17.562069       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:58:17.562071       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:58:17.562077       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:17.562095       1 allocate.go:62] Enter Allocate ...
I0904 11:58:17.562097       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:17.562103       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:58:17.562106       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:58:17.562110       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:58:17.562122       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:58:17.562124       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:58:17.562126       1 allocate.go:83] Leaving Allocate ...
I0904 11:58:17.562129       1 backfill.go:59] Enter Backfill ...
I0904 11:58:17.562131       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:17.562136       1 backfill.go:110] Leaving Backfill ...
I0904 11:58:17.562139       1 reclaim.go:47] Enter Reclaim ...
I0904 11:58:17.562150       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:58:17.562152       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:17.562156       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:58:17.562161       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:58:17.562172       1 preempt.go:103] Enter Preempt ...
I0904 11:58:17.562174       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:17.562177       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:58:17.562180       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:58:17.562183       1 preempt.go:270] Leaving Preempt ...
I0904 11:58:17.562250       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:58:17.562269       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:58:17.562273       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:17.562280       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:58:17.562286       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:17.562292       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:58:17.562296       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:58:17.562301       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:58:17.562304       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:17.562319       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:58:17.562347       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:58:17.562353       1 session.go:361] Session 0b9d6ccc-ebb0-4519-a404-4c5846175556 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:58:17.562357       1 session.go:375] Close Session 0b9d6ccc-ebb0-4519-a404-4c5846175556
I0904 11:58:17.562361       1 scheduler.go:133] End scheduling ...
I0904 11:58:27.471637       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:58:27.563353       1 scheduler.go:106] Start scheduling ...
I0904 11:58:27.563459       1 node_info.go:227] imageStates is map[]
I0904 11:58:27.563484       1 node_info.go:227] imageStates is map[]
I0904 11:58:27.563527       1 node_info.go:227] imageStates is map[]
I0904 11:58:27.563539       1 node_info.go:227] imageStates is map[]
I0904 11:58:27.563572       1 node_info.go:227] imageStates is map[]
I0904 11:58:27.563586       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:58:27.563616       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:58:27.563649       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:58:27.563658       1 session.go:230] Open Session 506200c1-2940-4740-ba08-241b5a3ed081 with <1> Job and <5> Queues
I0904 11:58:27.563669       1 session.go:233] Session 506200c1-2940-4740-ba08-241b5a3ed081 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:58:27.563800       1 sla.go:85] Enter sla plugin ...
I0904 11:58:27.563815       1 sla.go:154] Leaving sla plugin.
I0904 11:58:27.563820       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:58:27.563831       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:58:27.563836       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00
I0904 11:58:27.563890       1 factory.go:59] Register preBinder predicates successfully
I0904 11:58:27.563905       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 11:58:27.563925       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:58:27.563952       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:58:27.563977       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:58:27.563983       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:58:27.564004       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:58:27.564024       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:58:27.564034       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:58:27.564040       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:58:27.564049       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:58:27.564063       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:58:27.564095       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:58:27.564105       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:58:27.564140       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:58:27.564194       1 binpack.go:165] Enter binpack plugin ...
I0904 11:58:27.564197       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:58:27.564203       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:58:27.564207       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:58:27.564209       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:58:27.564216       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:27.564225       1 allocate.go:62] Enter Allocate ...
I0904 11:58:27.564227       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:27.564232       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:58:27.564235       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:58:27.564238       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:58:27.564240       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:58:27.564242       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:58:27.564245       1 allocate.go:83] Leaving Allocate ...
I0904 11:58:27.564248       1 backfill.go:59] Enter Backfill ...
I0904 11:58:27.564251       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:27.564254       1 backfill.go:110] Leaving Backfill ...
I0904 11:58:27.564258       1 reclaim.go:47] Enter Reclaim ...
I0904 11:58:27.564261       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:58:27.564263       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:27.564266       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:58:27.564271       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:58:27.564273       1 preempt.go:103] Enter Preempt ...
I0904 11:58:27.564275       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:27.564278       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:58:27.564282       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:58:27.564287       1 preempt.go:270] Leaving Preempt ...
I0904 11:58:27.564359       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:58:27.564380       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:58:27.564384       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:27.564390       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:58:27.564404       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:27.564413       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:58:27.564417       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:58:27.564421       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:58:27.564425       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:27.564431       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:58:27.564456       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:58:27.564464       1 session.go:361] Session 506200c1-2940-4740-ba08-241b5a3ed081 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:58:27.564476       1 session.go:375] Close Session 506200c1-2940-4740-ba08-241b5a3ed081
I0904 11:58:27.564480       1 scheduler.go:133] End scheduling ...
I0904 11:58:33.365478       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StorageClass" totalItems=9
I0904 11:58:37.564861       1 scheduler.go:106] Start scheduling ...
I0904 11:58:37.564960       1 node_info.go:227] imageStates is map[]
I0904 11:58:37.564995       1 node_info.go:227] imageStates is map[]
I0904 11:58:37.565005       1 node_info.go:227] imageStates is map[]
I0904 11:58:37.565016       1 node_info.go:227] imageStates is map[]
I0904 11:58:37.565024       1 node_info.go:227] imageStates is map[]
I0904 11:58:37.565046       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:58:37.565081       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:58:37.565099       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:58:37.565109       1 session.go:230] Open Session 927b65a1-0bd4-4b3b-82f3-0777f1f8901b with <1> Job and <5> Queues
I0904 11:58:37.565119       1 session.go:233] Session 927b65a1-0bd4-4b3b-82f3-0777f1f8901b operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:58:37.565244       1 sla.go:85] Enter sla plugin ...
I0904 11:58:37.565249       1 sla.go:154] Leaving sla plugin.
I0904 11:58:37.565252       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:58:37.565262       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:58:37.565269       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 11:58:37.565326       1 factory.go:59] Register preBinder predicates successfully
I0904 11:58:37.565342       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>
I0904 11:58:37.565361       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:58:37.565379       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:58:37.565396       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:58:37.565403       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:58:37.565412       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:58:37.565428       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:58:37.565438       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:58:37.565462       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:58:37.565476       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:58:37.565490       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:58:37.565499       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:58:37.565507       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:58:37.565517       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:58:37.565544       1 binpack.go:165] Enter binpack plugin ...
I0904 11:58:37.565547       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:58:37.565551       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:58:37.565556       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:58:37.565558       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:58:37.565564       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:37.565574       1 allocate.go:62] Enter Allocate ...
I0904 11:58:37.565577       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:37.565582       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:58:37.565587       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:58:37.565590       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:58:37.565592       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:58:37.565594       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:58:37.565596       1 allocate.go:83] Leaving Allocate ...
I0904 11:58:37.565599       1 backfill.go:59] Enter Backfill ...
I0904 11:58:37.565601       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:37.565605       1 backfill.go:110] Leaving Backfill ...
I0904 11:58:37.565608       1 reclaim.go:47] Enter Reclaim ...
I0904 11:58:37.565610       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:58:37.565612       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:37.565616       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:58:37.565621       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:58:37.565624       1 preempt.go:103] Enter Preempt ...
I0904 11:58:37.565626       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:37.565629       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:58:37.565633       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:58:37.565638       1 preempt.go:270] Leaving Preempt ...
I0904 11:58:37.565703       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:37.565725       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:58:37.565730       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:37.565737       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:58:37.565750       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:58:37.565755       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:58:37.565767       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:37.565773       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:58:37.565799       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:58:37.565801       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:58:37.565806       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:58:37.565813       1 session.go:361] Session 927b65a1-0bd4-4b3b-82f3-0777f1f8901b operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:58:37.565817       1 session.go:375] Close Session 927b65a1-0bd4-4b3b-82f3-0777f1f8901b
I0904 11:58:37.565821       1 scheduler.go:133] End scheduling ...
I0904 11:58:45.368906       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PodDisruptionBudget" totalItems=9
I0904 11:58:47.565925       1 scheduler.go:106] Start scheduling ...
I0904 11:58:47.566040       1 node_info.go:227] imageStates is map[]
I0904 11:58:47.566076       1 node_info.go:227] imageStates is map[]
I0904 11:58:47.566086       1 node_info.go:227] imageStates is map[]
I0904 11:58:47.566097       1 node_info.go:227] imageStates is map[]
I0904 11:58:47.566106       1 node_info.go:227] imageStates is map[]
I0904 11:58:47.566133       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:58:47.566162       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:58:47.566178       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:58:47.566191       1 session.go:230] Open Session c881a263-4658-4844-8838-6fd8f2ec317b with <1> Job and <5> Queues
I0904 11:58:47.566205       1 session.go:233] Session c881a263-4658-4844-8838-6fd8f2ec317b operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:58:47.566349       1 sla.go:85] Enter sla plugin ...
I0904 11:58:47.566368       1 sla.go:154] Leaving sla plugin.
I0904 11:58:47.566374       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:58:47.566386       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:58:47.566393       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00
I0904 11:58:47.566444       1 factory.go:59] Register preBinder predicates successfully
I0904 11:58:47.566450       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 11:58:47.566467       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:58:47.566485       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:58:47.566501       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:58:47.566511       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:58:47.566523       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:58:47.566532       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:58:47.566543       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:58:47.566552       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:58:47.566562       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:58:47.566576       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:58:47.566592       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:58:47.566605       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:58:47.566614       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:58:47.566649       1 binpack.go:165] Enter binpack plugin ...
I0904 11:58:47.566654       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:58:47.566660       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:58:47.566665       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:58:47.566669       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:58:47.566677       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:47.566715       1 allocate.go:62] Enter Allocate ...
I0904 11:58:47.566719       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:47.566726       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:58:47.566729       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:58:47.566733       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:58:47.566736       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:58:47.566739       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:58:47.566743       1 allocate.go:83] Leaving Allocate ...
I0904 11:58:47.566747       1 backfill.go:59] Enter Backfill ...
I0904 11:58:47.566750       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:47.566756       1 backfill.go:110] Leaving Backfill ...
I0904 11:58:47.566759       1 reclaim.go:47] Enter Reclaim ...
I0904 11:58:47.566762       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:58:47.566765       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:47.566770       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:58:47.566777       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:58:47.566780       1 preempt.go:103] Enter Preempt ...
I0904 11:58:47.566783       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:47.566787       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:58:47.566793       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:58:47.566797       1 preempt.go:270] Leaving Preempt ...
I0904 11:58:47.566885       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:58:47.566913       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:58:47.566918       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:47.566927       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:58:47.566932       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:47.566942       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:58:47.566947       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:58:47.566953       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:58:47.566959       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:47.566965       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:58:47.566987       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:58:47.566996       1 session.go:361] Session c881a263-4658-4844-8838-6fd8f2ec317b operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:58:47.567000       1 session.go:375] Close Session c881a263-4658-4844-8838-6fd8f2ec317b
I0904 11:58:47.567006       1 scheduler.go:133] End scheduling ...
I0904 11:58:48.374522       1 reflector.go:946] "Watch close" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145" type="*v1beta1.Queue" totalItems=11
I0904 11:58:57.472671       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:58:57.567988       1 scheduler.go:106] Start scheduling ...
I0904 11:58:57.568243       1 node_info.go:227] imageStates is map[]
I0904 11:58:57.568370       1 node_info.go:227] imageStates is map[]
I0904 11:58:57.568396       1 node_info.go:227] imageStates is map[]
I0904 11:58:57.568424       1 node_info.go:227] imageStates is map[]
I0904 11:58:57.568452       1 node_info.go:227] imageStates is map[]
I0904 11:58:57.568517       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:58:57.568661       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:58:57.568696       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:58:57.568723       1 session.go:230] Open Session 9ac9c793-7d3b-40c8-a6d3-8c4230bcbcda with <1> Job and <5> Queues
I0904 11:58:57.568792       1 session.go:233] Session 9ac9c793-7d3b-40c8-a6d3-8c4230bcbcda operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:58:57.569166       1 sla.go:85] Enter sla plugin ...
I0904 11:58:57.569218       1 sla.go:154] Leaving sla plugin.
I0904 11:58:57.569231       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:58:57.569263       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:58:57.569279       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00
I0904 11:58:57.569394       1 factory.go:59] Register preBinder predicates successfully
I0904 11:58:57.569409       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 11:58:57.569461       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:58:57.569557       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:58:57.569642       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:58:57.569660       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:58:57.569700       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:58:57.569734       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:58:57.569804       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:58:57.569829       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:58:57.569859       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:58:57.569903       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:58:57.569929       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:58:57.569959       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:58:57.570020       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:58:57.570087       1 binpack.go:165] Enter binpack plugin ...
I0904 11:58:57.570099       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:58:57.570113       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:58:57.570184       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:58:57.570192       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:58:57.570208       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:57.570231       1 allocate.go:62] Enter Allocate ...
I0904 11:58:57.570239       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:57.570255       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:58:57.570331       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:58:57.570342       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:58:57.570349       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:58:57.570356       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:58:57.570363       1 allocate.go:83] Leaving Allocate ...
I0904 11:58:57.570373       1 backfill.go:59] Enter Backfill ...
I0904 11:58:57.570381       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:57.570394       1 backfill.go:110] Leaving Backfill ...
I0904 11:58:57.570404       1 reclaim.go:47] Enter Reclaim ...
I0904 11:58:57.570411       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:58:57.570418       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:57.570429       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:58:57.570445       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:58:57.570453       1 preempt.go:103] Enter Preempt ...
I0904 11:58:57.570460       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:58:57.570471       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:58:57.570483       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:58:57.570491       1 preempt.go:270] Leaving Preempt ...
I0904 11:58:57.570648       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:57.570724       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:58:57.570740       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:58:57.570756       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:58:57.570768       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:57.570784       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:58:57.570837       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:58:57.570846       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:58:57.570859       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:58:57.570871       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:58:57.570888       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:58:57.570915       1 session.go:361] Session 9ac9c793-7d3b-40c8-a6d3-8c4230bcbcda operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:58:57.570930       1 session.go:375] Close Session 9ac9c793-7d3b-40c8-a6d3-8c4230bcbcda
I0904 11:58:57.570942       1 scheduler.go:133] End scheduling ...
I0904 11:58:58.374159       1 reflector.go:946] "Watch close" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145" type="*v1alpha1.HyperNode" totalItems=9
I0904 11:59:06.376268       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StatefulSet" totalItems=8
I0904 11:59:07.371454       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Service" totalItems=8
I0904 11:59:07.571729       1 scheduler.go:106] Start scheduling ...
I0904 11:59:07.571958       1 node_info.go:227] imageStates is map[]
I0904 11:59:07.572000       1 node_info.go:227] imageStates is map[]
I0904 11:59:07.572098       1 node_info.go:227] imageStates is map[]
I0904 11:59:07.572136       1 node_info.go:227] imageStates is map[]
I0904 11:59:07.572160       1 node_info.go:227] imageStates is map[]
I0904 11:59:07.572217       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:59:07.572275       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:59:07.572327       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:59:07.572354       1 session.go:230] Open Session 724d498a-ea49-430e-9b4c-f7c330731cfd with <1> Job and <5> Queues
I0904 11:59:07.572385       1 session.go:233] Session 724d498a-ea49-430e-9b4c-f7c330731cfd operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:59:07.572729       1 sla.go:85] Enter sla plugin ...
I0904 11:59:07.572772       1 sla.go:154] Leaving sla plugin.
I0904 11:59:07.572786       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:59:07.572817       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:59:07.572833       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00
I0904 11:59:07.572992       1 factory.go:59] Register preBinder predicates successfully
I0904 11:59:07.573037       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>
I0904 11:59:07.573085       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:59:07.573128       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:59:07.573172       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:59:07.573216       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:59:07.573248       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:59:07.573270       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:59:07.573296       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:59:07.573319       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:59:07.573350       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:59:07.573387       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:59:07.573413       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:59:07.573461       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:59:07.573490       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:59:07.573552       1 binpack.go:165] Enter binpack plugin ...
I0904 11:59:07.573560       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:59:07.573571       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:59:07.573582       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:59:07.573589       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:59:07.573602       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:07.573621       1 allocate.go:62] Enter Allocate ...
I0904 11:59:07.573627       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:07.573639       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:59:07.573646       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:59:07.573655       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:59:07.573661       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:59:07.573667       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:59:07.573673       1 allocate.go:83] Leaving Allocate ...
I0904 11:59:07.573680       1 backfill.go:59] Enter Backfill ...
I0904 11:59:07.573687       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:07.573697       1 backfill.go:110] Leaving Backfill ...
I0904 11:59:07.573704       1 reclaim.go:47] Enter Reclaim ...
I0904 11:59:07.573710       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:59:07.573719       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:07.573730       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:59:07.573744       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:59:07.573755       1 preempt.go:103] Enter Preempt ...
I0904 11:59:07.573761       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:07.573772       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:59:07.573782       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:59:07.573789       1 preempt.go:270] Leaving Preempt ...
I0904 11:59:07.573936       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:07.573993       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:59:07.574008       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:59:07.574020       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:59:07.574030       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:07.574044       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:59:07.574107       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:59:07.574115       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:59:07.574127       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:59:07.574138       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:07.574154       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:59:07.574174       1 session.go:361] Session 724d498a-ea49-430e-9b4c-f7c330731cfd operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:59:07.574184       1 session.go:375] Close Session 724d498a-ea49-430e-9b4c-f7c330731cfd
I0904 11:59:07.574194       1 scheduler.go:133] End scheduling ...
I0904 11:59:17.574994       1 scheduler.go:106] Start scheduling ...
I0904 11:59:17.575186       1 node_info.go:227] imageStates is map[]
I0904 11:59:17.575290       1 node_info.go:227] imageStates is map[]
I0904 11:59:17.575440       1 node_info.go:227] imageStates is map[]
I0904 11:59:17.575465       1 node_info.go:227] imageStates is map[]
I0904 11:59:17.575521       1 node_info.go:227] imageStates is map[]
I0904 11:59:17.575567       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:59:17.575693       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:59:17.575718       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:59:17.575768       1 session.go:230] Open Session 89485300-7b1e-45ba-9534-b9c763f8445d with <1> Job and <5> Queues
I0904 11:59:17.575795       1 session.go:233] Session 89485300-7b1e-45ba-9534-b9c763f8445d operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:59:17.576074       1 sla.go:85] Enter sla plugin ...
I0904 11:59:17.576108       1 sla.go:154] Leaving sla plugin.
I0904 11:59:17.576117       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:59:17.576143       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:59:17.576153       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 11:59:17.576234       1 factory.go:59] Register preBinder predicates successfully
I0904 11:59:17.576245       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 11:59:17.576427       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:59:17.576467       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:59:17.576506       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:59:17.576519       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:59:17.576539       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:59:17.576564       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:59:17.576585       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:59:17.576608       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:59:17.576630       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:59:17.576666       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:59:17.576690       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:59:17.576709       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:59:17.576735       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:59:17.576791       1 binpack.go:165] Enter binpack plugin ...
I0904 11:59:17.576800       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:59:17.576831       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:59:17.576850       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:59:17.576855       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:59:17.576868       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:17.576884       1 allocate.go:62] Enter Allocate ...
I0904 11:59:17.576889       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:17.576900       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:59:17.576907       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:59:17.576914       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:59:17.576919       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:59:17.576925       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:59:17.576931       1 allocate.go:83] Leaving Allocate ...
I0904 11:59:17.576938       1 backfill.go:59] Enter Backfill ...
I0904 11:59:17.576943       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:17.576959       1 backfill.go:110] Leaving Backfill ...
I0904 11:59:17.576966       1 reclaim.go:47] Enter Reclaim ...
I0904 11:59:17.576972       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:59:17.576977       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:17.576986       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:59:17.576997       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:59:17.577002       1 preempt.go:103] Enter Preempt ...
I0904 11:59:17.577007       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:17.577016       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:59:17.577024       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:59:17.577032       1 preempt.go:270] Leaving Preempt ...
I0904 11:59:17.577153       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:17.577198       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:59:17.577247       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:59:17.577253       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:59:17.577264       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:59:17.577275       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:17.577288       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:59:17.577301       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:17.577316       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:59:17.577349       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:59:17.577362       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:59:17.577379       1 session.go:361] Session 89485300-7b1e-45ba-9534-b9c763f8445d operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:59:17.577388       1 session.go:375] Close Session 89485300-7b1e-45ba-9534-b9c763f8445d
I0904 11:59:17.577397       1 scheduler.go:133] End scheduling ...
I0904 11:59:27.473639       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:59:27.578027       1 scheduler.go:106] Start scheduling ...
I0904 11:59:27.578180       1 node_info.go:227] imageStates is map[]
I0904 11:59:27.578218       1 node_info.go:227] imageStates is map[]
I0904 11:59:27.578233       1 node_info.go:227] imageStates is map[]
I0904 11:59:27.578247       1 node_info.go:227] imageStates is map[]
I0904 11:59:27.578259       1 node_info.go:227] imageStates is map[]
I0904 11:59:27.578276       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:59:27.578337       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:59:27.578352       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:59:27.578365       1 session.go:230] Open Session 727e813c-234c-4a18-8b39-c3c93d518c13 with <1> Job and <5> Queues
I0904 11:59:27.578395       1 session.go:233] Session 727e813c-234c-4a18-8b39-c3c93d518c13 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:59:27.578566       1 sla.go:85] Enter sla plugin ...
I0904 11:59:27.578585       1 sla.go:154] Leaving sla plugin.
I0904 11:59:27.578592       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:59:27.578606       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:59:27.578613       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00
I0904 11:59:27.578665       1 factory.go:59] Register preBinder predicates successfully
I0904 11:59:27.578671       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 11:59:27.578696       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:59:27.578736       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:59:27.578757       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:59:27.578766       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:59:27.578787       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:59:27.578814       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:59:27.578825       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:59:27.578833       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:59:27.578849       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:59:27.578884       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:59:27.578898       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:59:27.578909       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:59:27.578922       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 11:59:27.578953       1 binpack.go:165] Enter binpack plugin ...
I0904 11:59:27.578957       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:59:27.578963       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:59:27.578969       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:59:27.578972       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:59:27.578979       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:27.578988       1 allocate.go:62] Enter Allocate ...
I0904 11:59:27.578990       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:27.578997       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:59:27.579001       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:59:27.579004       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:59:27.579007       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:59:27.579010       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:59:27.579013       1 allocate.go:83] Leaving Allocate ...
I0904 11:59:27.579076       1 backfill.go:59] Enter Backfill ...
I0904 11:59:27.579080       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:27.579085       1 backfill.go:110] Leaving Backfill ...
I0904 11:59:27.579089       1 reclaim.go:47] Enter Reclaim ...
I0904 11:59:27.579092       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:59:27.579095       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:27.579100       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:59:27.579107       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:59:27.579110       1 preempt.go:103] Enter Preempt ...
I0904 11:59:27.579113       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:27.579118       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:59:27.579122       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:59:27.579126       1 preempt.go:270] Leaving Preempt ...
I0904 11:59:27.579218       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:59:27.579239       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:59:27.579243       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:27.579248       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:59:27.579265       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:59:27.579268       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:59:27.579273       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:59:27.579277       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:27.579282       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:59:27.579287       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:27.579294       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:59:27.579302       1 session.go:361] Session 727e813c-234c-4a18-8b39-c3c93d518c13 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:59:27.579305       1 session.go:375] Close Session 727e813c-234c-4a18-8b39-c3c93d518c13
I0904 11:59:27.579325       1 scheduler.go:133] End scheduling ...
I0904 11:59:30.372084       1 reflector.go:946] "Watch close" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145" type="*v1alpha1.Numatopology" totalItems=9
I0904 11:59:34.377754       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicaSet" totalItems=9
I0904 11:59:37.580115       1 scheduler.go:106] Start scheduling ...
I0904 11:59:37.580379       1 node_info.go:227] imageStates is map[]
I0904 11:59:37.580446       1 node_info.go:227] imageStates is map[]
I0904 11:59:37.580504       1 node_info.go:227] imageStates is map[]
I0904 11:59:37.580577       1 node_info.go:227] imageStates is map[]
I0904 11:59:37.580613       1 node_info.go:227] imageStates is map[]
I0904 11:59:37.580674       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:59:37.580724       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:59:37.580747       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:59:37.580770       1 session.go:230] Open Session 94cab3db-5682-447b-8d7d-e6cc621c35f9 with <1> Job and <5> Queues
I0904 11:59:37.580821       1 session.go:233] Session 94cab3db-5682-447b-8d7d-e6cc621c35f9 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:59:37.581076       1 sla.go:85] Enter sla plugin ...
I0904 11:59:37.581118       1 sla.go:154] Leaving sla plugin.
I0904 11:59:37.581128       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:59:37.581155       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:59:37.581167       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00
I0904 11:59:37.581251       1 factory.go:59] Register preBinder predicates successfully
I0904 11:59:37.581284       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 11:59:37.581330       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:59:37.581375       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 11:59:37.581417       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 11:59:37.581437       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:59:37.581464       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:59:37.581504       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 11:59:37.581528       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 11:59:37.581547       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 11:59:37.581575       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:59:37.581601       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:59:37.581625       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 11:59:37.581644       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:59:37.581689       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 11:59:37.581746       1 binpack.go:165] Enter binpack plugin ...
I0904 11:59:37.581775       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:59:37.581785       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:59:37.581794       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:59:37.581800       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:59:37.581811       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:37.581825       1 allocate.go:62] Enter Allocate ...
I0904 11:59:37.581832       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:37.581843       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:59:37.581849       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:59:37.581856       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:59:37.581862       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:59:37.581868       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:59:37.581873       1 allocate.go:83] Leaving Allocate ...
I0904 11:59:37.581878       1 backfill.go:59] Enter Backfill ...
I0904 11:59:37.581884       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:37.581893       1 backfill.go:110] Leaving Backfill ...
I0904 11:59:37.581901       1 reclaim.go:47] Enter Reclaim ...
I0904 11:59:37.581906       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:59:37.581912       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:37.581920       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:59:37.581931       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:59:37.581936       1 preempt.go:103] Enter Preempt ...
I0904 11:59:37.581940       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:37.581949       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:59:37.581957       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:59:37.581964       1 preempt.go:270] Leaving Preempt ...
I0904 11:59:37.582084       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:37.582136       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:59:37.582149       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:59:37.582160       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:59:37.582170       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:37.582184       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:59:37.582221       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:59:37.582228       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:59:37.582238       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:59:37.582246       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:37.582259       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:59:37.582278       1 session.go:361] Session 94cab3db-5682-447b-8d7d-e6cc621c35f9 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:59:37.582285       1 session.go:375] Close Session 94cab3db-5682-447b-8d7d-e6cc621c35f9
I0904 11:59:37.582298       1 scheduler.go:133] End scheduling ...
I0904 11:59:38.365980       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Namespace" totalItems=10
I0904 11:59:38.377975       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Pod" totalItems=9
I0904 11:59:47.582348       1 scheduler.go:106] Start scheduling ...
I0904 11:59:47.582478       1 node_info.go:227] imageStates is map[]
I0904 11:59:47.582496       1 node_info.go:227] imageStates is map[]
I0904 11:59:47.582511       1 node_info.go:227] imageStates is map[]
I0904 11:59:47.582525       1 node_info.go:227] imageStates is map[]
I0904 11:59:47.582576       1 node_info.go:227] imageStates is map[]
I0904 11:59:47.582613       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:59:47.582659       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:59:47.582675       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:59:47.582686       1 session.go:230] Open Session 7031ce5f-bf32-4569-ab7c-73314d605475 with <1> Job and <5> Queues
I0904 11:59:47.582701       1 session.go:233] Session 7031ce5f-bf32-4569-ab7c-73314d605475 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:59:47.582851       1 sla.go:85] Enter sla plugin ...
I0904 11:59:47.582874       1 sla.go:154] Leaving sla plugin.
I0904 11:59:47.582880       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:59:47.582894       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:59:47.582901       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00
I0904 11:59:47.582956       1 factory.go:59] Register preBinder predicates successfully
I0904 11:59:47.582963       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 11:59:47.582988       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:59:47.583010       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:59:47.583029       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 10000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 11:59:47.583054       1 binpack.go:165] Enter binpack plugin ...
I0904 11:59:47.583061       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:59:47.583066       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:59:47.583072       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:59:47.583075       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:59:47.583082       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:47.583107       1 allocate.go:62] Enter Allocate ...
I0904 11:59:47.583110       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:47.583117       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:59:47.583121       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:59:47.583125       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:59:47.583130       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:59:47.583133       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:59:47.583136       1 allocate.go:83] Leaving Allocate ...
I0904 11:59:47.583141       1 backfill.go:59] Enter Backfill ...
I0904 11:59:47.583144       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:47.583150       1 backfill.go:110] Leaving Backfill ...
I0904 11:59:47.583154       1 reclaim.go:47] Enter Reclaim ...
I0904 11:59:47.583157       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:59:47.583160       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:47.583165       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:59:47.583171       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:59:47.583175       1 preempt.go:103] Enter Preempt ...
I0904 11:59:47.583178       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:47.583182       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:59:47.583187       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:59:47.583190       1 preempt.go:270] Leaving Preempt ...
I0904 11:59:47.583260       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:47.583292       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:59:47.583301       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:59:47.583308       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:59:47.583314       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:47.583359       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:59:47.592481       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:59:47.592559       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:59:47.592573       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:47.592593       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:59:47.592619       1 session.go:361] Session 7031ce5f-bf32-4569-ab7c-73314d605475 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:59:47.592629       1 session.go:375] Close Session 7031ce5f-bf32-4569-ab7c-73314d605475
I0904 11:59:47.592639       1 scheduler.go:133] End scheduling ...
I0904 11:59:57.474265       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 11:59:57.592746       1 scheduler.go:106] Start scheduling ...
I0904 11:59:57.592853       1 node_info.go:227] imageStates is map[]
I0904 11:59:57.592903       1 node_info.go:227] imageStates is map[]
I0904 11:59:57.592927       1 node_info.go:227] imageStates is map[]
I0904 11:59:57.592937       1 node_info.go:227] imageStates is map[]
I0904 11:59:57.592948       1 node_info.go:227] imageStates is map[]
I0904 11:59:57.592971       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 11:59:57.593000       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 11:59:57.593012       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 11:59:57.593022       1 session.go:230] Open Session 1340371d-c83c-4c50-a169-d156457bb7b0 with <1> Job and <5> Queues
I0904 11:59:57.593033       1 session.go:233] Session 1340371d-c83c-4c50-a169-d156457bb7b0 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:59:57.593160       1 sla.go:85] Enter sla plugin ...
I0904 11:59:57.593165       1 sla.go:154] Leaving sla plugin.
I0904 11:59:57.593169       1 overcommit.go:75] Enter overcommit plugin ...
I0904 11:59:57.593178       1 overcommit.go:142] Leaving overcommit plugin.
I0904 11:59:57.593184       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00
I0904 11:59:57.593242       1 factory.go:59] Register preBinder predicates successfully
I0904 11:59:57.593256       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
I0904 11:59:57.593277       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 11:59:57.593292       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 11:59:57.593315       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 10000.00, pods 550.00>
I0904 11:59:57.593334       1 binpack.go:165] Enter binpack plugin ...
I0904 11:59:57.593337       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 11:59:57.593341       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 11:59:57.593345       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 11:59:57.593347       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 11:59:57.593353       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:57.593362       1 allocate.go:62] Enter Allocate ...
I0904 11:59:57.593365       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:57.593370       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 11:59:57.593372       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 11:59:57.593375       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:59:57.593378       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 11:59:57.593381       1 allocate.go:150] Can not find jobs for queue q1.
I0904 11:59:57.593383       1 allocate.go:83] Leaving Allocate ...
I0904 11:59:57.593386       1 backfill.go:59] Enter Backfill ...
I0904 11:59:57.593388       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:57.593392       1 backfill.go:110] Leaving Backfill ...
I0904 11:59:57.593395       1 reclaim.go:47] Enter Reclaim ...
I0904 11:59:57.593397       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 11:59:57.593399       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:57.593403       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:59:57.593407       1 reclaim.go:234] Leaving Reclaim ...
I0904 11:59:57.593410       1 preempt.go:103] Enter Preempt ...
I0904 11:59:57.593412       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 11:59:57.593416       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 11:59:57.593419       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 11:59:57.593422       1 preempt.go:270] Leaving Preempt ...
I0904 11:59:57.593480       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:57.593501       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:59:57.593506       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:59:57.593511       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:59:57.593514       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:57.593520       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 11:59:57.593534       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 11:59:57.593536       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 11:59:57.593540       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 11:59:57.593543       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 11:59:57.593548       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 11:59:57.593555       1 session.go:361] Session 1340371d-c83c-4c50-a169-d156457bb7b0 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 11:59:57.593558       1 session.go:375] Close Session 1340371d-c83c-4c50-a169-d156457bb7b0
I0904 11:59:57.593562       1 scheduler.go:133] End scheduling ...
I0904 12:00:02.749924       1 cache.go:1179] started sync node integration-control-plane
I0904 12:00:02.750007       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:00:02.750195       1 node_info.go:227] imageStates is map[]
I0904 12:00:07.593808       1 scheduler.go:106] Start scheduling ...
I0904 12:00:07.593910       1 node_info.go:227] imageStates is map[]
I0904 12:00:07.593967       1 node_info.go:227] imageStates is map[]
I0904 12:00:07.594011       1 node_info.go:227] imageStates is map[]
I0904 12:00:07.594026       1 node_info.go:227] imageStates is map[]
I0904 12:00:07.594042       1 node_info.go:227] imageStates is map[]
I0904 12:00:07.594071       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:00:07.594105       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:00:07.594120       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:00:07.594133       1 session.go:230] Open Session dc06ca53-8252-47f7-a9be-4f10c73514cd with <1> Job and <5> Queues
I0904 12:00:07.594148       1 session.go:233] Session dc06ca53-8252-47f7-a9be-4f10c73514cd operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:00:07.594314       1 sla.go:85] Enter sla plugin ...
I0904 12:00:07.594339       1 sla.go:154] Leaving sla plugin.
I0904 12:00:07.594346       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:00:07.594363       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:00:07.594370       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00
I0904 12:00:07.594431       1 factory.go:59] Register preBinder predicates successfully
I0904 12:00:07.594438       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 12:00:07.594466       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:00:07.594491       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:00:07.594510       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 10000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:00:07.594538       1 binpack.go:165] Enter binpack plugin ...
I0904 12:00:07.594542       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:00:07.594548       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:00:07.594554       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:00:07.594557       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:00:07.594566       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:07.594575       1 allocate.go:62] Enter Allocate ...
I0904 12:00:07.594579       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:07.594586       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:00:07.594591       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:00:07.594596       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:00:07.594599       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:00:07.594603       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:00:07.594606       1 allocate.go:83] Leaving Allocate ...
I0904 12:00:07.594611       1 backfill.go:59] Enter Backfill ...
I0904 12:00:07.594615       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:07.594620       1 backfill.go:110] Leaving Backfill ...
I0904 12:00:07.594625       1 reclaim.go:47] Enter Reclaim ...
I0904 12:00:07.594628       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:00:07.594631       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:07.594637       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:00:07.594645       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:00:07.594649       1 preempt.go:103] Enter Preempt ...
I0904 12:00:07.594652       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:07.594663       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:00:07.594669       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:00:07.594674       1 preempt.go:270] Leaving Preempt ...
I0904 12:00:07.594796       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:07.594815       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:00:07.594826       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:07.594836       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:00:07.594843       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:00:07.594852       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:00:07.594858       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:07.594865       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:00:07.594887       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:00:07.594891       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:00:07.594898       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:00:07.594908       1 session.go:361] Session dc06ca53-8252-47f7-a9be-4f10c73514cd operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:00:07.594914       1 session.go:375] Close Session dc06ca53-8252-47f7-a9be-4f10c73514cd
I0904 12:00:07.594921       1 scheduler.go:133] End scheduling ...
I0904 12:00:12.986832       1 cache.go:1179] started sync node integration-control-plane
I0904 12:00:12.986854       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:00:12.986915       1 node_info.go:227] imageStates is map[]
I0904 12:00:17.595833       1 scheduler.go:106] Start scheduling ...
I0904 12:00:17.595935       1 node_info.go:227] imageStates is map[]
I0904 12:00:17.595968       1 node_info.go:227] imageStates is map[]
I0904 12:00:17.595977       1 node_info.go:227] imageStates is map[]
I0904 12:00:17.595987       1 node_info.go:227] imageStates is map[]
I0904 12:00:17.595996       1 node_info.go:227] imageStates is map[]
I0904 12:00:17.596019       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:00:17.596054       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:00:17.596066       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:00:17.596077       1 session.go:230] Open Session e7d3d6a1-cd40-45f2-b575-3815ef7a41f4 with <1> Job and <5> Queues
I0904 12:00:17.596088       1 session.go:233] Session e7d3d6a1-cd40-45f2-b575-3815ef7a41f4 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:00:17.596219       1 sla.go:85] Enter sla plugin ...
I0904 12:00:17.596235       1 sla.go:154] Leaving sla plugin.
I0904 12:00:17.596240       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:00:17.596252       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:00:17.596257       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:00:17.596302       1 factory.go:59] Register preBinder predicates successfully
I0904 12:00:17.596307       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:00:17.596325       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:00:17.596341       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:00:17.596370       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 10000.00, ephemeral-storage 1081101176832000.00>
I0904 12:00:17.596390       1 binpack.go:165] Enter binpack plugin ...
I0904 12:00:17.596393       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:00:17.596397       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:00:17.596401       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:00:17.596403       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:00:17.596409       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:17.596416       1 allocate.go:62] Enter Allocate ...
I0904 12:00:17.596419       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:17.596425       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:00:17.596427       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:00:17.596430       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:00:17.596434       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:00:17.596436       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:00:17.596438       1 allocate.go:83] Leaving Allocate ...
I0904 12:00:17.596442       1 backfill.go:59] Enter Backfill ...
I0904 12:00:17.596444       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:17.596450       1 backfill.go:110] Leaving Backfill ...
I0904 12:00:17.596454       1 reclaim.go:47] Enter Reclaim ...
I0904 12:00:17.596456       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:00:17.596458       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:17.596461       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:00:17.596466       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:00:17.596470       1 preempt.go:103] Enter Preempt ...
I0904 12:00:17.596472       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:17.596476       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:00:17.596480       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:00:17.596486       1 preempt.go:270] Leaving Preempt ...
I0904 12:00:17.596550       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:00:17.596576       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:00:17.596580       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:17.596585       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:00:17.596601       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:00:17.596605       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:00:17.596609       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:00:17.596614       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:17.596620       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:00:17.596624       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:17.596631       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:00:17.596656       1 session.go:361] Session e7d3d6a1-cd40-45f2-b575-3815ef7a41f4 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:00:17.596662       1 session.go:375] Close Session e7d3d6a1-cd40-45f2-b575-3815ef7a41f4
I0904 12:00:17.596666       1 scheduler.go:133] End scheduling ...
I0904 12:00:27.475202       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:00:27.597549       1 scheduler.go:106] Start scheduling ...
I0904 12:00:27.597671       1 node_info.go:227] imageStates is map[]
I0904 12:00:27.597752       1 node_info.go:227] imageStates is map[]
I0904 12:00:27.597793       1 node_info.go:227] imageStates is map[]
I0904 12:00:27.597873       1 node_info.go:227] imageStates is map[]
I0904 12:00:27.597912       1 node_info.go:227] imageStates is map[]
I0904 12:00:27.597940       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:00:27.597979       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:00:27.597991       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:00:27.598004       1 session.go:230] Open Session d5dd7fb4-760a-4992-b517-66f09b35b2b9 with <1> Job and <5> Queues
I0904 12:00:27.598020       1 session.go:233] Session d5dd7fb4-760a-4992-b517-66f09b35b2b9 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:00:27.598180       1 sla.go:85] Enter sla plugin ...
I0904 12:00:27.598203       1 sla.go:154] Leaving sla plugin.
I0904 12:00:27.598208       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:00:27.598222       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:00:27.598228       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:00:27.598277       1 factory.go:59] Register preBinder predicates successfully
I0904 12:00:27.598284       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 12:00:27.598304       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:00:27.598337       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:00:27.598353       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 10000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:00:27.598405       1 binpack.go:165] Enter binpack plugin ...
I0904 12:00:27.598409       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:00:27.598415       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:00:27.598419       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:00:27.598422       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:00:27.598428       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:27.598437       1 allocate.go:62] Enter Allocate ...
I0904 12:00:27.598440       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:27.598447       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:00:27.598452       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:00:27.598456       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:00:27.598460       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:00:27.598462       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:00:27.598465       1 allocate.go:83] Leaving Allocate ...
I0904 12:00:27.598469       1 backfill.go:59] Enter Backfill ...
I0904 12:00:27.598471       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:27.598475       1 backfill.go:110] Leaving Backfill ...
I0904 12:00:27.598479       1 reclaim.go:47] Enter Reclaim ...
I0904 12:00:27.598481       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:00:27.598485       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:27.598489       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:00:27.598495       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:00:27.598500       1 preempt.go:103] Enter Preempt ...
I0904 12:00:27.598503       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:27.598506       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:00:27.598511       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:00:27.598515       1 preempt.go:270] Leaving Preempt ...
I0904 12:00:27.598582       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:00:27.598596       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:00:27.598600       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:27.598609       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:00:27.598623       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:00:27.598627       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:00:27.598632       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:00:27.598636       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:27.598643       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:00:27.598650       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:27.598657       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:00:27.598666       1 session.go:361] Session d5dd7fb4-760a-4992-b517-66f09b35b2b9 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:00:27.598670       1 session.go:375] Close Session d5dd7fb4-760a-4992-b517-66f09b35b2b9
I0904 12:00:27.598674       1 scheduler.go:133] End scheduling ...
I0904 12:00:32.369829       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicationController" totalItems=11
I0904 12:00:35.372088       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolume" totalItems=10
I0904 12:00:37.599578       1 scheduler.go:106] Start scheduling ...
I0904 12:00:37.599721       1 node_info.go:227] imageStates is map[]
I0904 12:00:37.599783       1 node_info.go:227] imageStates is map[]
I0904 12:00:37.599802       1 node_info.go:227] imageStates is map[]
I0904 12:00:37.599820       1 node_info.go:227] imageStates is map[]
I0904 12:00:37.599836       1 node_info.go:227] imageStates is map[]
I0904 12:00:37.599872       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:00:37.599912       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:00:37.599929       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:00:37.599943       1 session.go:230] Open Session 59cd91ee-0127-42ac-a4f0-67426e4414c5 with <1> Job and <5> Queues
I0904 12:00:37.599979       1 session.go:233] Session 59cd91ee-0127-42ac-a4f0-67426e4414c5 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:00:37.600236       1 sla.go:85] Enter sla plugin ...
I0904 12:00:37.600245       1 sla.go:154] Leaving sla plugin.
I0904 12:00:37.600251       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:00:37.600271       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:00:37.600280       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00
I0904 12:00:37.600346       1 factory.go:59] Register preBinder predicates successfully
I0904 12:00:37.600355       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:00:37.600384       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:00:37.600413       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:00:37.600437       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 10000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>
I0904 12:00:37.600463       1 binpack.go:165] Enter binpack plugin ...
I0904 12:00:37.600504       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:00:37.600512       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:00:37.600519       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:00:37.600523       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:00:37.600532       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:37.600544       1 allocate.go:62] Enter Allocate ...
I0904 12:00:37.600548       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:37.600560       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:00:37.600565       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:00:37.600570       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:00:37.600573       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:00:37.600578       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:00:37.600582       1 allocate.go:83] Leaving Allocate ...
I0904 12:00:37.600587       1 backfill.go:59] Enter Backfill ...
I0904 12:00:37.600592       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:37.600599       1 backfill.go:110] Leaving Backfill ...
I0904 12:00:37.600604       1 reclaim.go:47] Enter Reclaim ...
I0904 12:00:37.600608       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:00:37.600612       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:37.600619       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:00:37.600628       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:00:37.600632       1 preempt.go:103] Enter Preempt ...
I0904 12:00:37.600636       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:37.600643       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:00:37.600649       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:00:37.600654       1 preempt.go:270] Leaving Preempt ...
I0904 12:00:37.600748       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:37.600770       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:00:37.600778       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:37.600790       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:00:37.600798       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:00:37.600806       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:00:37.600820       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:37.600829       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:00:37.600860       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:00:37.600865       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:00:37.600873       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:00:37.600885       1 session.go:361] Session 59cd91ee-0127-42ac-a4f0-67426e4414c5 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:00:37.600891       1 session.go:375] Close Session 59cd91ee-0127-42ac-a4f0-67426e4414c5
I0904 12:00:37.600898       1 scheduler.go:133] End scheduling ...
I0904 12:00:47.601691       1 scheduler.go:106] Start scheduling ...
I0904 12:00:47.601894       1 node_info.go:227] imageStates is map[]
I0904 12:00:47.601982       1 node_info.go:227] imageStates is map[]
I0904 12:00:47.602007       1 node_info.go:227] imageStates is map[]
I0904 12:00:47.602017       1 node_info.go:227] imageStates is map[]
I0904 12:00:47.602037       1 node_info.go:227] imageStates is map[]
I0904 12:00:47.602073       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:00:47.602112       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:00:47.602123       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:00:47.602134       1 session.go:230] Open Session 025842e4-da12-486f-ae0c-32d1532c941a with <1> Job and <5> Queues
I0904 12:00:47.602145       1 session.go:233] Session 025842e4-da12-486f-ae0c-32d1532c941a operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:00:47.602280       1 sla.go:85] Enter sla plugin ...
I0904 12:00:47.602297       1 sla.go:154] Leaving sla plugin.
I0904 12:00:47.602302       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:00:47.602314       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:00:47.602319       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00
I0904 12:00:47.602365       1 factory.go:59] Register preBinder predicates successfully
I0904 12:00:47.602371       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
I0904 12:00:47.602392       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:00:47.602429       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:00:47.602446       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 10000.00>
I0904 12:00:47.602473       1 binpack.go:165] Enter binpack plugin ...
I0904 12:00:47.602492       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:00:47.602498       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:00:47.602505       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:00:47.602508       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:00:47.602516       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:47.602527       1 allocate.go:62] Enter Allocate ...
I0904 12:00:47.602531       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:47.602537       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:00:47.602542       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:00:47.602546       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:00:47.602549       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:00:47.602552       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:00:47.602555       1 allocate.go:83] Leaving Allocate ...
I0904 12:00:47.602560       1 backfill.go:59] Enter Backfill ...
I0904 12:00:47.602563       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:47.602568       1 backfill.go:110] Leaving Backfill ...
I0904 12:00:47.602572       1 reclaim.go:47] Enter Reclaim ...
I0904 12:00:47.602576       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:00:47.602579       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:47.602584       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:00:47.602591       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:00:47.602595       1 preempt.go:103] Enter Preempt ...
I0904 12:00:47.602598       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:47.602603       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:00:47.602608       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:00:47.602628       1 preempt.go:270] Leaving Preempt ...
I0904 12:00:47.602779       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:00:47.602808       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:00:47.602813       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:47.602823       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:00:47.602829       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:47.602845       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:00:47.602851       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:00:47.602858       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:00:47.602862       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:47.602868       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:00:47.602883       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:00:47.602892       1 session.go:361] Session 025842e4-da12-486f-ae0c-32d1532c941a operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:00:47.602896       1 session.go:375] Close Session 025842e4-da12-486f-ae0c-32d1532c941a
I0904 12:00:47.602901       1 scheduler.go:133] End scheduling ...
I0904 12:00:49.367102       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolumeClaim" totalItems=11
I0904 12:00:57.476004       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:00:57.603752       1 scheduler.go:106] Start scheduling ...
I0904 12:00:57.604066       1 node_info.go:227] imageStates is map[]
I0904 12:00:57.604127       1 node_info.go:227] imageStates is map[]
I0904 12:00:57.604153       1 node_info.go:227] imageStates is map[]
I0904 12:00:57.604195       1 node_info.go:227] imageStates is map[]
I0904 12:00:57.604218       1 node_info.go:227] imageStates is map[]
I0904 12:00:57.604246       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:00:57.604278       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:00:57.604291       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:00:57.604304       1 session.go:230] Open Session b008122e-e23a-44b1-877b-f2b136192cea with <1> Job and <5> Queues
I0904 12:00:57.604402       1 session.go:233] Session b008122e-e23a-44b1-877b-f2b136192cea operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:00:57.604573       1 sla.go:85] Enter sla plugin ...
I0904 12:00:57.604598       1 sla.go:154] Leaving sla plugin.
I0904 12:00:57.604617       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:00:57.604633       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:00:57.604641       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00
I0904 12:00:57.604700       1 factory.go:59] Register preBinder predicates successfully
I0904 12:00:57.604711       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 12:00:57.604736       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:00:57.604761       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:00:57.604779       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 10000.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 12:00:57.604804       1 binpack.go:165] Enter binpack plugin ...
I0904 12:00:57.604825       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:00:57.604831       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:00:57.604839       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:00:57.604843       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:00:57.604850       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:57.604860       1 allocate.go:62] Enter Allocate ...
I0904 12:00:57.604863       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:57.604871       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:00:57.604876       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:00:57.604882       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:00:57.604884       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:00:57.604887       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:00:57.604891       1 allocate.go:83] Leaving Allocate ...
I0904 12:00:57.604895       1 backfill.go:59] Enter Backfill ...
I0904 12:00:57.604899       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:57.604904       1 backfill.go:110] Leaving Backfill ...
I0904 12:00:57.604908       1 reclaim.go:47] Enter Reclaim ...
I0904 12:00:57.604911       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:00:57.604914       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:57.604919       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:00:57.604926       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:00:57.604929       1 preempt.go:103] Enter Preempt ...
I0904 12:00:57.604932       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:00:57.604937       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:00:57.604942       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:00:57.604946       1 preempt.go:270] Leaving Preempt ...
I0904 12:00:57.605025       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:57.605077       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:00:57.605102       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:57.605113       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:00:57.605119       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:00:57.605127       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:00:57.605133       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:00:57.605145       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:00:57.605165       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:00:57.605168       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:00:57.605174       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:00:57.605185       1 session.go:361] Session b008122e-e23a-44b1-877b-f2b136192cea operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:00:57.605191       1 session.go:375] Close Session b008122e-e23a-44b1-877b-f2b136192cea
I0904 12:00:57.605198       1 scheduler.go:133] End scheduling ...
I0904 12:01:07.606027       1 scheduler.go:106] Start scheduling ...
I0904 12:01:07.606159       1 node_info.go:227] imageStates is map[]
I0904 12:01:07.606214       1 node_info.go:227] imageStates is map[]
I0904 12:01:07.606235       1 node_info.go:227] imageStates is map[]
I0904 12:01:07.606251       1 node_info.go:227] imageStates is map[]
I0904 12:01:07.606289       1 node_info.go:227] imageStates is map[]
I0904 12:01:07.606335       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:01:07.606393       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:01:07.606409       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:01:07.606422       1 session.go:230] Open Session a2eeb53f-ca77-4e22-9e4b-3916885db08e with <1> Job and <5> Queues
I0904 12:01:07.606436       1 session.go:233] Session a2eeb53f-ca77-4e22-9e4b-3916885db08e operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:01:07.606601       1 sla.go:85] Enter sla plugin ...
I0904 12:01:07.606607       1 sla.go:154] Leaving sla plugin.
I0904 12:01:07.606613       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:01:07.606625       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:01:07.606631       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00
I0904 12:01:07.606685       1 factory.go:59] Register preBinder predicates successfully
I0904 12:01:07.606691       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:01:07.606722       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:01:07.606743       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:01:07.606761       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 10000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:01:07.606784       1 binpack.go:165] Enter binpack plugin ...
I0904 12:01:07.606789       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:01:07.606794       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:01:07.606799       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:01:07.606803       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:01:07.606809       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:07.606818       1 allocate.go:62] Enter Allocate ...
I0904 12:01:07.606821       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:07.606828       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:01:07.606832       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:01:07.606837       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:01:07.606840       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:01:07.606848       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:01:07.606851       1 allocate.go:83] Leaving Allocate ...
I0904 12:01:07.606856       1 backfill.go:59] Enter Backfill ...
I0904 12:01:07.606859       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:07.606865       1 backfill.go:110] Leaving Backfill ...
I0904 12:01:07.606869       1 reclaim.go:47] Enter Reclaim ...
I0904 12:01:07.606872       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:01:07.606875       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:07.606924       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:01:07.606932       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:01:07.606937       1 preempt.go:103] Enter Preempt ...
I0904 12:01:07.606940       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:07.606946       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:01:07.606951       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:01:07.606955       1 preempt.go:270] Leaving Preempt ...
I0904 12:01:07.607041       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:01:07.607060       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:01:07.607066       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:07.607077       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:01:07.607085       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:07.607094       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:01:07.607102       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:01:07.607108       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:01:07.607114       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:07.607120       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:01:07.607141       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:01:07.607150       1 session.go:361] Session a2eeb53f-ca77-4e22-9e4b-3916885db08e operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:01:07.607155       1 session.go:375] Close Session a2eeb53f-ca77-4e22-9e4b-3916885db08e
I0904 12:01:07.607160       1 scheduler.go:133] End scheduling ...
I0904 12:01:10.371778       1 reflector.go:946] "Watch close" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145" type="*v1beta1.PodGroup" totalItems=11
I0904 12:01:14.689202       1 cache.go:1179] started sync node kwok-node-a100-mate-0
I0904 12:01:14.689256       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-a100-mate-0
I0904 12:01:14.689435       1 node_info.go:227] imageStates is map[]
I0904 12:01:17.220311       1 cache.go:1179] started sync node kwok-node-1
I0904 12:01:17.220339       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-1
I0904 12:01:17.220396       1 node_info.go:227] imageStates is map[]
I0904 12:01:17.608359       1 scheduler.go:106] Start scheduling ...
I0904 12:01:17.608607       1 node_info.go:227] imageStates is map[]
I0904 12:01:17.608726       1 node_info.go:227] imageStates is map[]
I0904 12:01:17.608758       1 node_info.go:227] imageStates is map[]
I0904 12:01:17.608789       1 node_info.go:227] imageStates is map[]
I0904 12:01:17.608827       1 node_info.go:227] imageStates is map[]
I0904 12:01:17.608918       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:01:17.608984       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:01:17.609046       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:01:17.609074       1 session.go:230] Open Session fd9c8267-a705-4e52-adc1-bd452e31d7a1 with <1> Job and <5> Queues
I0904 12:01:17.609105       1 session.go:233] Session fd9c8267-a705-4e52-adc1-bd452e31d7a1 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:01:17.609410       1 sla.go:85] Enter sla plugin ...
I0904 12:01:17.609459       1 sla.go:154] Leaving sla plugin.
I0904 12:01:17.609472       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:01:17.609501       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:01:17.609516       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00
I0904 12:01:17.609609       1 factory.go:59] Register preBinder predicates successfully
I0904 12:01:17.609624       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:01:17.609672       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:01:17.609762       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:01:17.609800       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, pods 550.00, nvidia.com/A100 10000.00, hugepages-2Mi 0.00>
I0904 12:01:17.609846       1 binpack.go:165] Enter binpack plugin ...
I0904 12:01:17.609855       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:01:17.609866       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:01:17.609878       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:01:17.609885       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:01:17.609898       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:17.609917       1 allocate.go:62] Enter Allocate ...
I0904 12:01:17.609924       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:17.609937       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:01:17.609945       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:01:17.609954       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:01:17.609961       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:01:17.609967       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:01:17.609974       1 allocate.go:83] Leaving Allocate ...
I0904 12:01:17.609982       1 backfill.go:59] Enter Backfill ...
I0904 12:01:17.609991       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:17.610003       1 backfill.go:110] Leaving Backfill ...
I0904 12:01:17.610010       1 reclaim.go:47] Enter Reclaim ...
I0904 12:01:17.610016       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:01:17.610023       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:17.610034       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:01:17.610047       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:01:17.610054       1 preempt.go:103] Enter Preempt ...
I0904 12:01:17.610060       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:17.610071       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:01:17.610081       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:01:17.610090       1 preempt.go:270] Leaving Preempt ...
I0904 12:01:17.610260       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:01:17.610326       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:01:17.610342       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:17.610364       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:01:17.610377       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:17.610398       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:01:17.610412       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:01:17.610424       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:01:17.610438       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:17.610453       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:01:17.610492       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:01:17.610510       1 session.go:361] Session fd9c8267-a705-4e52-adc1-bd452e31d7a1 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:01:17.610518       1 session.go:375] Close Session fd9c8267-a705-4e52-adc1-bd452e31d7a1
I0904 12:01:17.610528       1 scheduler.go:133] End scheduling ...
I0904 12:01:19.569359       1 cache.go:1179] started sync node kwok-node-2
I0904 12:01:19.569428       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-2
I0904 12:01:19.569551       1 node_info.go:227] imageStates is map[]
I0904 12:01:20.899903       1 cache.go:1179] started sync node kwok-node-0
I0904 12:01:20.900170       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-0
I0904 12:01:20.900368       1 node_info.go:227] imageStates is map[]
I0904 12:01:27.476539       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:01:27.611146       1 scheduler.go:106] Start scheduling ...
I0904 12:01:27.611292       1 node_info.go:227] imageStates is map[]
I0904 12:01:27.611382       1 node_info.go:227] imageStates is map[]
I0904 12:01:27.611455       1 node_info.go:227] imageStates is map[]
I0904 12:01:27.611506       1 node_info.go:227] imageStates is map[]
I0904 12:01:27.611531       1 node_info.go:227] imageStates is map[]
I0904 12:01:27.611581       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:01:27.611635       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:01:27.611657       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:01:27.611703       1 session.go:230] Open Session 0af919fb-2c1b-49e3-8103-4cd16d019124 with <1> Job and <5> Queues
I0904 12:01:27.611728       1 session.go:233] Session 0af919fb-2c1b-49e3-8103-4cd16d019124 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:01:27.612055       1 sla.go:85] Enter sla plugin ...
I0904 12:01:27.612092       1 sla.go:154] Leaving sla plugin.
I0904 12:01:27.612102       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:01:27.612127       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:01:27.612138       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 12:01:27.612246       1 factory.go:59] Register preBinder predicates successfully
I0904 12:01:27.612259       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 12:01:27.612328       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:01:27.612371       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:01:27.612401       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 10000.00, pods 550.00>
I0904 12:01:27.612442       1 binpack.go:165] Enter binpack plugin ...
I0904 12:01:27.612449       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:01:27.612459       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:01:27.612467       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:01:27.612473       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:01:27.612484       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:27.612500       1 allocate.go:62] Enter Allocate ...
I0904 12:01:27.612505       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:27.612517       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:01:27.612523       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:01:27.612530       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:01:27.612535       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:01:27.612541       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:01:27.612547       1 allocate.go:83] Leaving Allocate ...
I0904 12:01:27.612554       1 backfill.go:59] Enter Backfill ...
I0904 12:01:27.612560       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:27.612570       1 backfill.go:110] Leaving Backfill ...
I0904 12:01:27.612576       1 reclaim.go:47] Enter Reclaim ...
I0904 12:01:27.612582       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:01:27.612588       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:27.612597       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:01:27.612610       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:01:27.612615       1 preempt.go:103] Enter Preempt ...
I0904 12:01:27.612620       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:27.612629       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:01:27.612637       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:01:27.612644       1 preempt.go:270] Leaving Preempt ...
I0904 12:01:27.612769       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:01:27.612799       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:01:27.612811       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:27.612827       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:01:27.612863       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:01:27.612870       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:01:27.612882       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:01:27.612893       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:27.612908       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:01:27.612921       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:27.612936       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:01:27.612957       1 session.go:361] Session 0af919fb-2c1b-49e3-8103-4cd16d019124 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:01:27.612966       1 session.go:375] Close Session 0af919fb-2c1b-49e3-8103-4cd16d019124
I0904 12:01:27.613025       1 scheduler.go:133] End scheduling ...
I0904 12:01:34.528856       1 cache.go:1179] started sync node integration-control-plane
I0904 12:01:34.528937       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:01:34.529068       1 node_info.go:227] imageStates is map[]
I0904 12:01:37.613769       1 scheduler.go:106] Start scheduling ...
I0904 12:01:37.614014       1 node_info.go:227] imageStates is map[]
I0904 12:01:37.614090       1 node_info.go:227] imageStates is map[]
I0904 12:01:37.614133       1 node_info.go:227] imageStates is map[]
I0904 12:01:37.614170       1 node_info.go:227] imageStates is map[]
I0904 12:01:37.614196       1 node_info.go:227] imageStates is map[]
I0904 12:01:37.614256       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:01:37.614324       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:01:37.614354       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:01:37.614377       1 session.go:230] Open Session 25c7f45c-882d-44b7-8767-f089f61da0dd with <1> Job and <5> Queues
I0904 12:01:37.614410       1 session.go:233] Session 25c7f45c-882d-44b7-8767-f089f61da0dd operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:01:37.620639       1 sla.go:85] Enter sla plugin ...
I0904 12:01:37.620692       1 sla.go:154] Leaving sla plugin.
I0904 12:01:37.620702       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:01:37.620731       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:01:37.620742       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00
I0904 12:01:37.620845       1 factory.go:59] Register preBinder predicates successfully
I0904 12:01:37.620857       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 12:01:37.620898       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:01:37.620942       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:01:37.621000       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 10000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:01:37.621027       1 binpack.go:165] Enter binpack plugin ...
I0904 12:01:37.621033       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:01:37.621040       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:01:37.621046       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:01:37.621050       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:01:37.621058       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:37.621072       1 allocate.go:62] Enter Allocate ...
I0904 12:01:37.621076       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:37.621084       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:01:37.621089       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:01:37.621095       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:01:37.621102       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:01:37.621106       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:01:37.621110       1 allocate.go:83] Leaving Allocate ...
I0904 12:01:37.621116       1 backfill.go:59] Enter Backfill ...
I0904 12:01:37.621120       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:37.621127       1 backfill.go:110] Leaving Backfill ...
I0904 12:01:37.621150       1 reclaim.go:47] Enter Reclaim ...
I0904 12:01:37.621154       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:01:37.621159       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:37.621165       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:01:37.621174       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:01:37.621178       1 preempt.go:103] Enter Preempt ...
I0904 12:01:37.621182       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:37.621188       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:01:37.621194       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:01:37.621203       1 preempt.go:270] Leaving Preempt ...
I0904 12:01:37.621298       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:37.621318       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:01:37.621327       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:37.621338       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:01:37.621348       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:01:37.621356       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:01:37.621367       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:37.621376       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:01:37.621415       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:01:37.621420       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:01:37.621444       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:01:37.621457       1 session.go:361] Session 25c7f45c-882d-44b7-8767-f089f61da0dd operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:01:37.621476       1 session.go:375] Close Session 25c7f45c-882d-44b7-8767-f089f61da0dd
I0904 12:01:37.621483       1 scheduler.go:133] End scheduling ...
I0904 12:01:44.704586       1 cache.go:1179] started sync node integration-control-plane
I0904 12:01:44.704619       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:01:44.704715       1 node_info.go:227] imageStates is map[]
I0904 12:01:47.622767       1 scheduler.go:106] Start scheduling ...
I0904 12:01:47.623068       1 node_info.go:227] imageStates is map[]
I0904 12:01:47.623122       1 node_info.go:227] imageStates is map[]
I0904 12:01:47.623169       1 node_info.go:227] imageStates is map[]
I0904 12:01:47.623193       1 node_info.go:227] imageStates is map[]
I0904 12:01:47.623207       1 node_info.go:227] imageStates is map[]
I0904 12:01:47.623242       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:01:47.623282       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:01:47.623318       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:01:47.623338       1 session.go:230] Open Session 8b48bf47-2e91-452a-b6d7-658da3d98845 with <1> Job and <5> Queues
I0904 12:01:47.623357       1 session.go:233] Session 8b48bf47-2e91-452a-b6d7-658da3d98845 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:01:47.623591       1 sla.go:85] Enter sla plugin ...
I0904 12:01:47.623625       1 sla.go:154] Leaving sla plugin.
I0904 12:01:47.623632       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:01:47.623652       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:01:47.623661       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00
I0904 12:01:47.623730       1 factory.go:59] Register preBinder predicates successfully
I0904 12:01:47.623739       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:01:47.623770       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:01:47.623799       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:01:47.623820       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 10000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:01:47.623846       1 binpack.go:165] Enter binpack plugin ...
I0904 12:01:47.623855       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:01:47.623862       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:01:47.623869       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:01:47.623873       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:01:47.623882       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:47.623913       1 allocate.go:62] Enter Allocate ...
I0904 12:01:47.623917       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:47.623926       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:01:47.623931       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:01:47.623936       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:01:47.623941       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:01:47.623945       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:01:47.623950       1 allocate.go:83] Leaving Allocate ...
I0904 12:01:47.623955       1 backfill.go:59] Enter Backfill ...
I0904 12:01:47.623960       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:47.623967       1 backfill.go:110] Leaving Backfill ...
I0904 12:01:47.623972       1 reclaim.go:47] Enter Reclaim ...
I0904 12:01:47.623976       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:01:47.623980       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:47.623986       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:01:47.623994       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:01:47.623998       1 preempt.go:103] Enter Preempt ...
I0904 12:01:47.624002       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:47.624008       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:01:47.624014       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:01:47.624019       1 preempt.go:270] Leaving Preempt ...
I0904 12:01:47.624113       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:47.624135       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:01:47.624145       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:47.624156       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:01:47.624163       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:01:47.624173       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:01:47.624179       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:47.624189       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:01:47.624221       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:01:47.624226       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:01:47.624234       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:01:47.624249       1 session.go:361] Session 8b48bf47-2e91-452a-b6d7-658da3d98845 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:01:47.624255       1 session.go:375] Close Session 8b48bf47-2e91-452a-b6d7-658da3d98845
I0904 12:01:47.624263       1 scheduler.go:133] End scheduling ...
I0904 12:01:57.477377       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:01:57.625081       1 scheduler.go:106] Start scheduling ...
I0904 12:01:57.625215       1 node_info.go:227] imageStates is map[]
I0904 12:01:57.625254       1 node_info.go:227] imageStates is map[]
I0904 12:01:57.625266       1 node_info.go:227] imageStates is map[]
I0904 12:01:57.625284       1 node_info.go:227] imageStates is map[]
I0904 12:01:57.625296       1 node_info.go:227] imageStates is map[]
I0904 12:01:57.625361       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:01:57.625405       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:01:57.625493       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:01:57.625581       1 session.go:230] Open Session bfdd860b-108d-469a-97e5-c6160ddb1b0c with <1> Job and <5> Queues
I0904 12:01:57.625603       1 session.go:233] Session bfdd860b-108d-469a-97e5-c6160ddb1b0c operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:01:57.625793       1 sla.go:85] Enter sla plugin ...
I0904 12:01:57.625819       1 sla.go:154] Leaving sla plugin.
I0904 12:01:57.625825       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:01:57.625839       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:01:57.625846       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:01:57.625911       1 factory.go:59] Register preBinder predicates successfully
I0904 12:01:57.625922       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:01:57.625949       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:01:57.625994       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:01:57.626012       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 10000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:01:57.626037       1 binpack.go:165] Enter binpack plugin ...
I0904 12:01:57.626054       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:01:57.626060       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:01:57.626066       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:01:57.626069       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:01:57.626077       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:57.626089       1 allocate.go:62] Enter Allocate ...
I0904 12:01:57.626095       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:57.626104       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:01:57.626108       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:01:57.626115       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:01:57.626119       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:01:57.626122       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:01:57.626126       1 allocate.go:83] Leaving Allocate ...
I0904 12:01:57.626133       1 backfill.go:59] Enter Backfill ...
I0904 12:01:57.626138       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:57.626146       1 backfill.go:110] Leaving Backfill ...
I0904 12:01:57.626152       1 reclaim.go:47] Enter Reclaim ...
I0904 12:01:57.626157       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:01:57.626162       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:57.626169       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:01:57.626177       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:01:57.626183       1 preempt.go:103] Enter Preempt ...
I0904 12:01:57.626187       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:01:57.626193       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:01:57.626199       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:01:57.626208       1 preempt.go:270] Leaving Preempt ...
I0904 12:01:57.626332       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:57.626354       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:01:57.626385       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:01:57.626392       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:01:57.626400       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:01:57.626414       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:57.626452       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:01:57.626478       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:01:57.626516       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:01:57.626527       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:01:57.626537       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:01:57.626560       1 session.go:361] Session bfdd860b-108d-469a-97e5-c6160ddb1b0c operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:01:57.626584       1 session.go:375] Close Session bfdd860b-108d-469a-97e5-c6160ddb1b0c
I0904 12:01:57.626604       1 scheduler.go:133] End scheduling ...
I0904 12:02:07.627747       1 scheduler.go:106] Start scheduling ...
I0904 12:02:07.627856       1 node_info.go:227] imageStates is map[]
I0904 12:02:07.627917       1 node_info.go:227] imageStates is map[]
I0904 12:02:07.627966       1 node_info.go:227] imageStates is map[]
I0904 12:02:07.628008       1 node_info.go:227] imageStates is map[]
I0904 12:02:07.628026       1 node_info.go:227] imageStates is map[]
I0904 12:02:07.628059       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:02:07.628125       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:02:07.628161       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:02:07.628179       1 session.go:230] Open Session 10ead90c-6619-46df-9e4c-511894077e7f with <1> Job and <5> Queues
I0904 12:02:07.628197       1 session.go:233] Session 10ead90c-6619-46df-9e4c-511894077e7f operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:02:07.628374       1 sla.go:85] Enter sla plugin ...
I0904 12:02:07.628402       1 sla.go:154] Leaving sla plugin.
I0904 12:02:07.628409       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:02:07.628427       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:02:07.628434       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:02:07.628490       1 factory.go:59] Register preBinder predicates successfully
I0904 12:02:07.628498       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:02:07.628528       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:02:07.628555       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:02:07.628576       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 10000.00, pods 550.00>
I0904 12:02:07.628600       1 binpack.go:165] Enter binpack plugin ...
I0904 12:02:07.628605       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:02:07.628611       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:02:07.628624       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:02:07.628628       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:02:07.628636       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:07.628669       1 allocate.go:62] Enter Allocate ...
I0904 12:02:07.628673       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:07.628681       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:02:07.628687       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:02:07.628692       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:02:07.628698       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:02:07.628702       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:02:07.628706       1 allocate.go:83] Leaving Allocate ...
I0904 12:02:07.628713       1 backfill.go:59] Enter Backfill ...
I0904 12:02:07.628717       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:07.628724       1 backfill.go:110] Leaving Backfill ...
I0904 12:02:07.628729       1 reclaim.go:47] Enter Reclaim ...
I0904 12:02:07.628733       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:02:07.628737       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:07.628745       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:02:07.628754       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:02:07.628775       1 preempt.go:103] Enter Preempt ...
I0904 12:02:07.628779       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:07.628785       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:02:07.628791       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:02:07.628795       1 preempt.go:270] Leaving Preempt ...
I0904 12:02:07.628891       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:02:07.628921       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:02:07.628928       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:07.628939       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:02:07.628964       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:02:07.628970       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:02:07.628977       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:02:07.628984       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:07.628994       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:02:07.629000       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:07.629011       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:02:07.629026       1 session.go:361] Session 10ead90c-6619-46df-9e4c-511894077e7f operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:02:07.629031       1 session.go:375] Close Session 10ead90c-6619-46df-9e4c-511894077e7f
I0904 12:02:07.629038       1 scheduler.go:133] End scheduling ...
I0904 12:02:17.629390       1 scheduler.go:106] Start scheduling ...
I0904 12:02:17.629533       1 node_info.go:227] imageStates is map[]
I0904 12:02:17.629591       1 node_info.go:227] imageStates is map[]
I0904 12:02:17.629618       1 node_info.go:227] imageStates is map[]
I0904 12:02:17.629635       1 node_info.go:227] imageStates is map[]
I0904 12:02:17.629653       1 node_info.go:227] imageStates is map[]
I0904 12:02:17.629691       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:02:17.629751       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:02:17.629770       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:02:17.629788       1 session.go:230] Open Session 685e17ef-f140-4f9e-92f9-d4ce598ff597 with <1> Job and <5> Queues
I0904 12:02:17.629811       1 session.go:233] Session 685e17ef-f140-4f9e-92f9-d4ce598ff597 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:02:17.630037       1 sla.go:85] Enter sla plugin ...
I0904 12:02:17.630066       1 sla.go:154] Leaving sla plugin.
I0904 12:02:17.630073       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:02:17.630093       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:02:17.630101       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:02:17.630262       1 factory.go:59] Register preBinder predicates successfully
I0904 12:02:17.630275       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>
I0904 12:02:17.630309       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:02:17.630345       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:02:17.630371       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 10000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>
I0904 12:02:17.630403       1 binpack.go:165] Enter binpack plugin ...
I0904 12:02:17.630413       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:02:17.630420       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:02:17.630427       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:02:17.630432       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:02:17.630441       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:17.630476       1 allocate.go:62] Enter Allocate ...
I0904 12:02:17.630481       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:17.630491       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:02:17.630496       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:02:17.630502       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:02:17.630507       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:02:17.630511       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:02:17.630515       1 allocate.go:83] Leaving Allocate ...
I0904 12:02:17.630522       1 backfill.go:59] Enter Backfill ...
I0904 12:02:17.630526       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:17.630534       1 backfill.go:110] Leaving Backfill ...
I0904 12:02:17.630539       1 reclaim.go:47] Enter Reclaim ...
I0904 12:02:17.630543       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:02:17.630548       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:17.630554       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:02:17.630564       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:02:17.630569       1 preempt.go:103] Enter Preempt ...
I0904 12:02:17.630573       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:17.630580       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:02:17.630586       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:02:17.630592       1 preempt.go:270] Leaving Preempt ...
I0904 12:02:17.630695       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:17.630720       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:02:17.630729       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:17.630743       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:02:17.630752       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:02:17.630761       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:02:17.630769       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:17.630778       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:02:17.630812       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:02:17.630817       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:02:17.630826       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:02:17.630839       1 session.go:361] Session 685e17ef-f140-4f9e-92f9-d4ce598ff597 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:02:17.630846       1 session.go:375] Close Session 685e17ef-f140-4f9e-92f9-d4ce598ff597
I0904 12:02:17.630853       1 scheduler.go:133] End scheduling ...
I0904 12:02:27.478021       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:02:27.631011       1 scheduler.go:106] Start scheduling ...
I0904 12:02:27.631149       1 node_info.go:227] imageStates is map[]
I0904 12:02:27.631183       1 node_info.go:227] imageStates is map[]
I0904 12:02:27.631216       1 node_info.go:227] imageStates is map[]
I0904 12:02:27.631242       1 node_info.go:227] imageStates is map[]
I0904 12:02:27.631309       1 node_info.go:227] imageStates is map[]
I0904 12:02:27.631377       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:02:27.631460       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:02:27.631488       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:02:27.631516       1 session.go:230] Open Session 069f9735-18ba-427d-88db-4f8d2cc25b2b with <1> Job and <5> Queues
I0904 12:02:27.631546       1 session.go:233] Session 069f9735-18ba-427d-88db-4f8d2cc25b2b operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:02:27.631853       1 sla.go:85] Enter sla plugin ...
I0904 12:02:27.631891       1 sla.go:154] Leaving sla plugin.
I0904 12:02:27.631902       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:02:27.631931       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:02:27.631948       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 12:02:27.632039       1 factory.go:59] Register preBinder predicates successfully
I0904 12:02:27.632050       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:02:27.632091       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:02:27.632130       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:02:27.632162       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 10000.00>
I0904 12:02:27.632199       1 binpack.go:165] Enter binpack plugin ...
I0904 12:02:27.632236       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:02:27.632247       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:02:27.632257       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:02:27.632263       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:02:27.632275       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:27.632291       1 allocate.go:62] Enter Allocate ...
I0904 12:02:27.632297       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:27.632332       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:02:27.632341       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:02:27.632348       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:02:27.632354       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:02:27.632360       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:02:27.632366       1 allocate.go:83] Leaving Allocate ...
I0904 12:02:27.632374       1 backfill.go:59] Enter Backfill ...
I0904 12:02:27.632384       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:27.632395       1 backfill.go:110] Leaving Backfill ...
I0904 12:02:27.632405       1 reclaim.go:47] Enter Reclaim ...
I0904 12:02:27.632412       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:02:27.632483       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:27.632528       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:02:27.632655       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:02:27.632664       1 preempt.go:103] Enter Preempt ...
I0904 12:02:27.632670       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:27.632679       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:02:27.632688       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:02:27.632695       1 preempt.go:270] Leaving Preempt ...
I0904 12:02:27.632812       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:02:27.632858       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:02:27.632870       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:27.632883       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:02:27.632917       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:02:27.632928       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:02:27.632962       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:02:27.632975       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:27.632990       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:02:27.633023       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:27.633041       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:02:27.633063       1 session.go:361] Session 069f9735-18ba-427d-88db-4f8d2cc25b2b operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:02:27.633092       1 session.go:375] Close Session 069f9735-18ba-427d-88db-4f8d2cc25b2b
I0904 12:02:27.633101       1 scheduler.go:133] End scheduling ...
I0904 12:02:37.633988       1 scheduler.go:106] Start scheduling ...
I0904 12:02:37.634177       1 node_info.go:227] imageStates is map[]
I0904 12:02:37.634275       1 node_info.go:227] imageStates is map[]
I0904 12:02:37.634300       1 node_info.go:227] imageStates is map[]
I0904 12:02:37.634328       1 node_info.go:227] imageStates is map[]
I0904 12:02:37.634357       1 node_info.go:227] imageStates is map[]
I0904 12:02:37.634404       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:02:37.634455       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:02:37.634501       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:02:37.634521       1 session.go:230] Open Session 776f0f13-58fd-421c-9feb-05166abb8900 with <1> Job and <5> Queues
I0904 12:02:37.634545       1 session.go:233] Session 776f0f13-58fd-421c-9feb-05166abb8900 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:02:37.634792       1 sla.go:85] Enter sla plugin ...
I0904 12:02:37.634831       1 sla.go:154] Leaving sla plugin.
I0904 12:02:37.634841       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:02:37.634866       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:02:37.634876       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 12:02:37.634957       1 factory.go:59] Register preBinder predicates successfully
I0904 12:02:37.634991       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 12:02:37.635031       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:02:37.635069       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:02:37.635120       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 10000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:02:37.635156       1 binpack.go:165] Enter binpack plugin ...
I0904 12:02:37.635163       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:02:37.635172       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:02:37.635181       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:02:37.635186       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:02:37.635197       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:37.635210       1 allocate.go:62] Enter Allocate ...
I0904 12:02:37.635216       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:37.635226       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:02:37.635233       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:02:37.635242       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:02:37.635249       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:02:37.635254       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:02:37.635259       1 allocate.go:83] Leaving Allocate ...
I0904 12:02:37.635269       1 backfill.go:59] Enter Backfill ...
I0904 12:02:37.635274       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:37.635283       1 backfill.go:110] Leaving Backfill ...
I0904 12:02:37.635288       1 reclaim.go:47] Enter Reclaim ...
I0904 12:02:37.635293       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:02:37.635299       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:37.635307       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:02:37.635318       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:02:37.635323       1 preempt.go:103] Enter Preempt ...
I0904 12:02:37.635328       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:37.635336       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:02:37.635344       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:02:37.635357       1 preempt.go:270] Leaving Preempt ...
I0904 12:02:37.635466       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:02:37.635504       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:02:37.635513       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:37.635530       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:02:37.635540       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:37.635581       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:02:37.635614       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:02:37.635626       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:02:37.635634       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:37.635645       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:02:37.635678       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:02:37.635691       1 session.go:361] Session 776f0f13-58fd-421c-9feb-05166abb8900 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:02:37.635700       1 session.go:375] Close Session 776f0f13-58fd-421c-9feb-05166abb8900
I0904 12:02:37.635708       1 scheduler.go:133] End scheduling ...
I0904 12:02:42.370545       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ResourceQuota" totalItems=6
I0904 12:02:47.636679       1 scheduler.go:106] Start scheduling ...
I0904 12:02:47.636754       1 node_info.go:227] imageStates is map[]
I0904 12:02:47.636794       1 node_info.go:227] imageStates is map[]
I0904 12:02:47.636812       1 node_info.go:227] imageStates is map[]
I0904 12:02:47.636821       1 node_info.go:227] imageStates is map[]
I0904 12:02:47.636831       1 node_info.go:227] imageStates is map[]
I0904 12:02:47.636854       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:02:47.636877       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:02:47.636889       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:02:47.636898       1 session.go:230] Open Session 2a823e19-6eb0-438d-9890-18d2f2e49ff1 with <1> Job and <5> Queues
I0904 12:02:47.636908       1 session.go:233] Session 2a823e19-6eb0-438d-9890-18d2f2e49ff1 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:02:47.637038       1 sla.go:85] Enter sla plugin ...
I0904 12:02:47.637054       1 sla.go:154] Leaving sla plugin.
I0904 12:02:47.637059       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:02:47.637079       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:02:47.637085       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00
I0904 12:02:47.637133       1 factory.go:59] Register preBinder predicates successfully
I0904 12:02:47.637138       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>
I0904 12:02:47.637156       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:02:47.637172       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:02:47.637184       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 10000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
I0904 12:02:47.637204       1 binpack.go:165] Enter binpack plugin ...
I0904 12:02:47.637208       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:02:47.637211       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:02:47.637215       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:02:47.637218       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:02:47.637223       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:47.637232       1 allocate.go:62] Enter Allocate ...
I0904 12:02:47.637235       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:47.637240       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:02:47.637243       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:02:47.637246       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:02:47.637248       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:02:47.637251       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:02:47.637253       1 allocate.go:83] Leaving Allocate ...
I0904 12:02:47.637257       1 backfill.go:59] Enter Backfill ...
I0904 12:02:47.637259       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:47.637263       1 backfill.go:110] Leaving Backfill ...
I0904 12:02:47.637266       1 reclaim.go:47] Enter Reclaim ...
I0904 12:02:47.637268       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:02:47.637270       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:47.637275       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:02:47.637280       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:02:47.637283       1 preempt.go:103] Enter Preempt ...
I0904 12:02:47.637285       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:47.637289       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:02:47.637292       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:02:47.637296       1 preempt.go:270] Leaving Preempt ...
I0904 12:02:47.637364       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:47.637383       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:02:47.637401       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:02:47.637404       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:02:47.637409       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:02:47.637422       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:47.637429       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:02:47.637442       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:47.637450       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:02:47.637454       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:02:47.637463       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:02:47.637470       1 session.go:361] Session 2a823e19-6eb0-438d-9890-18d2f2e49ff1 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:02:47.637474       1 session.go:375] Close Session 2a823e19-6eb0-438d-9890-18d2f2e49ff1
I0904 12:02:47.637478       1 scheduler.go:133] End scheduling ...
I0904 12:02:57.479321       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:02:57.637805       1 scheduler.go:106] Start scheduling ...
I0904 12:02:57.638044       1 node_info.go:227] imageStates is map[]
I0904 12:02:57.638118       1 node_info.go:227] imageStates is map[]
I0904 12:02:57.638164       1 node_info.go:227] imageStates is map[]
I0904 12:02:57.638209       1 node_info.go:227] imageStates is map[]
I0904 12:02:57.638253       1 node_info.go:227] imageStates is map[]
I0904 12:02:57.638330       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:02:57.638371       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:02:57.638411       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:02:57.638441       1 session.go:230] Open Session 8a7b6bce-c064-45b5-8a3f-a27292973ca1 with <1> Job and <5> Queues
I0904 12:02:57.638462       1 session.go:233] Session 8a7b6bce-c064-45b5-8a3f-a27292973ca1 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:02:57.638721       1 sla.go:85] Enter sla plugin ...
I0904 12:02:57.638754       1 sla.go:154] Leaving sla plugin.
I0904 12:02:57.638762       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:02:57.638783       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:02:57.638792       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00
I0904 12:02:57.638864       1 factory.go:59] Register preBinder predicates successfully
I0904 12:02:57.638902       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>
I0904 12:02:57.638960       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:02:57.639019       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:02:57.639044       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 10000.00, hugepages-2Mi 0.00, pods 550.00>
I0904 12:02:57.639073       1 binpack.go:165] Enter binpack plugin ...
I0904 12:02:57.639080       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:02:57.639090       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:02:57.639098       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:02:57.639103       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:02:57.639112       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:57.639125       1 allocate.go:62] Enter Allocate ...
I0904 12:02:57.639131       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:57.639143       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:02:57.639150       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:02:57.639157       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:02:57.639161       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:02:57.639166       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:02:57.639175       1 allocate.go:83] Leaving Allocate ...
I0904 12:02:57.639181       1 backfill.go:59] Enter Backfill ...
I0904 12:02:57.639186       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:57.639194       1 backfill.go:110] Leaving Backfill ...
I0904 12:02:57.639199       1 reclaim.go:47] Enter Reclaim ...
I0904 12:02:57.639204       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:02:57.639209       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:57.639216       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:02:57.639225       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:02:57.639230       1 preempt.go:103] Enter Preempt ...
I0904 12:02:57.639234       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:02:57.639241       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:02:57.639248       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:02:57.639254       1 preempt.go:270] Leaving Preempt ...
I0904 12:02:57.639380       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:57.639423       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:02:57.639438       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:02:57.639448       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:02:57.639454       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:57.639466       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:02:57.639504       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:02:57.639510       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:02:57.639519       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:02:57.639526       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:02:57.639538       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:02:57.639555       1 session.go:361] Session 8a7b6bce-c064-45b5-8a3f-a27292973ca1 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:02:57.639562       1 session.go:375] Close Session 8a7b6bce-c064-45b5-8a3f-a27292973ca1
I0904 12:02:57.639569       1 scheduler.go:133] End scheduling ...
I0904 12:03:07.640722       1 scheduler.go:106] Start scheduling ...
I0904 12:03:07.640810       1 node_info.go:227] imageStates is map[]
I0904 12:03:07.640865       1 node_info.go:227] imageStates is map[]
I0904 12:03:07.640895       1 node_info.go:227] imageStates is map[]
I0904 12:03:07.640916       1 node_info.go:227] imageStates is map[]
I0904 12:03:07.640939       1 node_info.go:227] imageStates is map[]
I0904 12:03:07.640961       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:03:07.641008       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:03:07.641021       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:03:07.641032       1 session.go:230] Open Session 8921fab8-b482-4467-807a-392633d293d0 with <1> Job and <5> Queues
I0904 12:03:07.641044       1 session.go:233] Session 8921fab8-b482-4467-807a-392633d293d0 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:03:07.641189       1 sla.go:85] Enter sla plugin ...
I0904 12:03:07.641207       1 sla.go:154] Leaving sla plugin.
I0904 12:03:07.641212       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:03:07.641226       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:03:07.641231       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00
I0904 12:03:07.641280       1 factory.go:59] Register preBinder predicates successfully
I0904 12:03:07.641285       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>
I0904 12:03:07.641305       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:03:07.641322       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:03:07.641351       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 10000.00, pods 550.00>
I0904 12:03:07.641369       1 binpack.go:165] Enter binpack plugin ...
I0904 12:03:07.641372       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:03:07.641377       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:03:07.641381       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:03:07.641384       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:03:07.641389       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:07.641397       1 allocate.go:62] Enter Allocate ...
I0904 12:03:07.641400       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:07.641405       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:03:07.641409       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:03:07.641412       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:03:07.641415       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:03:07.641417       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:03:07.641419       1 allocate.go:83] Leaving Allocate ...
I0904 12:03:07.641423       1 backfill.go:59] Enter Backfill ...
I0904 12:03:07.641426       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:07.641430       1 backfill.go:110] Leaving Backfill ...
I0904 12:03:07.641433       1 reclaim.go:47] Enter Reclaim ...
I0904 12:03:07.641435       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:03:07.641438       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:07.641441       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:03:07.641446       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:03:07.641449       1 preempt.go:103] Enter Preempt ...
I0904 12:03:07.641451       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:07.641455       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:03:07.641459       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:03:07.641462       1 preempt.go:270] Leaving Preempt ...
I0904 12:03:07.641523       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:03:07.641538       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:03:07.641542       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:07.641548       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:03:07.641552       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:07.641558       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:03:07.641563       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:03:07.641568       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:03:07.641572       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:07.641578       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:03:07.641593       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:03:07.641599       1 session.go:361] Session 8921fab8-b482-4467-807a-392633d293d0 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:03:07.641603       1 session.go:375] Close Session 8921fab8-b482-4467-807a-392633d293d0
I0904 12:03:07.641607       1 scheduler.go:133] End scheduling ...
I0904 12:03:16.724165       1 cache.go:1179] started sync node integration-control-plane
I0904 12:03:16.724188       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:03:16.724314       1 node_info.go:227] imageStates is map[]
I0904 12:03:17.642466       1 scheduler.go:106] Start scheduling ...
I0904 12:03:17.642577       1 node_info.go:227] imageStates is map[]
I0904 12:03:17.642606       1 node_info.go:227] imageStates is map[]
I0904 12:03:17.642623       1 node_info.go:227] imageStates is map[]
I0904 12:03:17.642670       1 node_info.go:227] imageStates is map[]
I0904 12:03:17.642691       1 node_info.go:227] imageStates is map[]
I0904 12:03:17.642723       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:03:17.642760       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:03:17.642780       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:03:17.642794       1 session.go:230] Open Session dfc248eb-88e4-40ab-815c-ff08b578b20e with <1> Job and <5> Queues
I0904 12:03:17.642814       1 session.go:233] Session dfc248eb-88e4-40ab-815c-ff08b578b20e operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:03:17.642991       1 sla.go:85] Enter sla plugin ...
I0904 12:03:17.643021       1 sla.go:154] Leaving sla plugin.
I0904 12:03:17.643028       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:03:17.643045       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:03:17.643053       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00
I0904 12:03:17.643113       1 factory.go:59] Register preBinder predicates successfully
I0904 12:03:17.643137       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 12:03:17.643166       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:03:17.643192       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:03:17.643213       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 10000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 12:03:17.643237       1 binpack.go:165] Enter binpack plugin ...
I0904 12:03:17.643242       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:03:17.643249       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:03:17.643256       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:03:17.643261       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:03:17.643269       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:17.643279       1 allocate.go:62] Enter Allocate ...
I0904 12:03:17.643283       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:17.643291       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:03:17.643295       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:03:17.643300       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:03:17.643304       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:03:17.643308       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:03:17.643311       1 allocate.go:83] Leaving Allocate ...
I0904 12:03:17.643316       1 backfill.go:59] Enter Backfill ...
I0904 12:03:17.643320       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:17.643327       1 backfill.go:110] Leaving Backfill ...
I0904 12:03:17.643331       1 reclaim.go:47] Enter Reclaim ...
I0904 12:03:17.643335       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:03:17.643339       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:17.643345       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:03:17.643353       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:03:17.643357       1 preempt.go:103] Enter Preempt ...
I0904 12:03:17.643361       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:17.643367       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:03:17.643373       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:03:17.643378       1 preempt.go:270] Leaving Preempt ...
I0904 12:03:17.643462       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:03:17.643497       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:03:17.643505       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:17.643515       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:03:17.643523       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:17.643533       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:03:17.643540       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:03:17.643546       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:03:17.643552       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:17.643559       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:03:17.643582       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:03:17.643591       1 session.go:361] Session dfc248eb-88e4-40ab-815c-ff08b578b20e operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:03:17.643602       1 session.go:375] Close Session dfc248eb-88e4-40ab-815c-ff08b578b20e
I0904 12:03:17.643608       1 scheduler.go:133] End scheduling ...
I0904 12:03:27.480342       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:03:27.643878       1 scheduler.go:106] Start scheduling ...
I0904 12:03:27.643958       1 node_info.go:227] imageStates is map[]
I0904 12:03:27.643973       1 node_info.go:227] imageStates is map[]
I0904 12:03:27.643987       1 node_info.go:227] imageStates is map[]
I0904 12:03:27.643998       1 node_info.go:227] imageStates is map[]
I0904 12:03:27.644030       1 node_info.go:227] imageStates is map[]
I0904 12:03:27.644059       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:03:27.644096       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:03:27.644122       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:03:27.644136       1 session.go:230] Open Session 4b00bc78-36bf-496a-ab9b-a43f0e7acf99 with <1> Job and <5> Queues
I0904 12:03:27.644148       1 session.go:233] Session 4b00bc78-36bf-496a-ab9b-a43f0e7acf99 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:03:27.644273       1 sla.go:85] Enter sla plugin ...
I0904 12:03:27.644293       1 sla.go:154] Leaving sla plugin.
I0904 12:03:27.644299       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:03:27.644315       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:03:27.644321       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00
I0904 12:03:27.644370       1 factory.go:59] Register preBinder predicates successfully
I0904 12:03:27.644387       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:03:27.644408       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:03:27.644438       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:03:27.644469       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 10000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 12:03:27.644488       1 binpack.go:165] Enter binpack plugin ...
I0904 12:03:27.644492       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:03:27.644496       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:03:27.644501       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:03:27.644504       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:03:27.644510       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:27.644519       1 allocate.go:62] Enter Allocate ...
I0904 12:03:27.644521       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:27.644529       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:03:27.644532       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:03:27.644535       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:03:27.644538       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:03:27.644540       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:03:27.644542       1 allocate.go:83] Leaving Allocate ...
I0904 12:03:27.644547       1 backfill.go:59] Enter Backfill ...
I0904 12:03:27.644549       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:27.644553       1 backfill.go:110] Leaving Backfill ...
I0904 12:03:27.644557       1 reclaim.go:47] Enter Reclaim ...
I0904 12:03:27.644559       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:03:27.644562       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:27.644566       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:03:27.644571       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:03:27.644574       1 preempt.go:103] Enter Preempt ...
I0904 12:03:27.644576       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:27.644582       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:03:27.644586       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:03:27.644589       1 preempt.go:270] Leaving Preempt ...
I0904 12:03:27.644656       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:27.644683       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:03:27.644689       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:03:27.644696       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:03:27.644700       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:27.644706       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:03:27.644723       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:03:27.644726       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:03:27.644731       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:03:27.644734       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:27.644742       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:03:27.644760       1 session.go:361] Session 4b00bc78-36bf-496a-ab9b-a43f0e7acf99 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:03:27.644766       1 session.go:375] Close Session 4b00bc78-36bf-496a-ab9b-a43f0e7acf99
I0904 12:03:27.644771       1 scheduler.go:133] End scheduling ...
I0904 12:03:37.153874       1 cache.go:1179] started sync node integration-control-plane
I0904 12:03:37.153902       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:03:37.153980       1 node_info.go:227] imageStates is map[]
I0904 12:03:37.644877       1 scheduler.go:106] Start scheduling ...
I0904 12:03:37.645045       1 node_info.go:227] imageStates is map[]
I0904 12:03:37.645094       1 node_info.go:227] imageStates is map[]
I0904 12:03:37.645108       1 node_info.go:227] imageStates is map[]
I0904 12:03:37.645120       1 node_info.go:227] imageStates is map[]
I0904 12:03:37.645130       1 node_info.go:227] imageStates is map[]
I0904 12:03:37.645156       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:03:37.645199       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:03:37.645209       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:03:37.645218       1 session.go:230] Open Session 00ada07b-069e-47f7-bd39-a24e5353bd23 with <1> Job and <5> Queues
I0904 12:03:37.645228       1 session.go:233] Session 00ada07b-069e-47f7-bd39-a24e5353bd23 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:03:37.645365       1 sla.go:85] Enter sla plugin ...
I0904 12:03:37.645381       1 sla.go:154] Leaving sla plugin.
I0904 12:03:37.645386       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:03:37.645396       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:03:37.645401       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00
I0904 12:03:37.645457       1 factory.go:59] Register preBinder predicates successfully
I0904 12:03:37.645471       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>
I0904 12:03:37.645490       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:03:37.645505       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:03:37.645529       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 10000.00, pods 550.00>
I0904 12:03:37.645556       1 binpack.go:165] Enter binpack plugin ...
I0904 12:03:37.645559       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:03:37.645562       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:03:37.645567       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:03:37.645569       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:03:37.645576       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:37.645582       1 allocate.go:62] Enter Allocate ...
I0904 12:03:37.645585       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:37.645589       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:03:37.645592       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:03:37.645595       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:03:37.645597       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:03:37.645599       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:03:37.645601       1 allocate.go:83] Leaving Allocate ...
I0904 12:03:37.645605       1 backfill.go:59] Enter Backfill ...
I0904 12:03:37.645607       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:37.645611       1 backfill.go:110] Leaving Backfill ...
I0904 12:03:37.645614       1 reclaim.go:47] Enter Reclaim ...
I0904 12:03:37.645616       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:03:37.645619       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:37.645622       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:03:37.645626       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:03:37.645629       1 preempt.go:103] Enter Preempt ...
I0904 12:03:37.645631       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:37.645634       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:03:37.645638       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:03:37.645640       1 preempt.go:270] Leaving Preempt ...
I0904 12:03:37.645707       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:03:37.645729       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:03:37.645734       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:37.645740       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:03:37.645765       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:03:37.645768       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:03:37.645772       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:03:37.645777       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:37.645782       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:03:37.645787       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:37.645793       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:03:37.645801       1 session.go:361] Session 00ada07b-069e-47f7-bd39-a24e5353bd23 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:03:37.645804       1 session.go:375] Close Session 00ada07b-069e-47f7-bd39-a24e5353bd23
I0904 12:03:37.645808       1 scheduler.go:133] End scheduling ...
I0904 12:03:47.646342       1 scheduler.go:106] Start scheduling ...
I0904 12:03:47.646486       1 node_info.go:227] imageStates is map[]
I0904 12:03:47.646558       1 node_info.go:227] imageStates is map[]
I0904 12:03:47.646591       1 node_info.go:227] imageStates is map[]
I0904 12:03:47.646609       1 node_info.go:227] imageStates is map[]
I0904 12:03:47.646624       1 node_info.go:227] imageStates is map[]
I0904 12:03:47.646657       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:03:47.646713       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:03:47.646747       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:03:47.646780       1 session.go:230] Open Session 9d7ef169-1931-405b-a016-258ce709f14f with <1> Job and <5> Queues
I0904 12:03:47.646798       1 session.go:233] Session 9d7ef169-1931-405b-a016-258ce709f14f operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:03:47.647011       1 sla.go:85] Enter sla plugin ...
I0904 12:03:47.647036       1 sla.go:154] Leaving sla plugin.
I0904 12:03:47.647043       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:03:47.647061       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:03:47.647069       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:03:47.647147       1 factory.go:59] Register preBinder predicates successfully
I0904 12:03:47.647173       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
I0904 12:03:47.647204       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:03:47.647235       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:03:47.647257       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 10000.00, pods 550.00>
I0904 12:03:47.647283       1 binpack.go:165] Enter binpack plugin ...
I0904 12:03:47.647289       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:03:47.647297       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:03:47.647304       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:03:47.647308       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:03:47.647318       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:47.647351       1 allocate.go:62] Enter Allocate ...
I0904 12:03:47.647356       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:47.647366       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:03:47.647371       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:03:47.647377       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:03:47.647381       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:03:47.647386       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:03:47.647390       1 allocate.go:83] Leaving Allocate ...
I0904 12:03:47.647395       1 backfill.go:59] Enter Backfill ...
I0904 12:03:47.647400       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:47.647408       1 backfill.go:110] Leaving Backfill ...
I0904 12:03:47.647413       1 reclaim.go:47] Enter Reclaim ...
I0904 12:03:47.647417       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:03:47.647421       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:47.647428       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:03:47.647437       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:03:47.647442       1 preempt.go:103] Enter Preempt ...
I0904 12:03:47.647446       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:47.647453       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:03:47.647460       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:03:47.647466       1 preempt.go:270] Leaving Preempt ...
I0904 12:03:47.647599       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:03:47.647637       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:03:47.647646       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:47.647661       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:03:47.647669       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:47.647681       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:03:47.647690       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:03:47.647698       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:03:47.647706       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:47.647717       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:03:47.647742       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:03:47.647755       1 session.go:361] Session 9d7ef169-1931-405b-a016-258ce709f14f operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:03:47.647761       1 session.go:375] Close Session 9d7ef169-1931-405b-a016-258ce709f14f
I0904 12:03:47.647769       1 scheduler.go:133] End scheduling ...
I0904 12:03:57.480788       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:03:57.648230       1 scheduler.go:106] Start scheduling ...
I0904 12:03:57.648450       1 node_info.go:227] imageStates is map[]
I0904 12:03:57.648529       1 node_info.go:227] imageStates is map[]
I0904 12:03:57.648647       1 node_info.go:227] imageStates is map[]
I0904 12:03:57.648727       1 node_info.go:227] imageStates is map[]
I0904 12:03:57.648756       1 node_info.go:227] imageStates is map[]
I0904 12:03:57.648805       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:03:57.648870       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:03:57.648938       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:03:57.648966       1 session.go:230] Open Session e73bc143-89e1-42ff-adad-63186e083e7f with <1> Job and <5> Queues
I0904 12:03:57.648998       1 session.go:233] Session e73bc143-89e1-42ff-adad-63186e083e7f operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:03:57.649343       1 sla.go:85] Enter sla plugin ...
I0904 12:03:57.649398       1 sla.go:154] Leaving sla plugin.
I0904 12:03:57.649412       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:03:57.649448       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:03:57.649462       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00
I0904 12:03:57.649577       1 factory.go:59] Register preBinder predicates successfully
I0904 12:03:57.649592       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:03:57.649658       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:03:57.649719       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:03:57.649770       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 10000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:03:57.649869       1 binpack.go:165] Enter binpack plugin ...
I0904 12:03:57.649881       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:03:57.649895       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:03:57.649909       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:03:57.649917       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:03:57.649934       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:57.649956       1 allocate.go:62] Enter Allocate ...
I0904 12:03:57.649966       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:57.649983       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:03:57.649993       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:03:57.650005       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:03:57.650022       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:03:57.650032       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:03:57.650040       1 allocate.go:83] Leaving Allocate ...
I0904 12:03:57.650050       1 backfill.go:59] Enter Backfill ...
I0904 12:03:57.650059       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:57.650074       1 backfill.go:110] Leaving Backfill ...
I0904 12:03:57.650090       1 reclaim.go:47] Enter Reclaim ...
I0904 12:03:57.650099       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:03:57.650108       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:57.650192       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:03:57.650212       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:03:57.650222       1 preempt.go:103] Enter Preempt ...
I0904 12:03:57.650230       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:03:57.650243       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:03:57.650258       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:03:57.650274       1 preempt.go:270] Leaving Preempt ...
I0904 12:03:57.650472       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:03:57.650548       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:03:57.650565       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:57.650583       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:03:57.650639       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:03:57.650652       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:03:57.650670       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:03:57.650727       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:57.650749       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:03:57.650793       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:03:57.650816       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:03:57.650841       1 session.go:361] Session e73bc143-89e1-42ff-adad-63186e083e7f operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:03:57.650881       1 session.go:375] Close Session e73bc143-89e1-42ff-adad-63186e083e7f
I0904 12:03:57.650892       1 scheduler.go:133] End scheduling ...
I0904 12:04:05.377767       1 reflector.go:946] "Watch close" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145" type="*v1alpha1.HyperNode" totalItems=7
I0904 12:04:07.306648       1 cache.go:1179] started sync node integration-control-plane
I0904 12:04:07.306677       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:04:07.306751       1 node_info.go:227] imageStates is map[]
I0904 12:04:07.651887       1 scheduler.go:106] Start scheduling ...
I0904 12:04:07.652184       1 node_info.go:227] imageStates is map[]
I0904 12:04:07.652239       1 node_info.go:227] imageStates is map[]
I0904 12:04:07.652268       1 node_info.go:227] imageStates is map[]
I0904 12:04:07.652284       1 node_info.go:227] imageStates is map[]
I0904 12:04:07.652300       1 node_info.go:227] imageStates is map[]
I0904 12:04:07.652331       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:04:07.652360       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:04:07.652374       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:04:07.652398       1 session.go:230] Open Session 1bf67b39-7f39-451b-b7a7-1bce746e5b33 with <1> Job and <5> Queues
I0904 12:04:07.652412       1 session.go:233] Session 1bf67b39-7f39-451b-b7a7-1bce746e5b33 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:04:07.652588       1 sla.go:85] Enter sla plugin ...
I0904 12:04:07.652608       1 sla.go:154] Leaving sla plugin.
I0904 12:04:07.652614       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:04:07.652631       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:04:07.652638       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00
I0904 12:04:07.652691       1 factory.go:59] Register preBinder predicates successfully
I0904 12:04:07.652711       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:04:07.652754       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:04:07.652794       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:04:07.652813       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 10000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>
I0904 12:04:07.652837       1 binpack.go:165] Enter binpack plugin ...
I0904 12:04:07.652841       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:04:07.652846       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:04:07.652852       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:04:07.652855       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:04:07.652862       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:07.652877       1 allocate.go:62] Enter Allocate ...
I0904 12:04:07.652880       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:07.652886       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:04:07.652889       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:04:07.652893       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:04:07.652895       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:04:07.652898       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:04:07.652901       1 allocate.go:83] Leaving Allocate ...
I0904 12:04:07.652906       1 backfill.go:59] Enter Backfill ...
I0904 12:04:07.652908       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:07.652913       1 backfill.go:110] Leaving Backfill ...
I0904 12:04:07.652917       1 reclaim.go:47] Enter Reclaim ...
I0904 12:04:07.652920       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:04:07.652923       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:07.652928       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:04:07.652934       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:04:07.652941       1 preempt.go:103] Enter Preempt ...
I0904 12:04:07.652944       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:07.652948       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:04:07.652953       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:04:07.652956       1 preempt.go:270] Leaving Preempt ...
I0904 12:04:07.653037       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:04:07.653062       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:04:07.653068       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:07.653075       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:04:07.653107       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:04:07.653123       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:04:07.653131       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:04:07.653136       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:07.653144       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:04:07.653151       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:07.653172       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:04:07.653200       1 session.go:361] Session 1bf67b39-7f39-451b-b7a7-1bce746e5b33 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:04:07.653216       1 session.go:375] Close Session 1bf67b39-7f39-451b-b7a7-1bce746e5b33
I0904 12:04:07.653220       1 scheduler.go:133] End scheduling ...
I0904 12:04:17.601097       1 cache.go:1179] started sync node integration-control-plane
I0904 12:04:17.601227       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:04:17.601355       1 node_info.go:227] imageStates is map[]
I0904 12:04:17.653989       1 scheduler.go:106] Start scheduling ...
I0904 12:04:17.654146       1 node_info.go:227] imageStates is map[]
I0904 12:04:17.654663       1 node_info.go:227] imageStates is map[]
I0904 12:04:17.654724       1 node_info.go:227] imageStates is map[]
I0904 12:04:17.654742       1 node_info.go:227] imageStates is map[]
I0904 12:04:17.654758       1 node_info.go:227] imageStates is map[]
I0904 12:04:17.654772       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:04:17.654818       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:04:17.655988       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:04:17.656082       1 session.go:230] Open Session 59ebb887-81db-4eeb-b5c2-14fb9d4a1239 with <1> Job and <5> Queues
I0904 12:04:17.656131       1 session.go:233] Session 59ebb887-81db-4eeb-b5c2-14fb9d4a1239 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:04:17.657119       1 sla.go:85] Enter sla plugin ...
I0904 12:04:17.657163       1 sla.go:154] Leaving sla plugin.
I0904 12:04:17.657174       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:04:17.657205       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:04:17.657216       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00
I0904 12:04:17.657318       1 factory.go:59] Register preBinder predicates successfully
I0904 12:04:17.657330       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:04:17.657374       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:04:17.657416       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
E0904 12:04:17.657447       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00> is less than its child queue <parent-a> capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 10000.00>
I0904 12:04:17.657482       1 binpack.go:165] Enter binpack plugin ...
I0904 12:04:17.657490       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:04:17.657500       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:04:17.657510       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:04:17.657521       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:04:17.657533       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:17.657582       1 allocate.go:62] Enter Allocate ...
I0904 12:04:17.657589       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:17.657602       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:04:17.657636       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:04:17.657644       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:04:17.657650       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:04:17.657656       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:04:17.657661       1 allocate.go:83] Leaving Allocate ...
I0904 12:04:17.657669       1 backfill.go:59] Enter Backfill ...
I0904 12:04:17.657676       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:17.657687       1 backfill.go:110] Leaving Backfill ...
I0904 12:04:17.657725       1 reclaim.go:47] Enter Reclaim ...
I0904 12:04:17.657759       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:04:17.657766       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:17.657776       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:04:17.657788       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:04:17.657822       1 preempt.go:103] Enter Preempt ...
I0904 12:04:17.657828       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:17.657838       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:04:17.657847       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:04:17.657855       1 preempt.go:270] Leaving Preempt ...
I0904 12:04:17.658005       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:17.658068       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:04:17.658083       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:17.658099       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:04:17.658111       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:04:17.658122       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:04:17.658130       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:17.658143       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:04:17.658178       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:04:17.658185       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:04:17.658195       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:04:17.658212       1 session.go:361] Session 59ebb887-81db-4eeb-b5c2-14fb9d4a1239 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:04:17.658220       1 session.go:375] Close Session 59ebb887-81db-4eeb-b5c2-14fb9d4a1239
I0904 12:04:17.658230       1 scheduler.go:133] End scheduling ...
I0904 12:04:27.481670       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:04:27.658971       1 scheduler.go:106] Start scheduling ...
I0904 12:04:27.659107       1 node_info.go:227] imageStates is map[]
I0904 12:04:27.659134       1 node_info.go:227] imageStates is map[]
I0904 12:04:27.659188       1 node_info.go:227] imageStates is map[]
I0904 12:04:27.659217       1 node_info.go:227] imageStates is map[]
I0904 12:04:27.659233       1 node_info.go:227] imageStates is map[]
I0904 12:04:27.659278       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:04:27.659324       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:04:27.659345       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:04:27.659361       1 session.go:230] Open Session ec6566d6-8d72-439c-a84a-373c8a0613fb with <1> Job and <5> Queues
I0904 12:04:27.659383       1 session.go:233] Session ec6566d6-8d72-439c-a84a-373c8a0613fb operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:04:27.659610       1 sla.go:85] Enter sla plugin ...
I0904 12:04:27.659644       1 sla.go:154] Leaving sla plugin.
I0904 12:04:27.659654       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:04:27.659674       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:04:27.659683       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00
I0904 12:04:27.659788       1 factory.go:59] Register preBinder predicates successfully
I0904 12:04:27.659798       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
I0904 12:04:27.659840       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:04:27.659876       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:04:27.659909       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:04:27.659943       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:04:27.659967       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:04:27.659986       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:04:27.660002       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:04:27.660012       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:04:27.660030       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:04:27.660052       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:04:27.660089       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:04:27.660105       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:04:27.660157       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:04:27.660206       1 binpack.go:165] Enter binpack plugin ...
I0904 12:04:27.660213       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:04:27.660259       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:04:27.660268       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:04:27.660273       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:04:27.660283       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:27.660297       1 allocate.go:62] Enter Allocate ...
I0904 12:04:27.660302       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:27.660313       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:04:27.660318       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:04:27.660325       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:04:27.660329       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:04:27.660334       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:04:27.660341       1 allocate.go:83] Leaving Allocate ...
I0904 12:04:27.660347       1 backfill.go:59] Enter Backfill ...
I0904 12:04:27.660353       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:27.660360       1 backfill.go:110] Leaving Backfill ...
I0904 12:04:27.660386       1 reclaim.go:47] Enter Reclaim ...
I0904 12:04:27.660391       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:04:27.660396       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:27.660403       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:04:27.660412       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:04:27.660418       1 preempt.go:103] Enter Preempt ...
I0904 12:04:27.660423       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:27.660429       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:04:27.660437       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:04:27.660443       1 preempt.go:270] Leaving Preempt ...
I0904 12:04:27.660566       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:27.660602       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:04:27.677498       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:04:27.677538       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:04:27.677545       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:27.677552       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:04:27.677558       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:27.677567       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:04:27.677573       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:04:27.677579       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:04:27.677593       1 session.go:361] Session ec6566d6-8d72-439c-a84a-373c8a0613fb operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:04:27.677598       1 session.go:375] Close Session ec6566d6-8d72-439c-a84a-373c8a0613fb
I0904 12:04:27.677606       1 scheduler.go:133] End scheduling ...
I0904 12:04:27.696478       1 cache.go:1179] started sync node integration-control-plane
I0904 12:04:27.696700       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:04:27.696991       1 node_info.go:227] imageStates is map[]
I0904 12:04:34.367476       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StorageClass" totalItems=6
I0904 12:04:37.677724       1 scheduler.go:106] Start scheduling ...
I0904 12:04:37.677866       1 node_info.go:227] imageStates is map[]
I0904 12:04:37.677897       1 node_info.go:227] imageStates is map[]
I0904 12:04:37.677944       1 node_info.go:227] imageStates is map[]
I0904 12:04:37.678000       1 node_info.go:227] imageStates is map[]
I0904 12:04:37.678056       1 node_info.go:227] imageStates is map[]
I0904 12:04:37.678113       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:04:37.678157       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:04:37.678205       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:04:37.678224       1 session.go:230] Open Session 53f90112-dc5a-42b7-affb-9243242112df with <1> Job and <5> Queues
I0904 12:04:37.678246       1 session.go:233] Session 53f90112-dc5a-42b7-affb-9243242112df operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:04:37.678482       1 sla.go:85] Enter sla plugin ...
I0904 12:04:37.678516       1 sla.go:154] Leaving sla plugin.
I0904 12:04:37.678525       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:04:37.678548       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:04:37.678558       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 12:04:37.678721       1 factory.go:59] Register preBinder predicates successfully
I0904 12:04:37.678733       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 12:04:37.678782       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:04:37.678841       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:04:37.678870       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:04:37.678883       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:04:37.678903       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:04:37.678921       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:04:37.678939       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:04:37.678950       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:04:37.678965       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:04:37.678986       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:04:37.679009       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:04:37.679029       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:04:37.679045       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:04:37.679095       1 binpack.go:165] Enter binpack plugin ...
I0904 12:04:37.679102       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:04:37.679110       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:04:37.679125       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:04:37.679130       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:04:37.679146       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:37.679181       1 allocate.go:62] Enter Allocate ...
I0904 12:04:37.679187       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:37.679197       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:04:37.679203       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:04:37.679209       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:04:37.679213       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:04:37.679218       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:04:37.679222       1 allocate.go:83] Leaving Allocate ...
I0904 12:04:37.679228       1 backfill.go:59] Enter Backfill ...
I0904 12:04:37.679233       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:37.679242       1 backfill.go:110] Leaving Backfill ...
I0904 12:04:37.679247       1 reclaim.go:47] Enter Reclaim ...
I0904 12:04:37.679252       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:04:37.679257       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:37.679265       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:04:37.679275       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:04:37.679279       1 preempt.go:103] Enter Preempt ...
I0904 12:04:37.679284       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:37.679291       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:04:37.679298       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:04:37.679304       1 preempt.go:270] Leaving Preempt ...
I0904 12:04:37.679401       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:04:37.679425       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:04:37.679434       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:37.679446       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:04:37.679454       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:37.679467       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:04:37.679502       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:04:37.679512       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:04:37.679520       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:37.679530       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:04:37.679566       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:04:37.679582       1 session.go:361] Session 53f90112-dc5a-42b7-affb-9243242112df operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:04:37.679589       1 session.go:375] Close Session 53f90112-dc5a-42b7-affb-9243242112df
I0904 12:04:37.679596       1 scheduler.go:133] End scheduling ...
I0904 12:04:47.680311       1 scheduler.go:106] Start scheduling ...
I0904 12:04:47.680604       1 node_info.go:227] imageStates is map[]
I0904 12:04:47.680721       1 node_info.go:227] imageStates is map[]
I0904 12:04:47.680763       1 node_info.go:227] imageStates is map[]
I0904 12:04:47.680905       1 node_info.go:227] imageStates is map[]
I0904 12:04:47.680951       1 node_info.go:227] imageStates is map[]
I0904 12:04:47.681059       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:04:47.681148       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:04:47.681187       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:04:47.681294       1 session.go:230] Open Session 3e846aa5-82e5-48fd-8bdc-a46cbadf1033 with <1> Job and <5> Queues
I0904 12:04:47.681344       1 session.go:233] Session 3e846aa5-82e5-48fd-8bdc-a46cbadf1033 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:04:47.681783       1 sla.go:85] Enter sla plugin ...
I0904 12:04:47.681884       1 sla.go:154] Leaving sla plugin.
I0904 12:04:47.681908       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:04:47.681954       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:04:47.681974       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 12:04:47.682115       1 factory.go:59] Register preBinder predicates successfully
I0904 12:04:47.682219       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 12:04:47.682316       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:04:47.682382       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:04:47.682514       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:04:47.682549       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:04:47.682596       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:04:47.682630       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:04:47.682656       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:04:47.682692       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:04:47.682749       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:04:47.682895       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:04:47.682952       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:04:47.682993       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:04:47.683031       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:04:47.683235       1 binpack.go:165] Enter binpack plugin ...
I0904 12:04:47.683261       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:04:47.683282       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:04:47.683299       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:04:47.683310       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:04:47.683328       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:47.683434       1 allocate.go:62] Enter Allocate ...
I0904 12:04:47.683455       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:47.683485       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:04:47.683497       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:04:47.683510       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:04:47.683526       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:04:47.683538       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:04:47.683546       1 allocate.go:83] Leaving Allocate ...
I0904 12:04:47.683559       1 backfill.go:59] Enter Backfill ...
I0904 12:04:47.683569       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:47.683587       1 backfill.go:110] Leaving Backfill ...
I0904 12:04:47.683598       1 reclaim.go:47] Enter Reclaim ...
I0904 12:04:47.683607       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:04:47.683621       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:47.683643       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:04:47.683663       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:04:47.683673       1 preempt.go:103] Enter Preempt ...
I0904 12:04:47.683683       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:47.683699       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:04:47.683713       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:04:47.683727       1 preempt.go:270] Leaving Preempt ...
I0904 12:04:47.684067       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:47.684207       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:04:47.684243       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:04:47.684268       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:04:47.684290       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:47.684313       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:04:47.684919       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:04:47.685040       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:04:47.685098       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:04:47.685121       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:47.685152       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:04:47.685294       1 session.go:361] Session 3e846aa5-82e5-48fd-8bdc-a46cbadf1033 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:04:47.685389       1 session.go:375] Close Session 3e846aa5-82e5-48fd-8bdc-a46cbadf1033
I0904 12:04:47.685417       1 scheduler.go:133] End scheduling ...
I0904 12:04:57.482549       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:04:57.685740       1 scheduler.go:106] Start scheduling ...
I0904 12:04:57.685911       1 node_info.go:227] imageStates is map[]
I0904 12:04:57.686002       1 node_info.go:227] imageStates is map[]
I0904 12:04:57.686023       1 node_info.go:227] imageStates is map[]
I0904 12:04:57.686044       1 node_info.go:227] imageStates is map[]
I0904 12:04:57.686064       1 node_info.go:227] imageStates is map[]
I0904 12:04:57.686110       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:04:57.686158       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:04:57.686176       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:04:57.686201       1 session.go:230] Open Session 7ca0708b-fd5f-46d2-b1bf-20e5d5447e17 with <1> Job and <5> Queues
I0904 12:04:57.686231       1 session.go:233] Session 7ca0708b-fd5f-46d2-b1bf-20e5d5447e17 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:04:57.686524       1 sla.go:85] Enter sla plugin ...
I0904 12:04:57.686557       1 sla.go:154] Leaving sla plugin.
I0904 12:04:57.686565       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:04:57.686587       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:04:57.686597       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:04:57.686676       1 factory.go:59] Register preBinder predicates successfully
I0904 12:04:57.686687       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:04:57.686727       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:04:57.686761       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:04:57.686792       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:04:57.686805       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:04:57.686831       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:04:57.686848       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:04:57.686861       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:04:57.686874       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:04:57.686895       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:04:57.686923       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:04:57.686944       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:04:57.686958       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:04:57.686977       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:04:57.687020       1 binpack.go:165] Enter binpack plugin ...
I0904 12:04:57.687026       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:04:57.687034       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:04:57.687041       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:04:57.687046       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:04:57.687055       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:57.687068       1 allocate.go:62] Enter Allocate ...
I0904 12:04:57.687073       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:57.687083       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:04:57.687088       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:04:57.687094       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:04:57.687099       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:04:57.687105       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:04:57.687110       1 allocate.go:83] Leaving Allocate ...
I0904 12:04:57.687115       1 backfill.go:59] Enter Backfill ...
I0904 12:04:57.687120       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:57.687128       1 backfill.go:110] Leaving Backfill ...
I0904 12:04:57.687133       1 reclaim.go:47] Enter Reclaim ...
I0904 12:04:57.687138       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:04:57.687143       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:57.687150       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:04:57.687162       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:04:57.687167       1 preempt.go:103] Enter Preempt ...
I0904 12:04:57.687171       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:04:57.687179       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:04:57.687187       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:04:57.687193       1 preempt.go:270] Leaving Preempt ...
I0904 12:04:57.687306       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:57.687332       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:04:57.687343       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:04:57.687353       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:04:57.687362       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:57.687374       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:04:57.687407       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:04:57.687412       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:04:57.687421       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:04:57.687429       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:04:57.687442       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:04:57.687460       1 session.go:361] Session 7ca0708b-fd5f-46d2-b1bf-20e5d5447e17 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:04:57.687468       1 session.go:375] Close Session 7ca0708b-fd5f-46d2-b1bf-20e5d5447e17
I0904 12:04:57.687475       1 scheduler.go:133] End scheduling ...
I0904 12:04:58.448729       1 cache.go:1179] started sync node integration-control-plane
I0904 12:04:58.448759       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:04:58.448880       1 node_info.go:227] imageStates is map[]
I0904 12:05:04.374484       1 reflector.go:946] "Watch close" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145" type="*v1alpha1.Numatopology" totalItems=7
I0904 12:05:07.688634       1 scheduler.go:106] Start scheduling ...
I0904 12:05:07.688886       1 node_info.go:227] imageStates is map[]
I0904 12:05:07.689016       1 node_info.go:227] imageStates is map[]
I0904 12:05:07.689069       1 node_info.go:227] imageStates is map[]
I0904 12:05:07.689106       1 node_info.go:227] imageStates is map[]
I0904 12:05:07.689141       1 node_info.go:227] imageStates is map[]
I0904 12:05:07.689221       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:05:07.689337       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:05:07.689367       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:05:07.689398       1 session.go:230] Open Session 64902bb3-4c33-48aa-896b-aec4886c1e98 with <1> Job and <5> Queues
I0904 12:05:07.689484       1 session.go:233] Session 64902bb3-4c33-48aa-896b-aec4886c1e98 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:05:07.689918       1 sla.go:85] Enter sla plugin ...
I0904 12:05:07.689969       1 sla.go:154] Leaving sla plugin.
I0904 12:05:07.689981       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:05:07.690015       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:05:07.690030       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00
I0904 12:05:07.690378       1 factory.go:59] Register preBinder predicates successfully
I0904 12:05:07.690397       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>
I0904 12:05:07.690471       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:05:07.690527       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:05:07.690577       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:05:07.690598       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:05:07.690621       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:05:07.690660       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:05:07.690686       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:05:07.690707       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:05:07.690734       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:05:07.690770       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:05:07.690796       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:05:07.690820       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:05:07.690837       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:05:07.690903       1 binpack.go:165] Enter binpack plugin ...
I0904 12:05:07.690913       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:05:07.690925       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:05:07.690936       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:05:07.690942       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:05:07.690956       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:07.690975       1 allocate.go:62] Enter Allocate ...
I0904 12:05:07.690987       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:07.691003       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:05:07.691011       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:05:07.691020       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:05:07.691026       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:05:07.691035       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:05:07.691043       1 allocate.go:83] Leaving Allocate ...
I0904 12:05:07.691051       1 backfill.go:59] Enter Backfill ...
I0904 12:05:07.691061       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:07.691074       1 backfill.go:110] Leaving Backfill ...
I0904 12:05:07.691082       1 reclaim.go:47] Enter Reclaim ...
I0904 12:05:07.691090       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:05:07.691096       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:07.691108       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:05:07.691124       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:05:07.691132       1 preempt.go:103] Enter Preempt ...
I0904 12:05:07.691138       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:07.691149       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:05:07.691161       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:05:07.691170       1 preempt.go:270] Leaving Preempt ...
I0904 12:05:07.691338       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:05:07.691370       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:05:07.691382       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:07.691406       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:05:07.691422       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:07.691443       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:05:07.691455       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:05:07.691470       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:05:07.691480       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:07.691498       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:05:07.691548       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:05:07.691571       1 session.go:361] Session 64902bb3-4c33-48aa-896b-aec4886c1e98 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:05:07.691583       1 session.go:375] Close Session 64902bb3-4c33-48aa-896b-aec4886c1e98
I0904 12:05:07.691594       1 scheduler.go:133] End scheduling ...
I0904 12:05:08.526214       1 cache.go:1179] started sync node integration-control-plane
I0904 12:05:08.526233       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:05:08.526346       1 node_info.go:227] imageStates is map[]
I0904 12:05:16.379530       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicaSet" totalItems=7
I0904 12:05:17.691923       1 scheduler.go:106] Start scheduling ...
I0904 12:05:17.692030       1 node_info.go:227] imageStates is map[]
I0904 12:05:17.692047       1 node_info.go:227] imageStates is map[]
I0904 12:05:17.692059       1 node_info.go:227] imageStates is map[]
I0904 12:05:17.692068       1 node_info.go:227] imageStates is map[]
I0904 12:05:17.692097       1 node_info.go:227] imageStates is map[]
I0904 12:05:17.692121       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:05:17.692145       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:05:17.692156       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:05:17.692168       1 session.go:230] Open Session c0c5b8fe-1139-4629-b6fd-720109bcb6f8 with <1> Job and <5> Queues
I0904 12:05:17.692181       1 session.go:233] Session c0c5b8fe-1139-4629-b6fd-720109bcb6f8 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:05:17.692318       1 sla.go:85] Enter sla plugin ...
I0904 12:05:17.692323       1 sla.go:154] Leaving sla plugin.
I0904 12:05:17.692327       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:05:17.692337       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:05:17.692344       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00
I0904 12:05:17.692388       1 factory.go:59] Register preBinder predicates successfully
I0904 12:05:17.692394       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:05:17.692413       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:05:17.692442       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:05:17.692456       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:05:17.692463       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:05:17.692473       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:05:17.692480       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:05:17.692487       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:05:17.692493       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:05:17.692504       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:05:17.692527       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:05:17.692543       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:05:17.692560       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:05:17.692578       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:05:17.692611       1 binpack.go:165] Enter binpack plugin ...
I0904 12:05:17.692614       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:05:17.692618       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:05:17.692622       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:05:17.692624       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:05:17.692630       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:17.692638       1 allocate.go:62] Enter Allocate ...
I0904 12:05:17.692640       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:17.692645       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:05:17.692647       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:05:17.692650       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:05:17.692653       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:05:17.692655       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:05:17.692657       1 allocate.go:83] Leaving Allocate ...
I0904 12:05:17.692660       1 backfill.go:59] Enter Backfill ...
I0904 12:05:17.692662       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:17.692665       1 backfill.go:110] Leaving Backfill ...
I0904 12:05:17.692669       1 reclaim.go:47] Enter Reclaim ...
I0904 12:05:17.692671       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:05:17.692673       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:17.692676       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:05:17.692681       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:05:17.692683       1 preempt.go:103] Enter Preempt ...
I0904 12:05:17.692685       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:17.692688       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:05:17.692692       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:05:17.692695       1 preempt.go:270] Leaving Preempt ...
I0904 12:05:17.692753       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:05:17.692774       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:05:17.692778       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:17.692783       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:05:17.692807       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:05:17.692819       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:05:17.692825       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:05:17.692838       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:17.692845       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:05:17.692857       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:17.692865       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:05:17.692873       1 session.go:361] Session c0c5b8fe-1139-4629-b6fd-720109bcb6f8 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:05:17.692876       1 session.go:375] Close Session c0c5b8fe-1139-4629-b6fd-720109bcb6f8
I0904 12:05:17.692880       1 scheduler.go:133] End scheduling ...
I0904 12:05:18.884102       1 cache.go:1179] started sync node integration-control-plane
I0904 12:05:18.884131       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:05:18.884268       1 node_info.go:227] imageStates is map[]
I0904 12:05:22.380953       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Pod" totalItems=7
I0904 12:05:26.372704       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Node" totalItems=28
I0904 12:05:27.483431       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:05:27.692982       1 scheduler.go:106] Start scheduling ...
I0904 12:05:27.693136       1 node_info.go:227] imageStates is map[]
I0904 12:05:27.693226       1 node_info.go:227] imageStates is map[]
I0904 12:05:27.693247       1 node_info.go:227] imageStates is map[]
I0904 12:05:27.693268       1 node_info.go:227] imageStates is map[]
I0904 12:05:27.693287       1 node_info.go:227] imageStates is map[]
I0904 12:05:27.693326       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:05:27.693367       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:05:27.693385       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:05:27.693408       1 session.go:230] Open Session 31ff475a-5c0f-4e4a-b68b-bde56abab0a3 with <1> Job and <5> Queues
I0904 12:05:27.693430       1 session.go:233] Session 31ff475a-5c0f-4e4a-b68b-bde56abab0a3 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:05:27.693646       1 sla.go:85] Enter sla plugin ...
I0904 12:05:27.693680       1 sla.go:154] Leaving sla plugin.
I0904 12:05:27.693688       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:05:27.693709       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:05:27.693719       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00
I0904 12:05:27.693794       1 factory.go:59] Register preBinder predicates successfully
I0904 12:05:27.693834       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>
I0904 12:05:27.693876       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:05:27.693910       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:05:27.693939       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:05:27.693951       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:05:27.693970       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:05:27.693992       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:05:27.694007       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:05:27.694026       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:05:27.694043       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:05:27.694062       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:05:27.694078       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:05:27.694096       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:05:27.694108       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:05:27.694159       1 binpack.go:165] Enter binpack plugin ...
I0904 12:05:27.694185       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:05:27.694193       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:05:27.694202       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:05:27.694206       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:05:27.694216       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:27.694230       1 allocate.go:62] Enter Allocate ...
I0904 12:05:27.694237       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:27.694246       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:05:27.694270       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:05:27.694276       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:05:27.694281       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:05:27.694286       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:05:27.694290       1 allocate.go:83] Leaving Allocate ...
I0904 12:05:27.694297       1 backfill.go:59] Enter Backfill ...
I0904 12:05:27.694304       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:27.694312       1 backfill.go:110] Leaving Backfill ...
I0904 12:05:27.694318       1 reclaim.go:47] Enter Reclaim ...
I0904 12:05:27.694322       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:05:27.694329       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:27.694336       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:05:27.694362       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:05:27.694367       1 preempt.go:103] Enter Preempt ...
I0904 12:05:27.694374       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:27.694382       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:05:27.694407       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:05:27.694413       1 preempt.go:270] Leaving Preempt ...
I0904 12:05:27.694507       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:27.694528       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:05:27.694565       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:05:27.694589       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:05:27.694599       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:05:27.694610       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:27.694622       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:05:27.694630       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:27.694642       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:05:27.694649       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:05:27.694657       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:05:27.694671       1 session.go:361] Session 31ff475a-5c0f-4e4a-b68b-bde56abab0a3 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:05:27.694676       1 session.go:375] Close Session 31ff475a-5c0f-4e4a-b68b-bde56abab0a3
I0904 12:05:27.694683       1 scheduler.go:133] End scheduling ...
I0904 12:05:29.223324       1 cache.go:1179] started sync node integration-control-plane
I0904 12:05:29.223590       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:05:29.223769       1 node_info.go:227] imageStates is map[]
I0904 12:05:30.376375       1 reflector.go:946] "Watch close" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145" type="*v1beta1.Queue" totalItems=12
I0904 12:05:37.695148       1 scheduler.go:106] Start scheduling ...
I0904 12:05:37.695256       1 node_info.go:227] imageStates is map[]
I0904 12:05:37.695294       1 node_info.go:227] imageStates is map[]
I0904 12:05:37.695303       1 node_info.go:227] imageStates is map[]
I0904 12:05:37.695313       1 node_info.go:227] imageStates is map[]
I0904 12:05:37.695321       1 node_info.go:227] imageStates is map[]
I0904 12:05:37.695341       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:05:37.695366       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:05:37.695385       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:05:37.695394       1 session.go:230] Open Session 159df900-bb90-419a-bdc8-b0f7b45124ed with <1> Job and <5> Queues
I0904 12:05:37.695406       1 session.go:233] Session 159df900-bb90-419a-bdc8-b0f7b45124ed operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:05:37.695528       1 sla.go:85] Enter sla plugin ...
I0904 12:05:37.695543       1 sla.go:154] Leaving sla plugin.
I0904 12:05:37.695548       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:05:37.695558       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:05:37.695563       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 12:05:37.695621       1 factory.go:59] Register preBinder predicates successfully
I0904 12:05:37.695627       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:05:37.695646       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:05:37.695673       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:05:37.695698       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:05:37.695705       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:05:37.695715       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:05:37.695722       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:05:37.695729       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:05:37.695745       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:05:37.695753       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:05:37.695765       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:05:37.695784       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:05:37.695801       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:05:37.695808       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:05:37.695830       1 binpack.go:165] Enter binpack plugin ...
I0904 12:05:37.695841       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:05:37.695845       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:05:37.695849       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:05:37.695852       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:05:37.695857       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:37.695864       1 allocate.go:62] Enter Allocate ...
I0904 12:05:37.695875       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:37.695879       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:05:37.695882       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:05:37.695885       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:05:37.695889       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:05:37.695891       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:05:37.695893       1 allocate.go:83] Leaving Allocate ...
I0904 12:05:37.695904       1 backfill.go:59] Enter Backfill ...
I0904 12:05:37.695907       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:37.695919       1 backfill.go:110] Leaving Backfill ...
I0904 12:05:37.695922       1 reclaim.go:47] Enter Reclaim ...
I0904 12:05:37.695924       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:05:37.695927       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:37.695931       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:05:37.695937       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:05:37.695948       1 preempt.go:103] Enter Preempt ...
I0904 12:05:37.695950       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:37.695954       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:05:37.695958       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:05:37.695960       1 preempt.go:270] Leaving Preempt ...
I0904 12:05:37.696024       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:37.696042       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:05:37.696060       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:05:37.696063       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:05:37.696067       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:05:37.696083       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:37.696090       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:05:37.696094       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:37.696100       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:05:37.696112       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:05:37.696117       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:05:37.696124       1 session.go:361] Session 159df900-bb90-419a-bdc8-b0f7b45124ed operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:05:37.696135       1 session.go:375] Close Session 159df900-bb90-419a-bdc8-b0f7b45124ed
I0904 12:05:37.696139       1 scheduler.go:133] End scheduling ...
I0904 12:05:47.696541       1 scheduler.go:106] Start scheduling ...
I0904 12:05:47.696689       1 node_info.go:227] imageStates is map[]
I0904 12:05:47.696770       1 node_info.go:227] imageStates is map[]
I0904 12:05:47.696789       1 node_info.go:227] imageStates is map[]
I0904 12:05:47.696837       1 node_info.go:227] imageStates is map[]
I0904 12:05:47.696854       1 node_info.go:227] imageStates is map[]
I0904 12:05:47.696904       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:05:47.696952       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:05:47.696993       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:05:47.697011       1 session.go:230] Open Session b1da3116-329a-42fb-bf03-dfabc1ecf643 with <1> Job and <5> Queues
I0904 12:05:47.697033       1 session.go:233] Session b1da3116-329a-42fb-bf03-dfabc1ecf643 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:05:47.697189       1 sla.go:85] Enter sla plugin ...
I0904 12:05:47.697204       1 sla.go:154] Leaving sla plugin.
I0904 12:05:47.697209       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:05:47.697220       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:05:47.697226       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00
I0904 12:05:47.697305       1 factory.go:59] Register preBinder predicates successfully
I0904 12:05:47.697321       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>
I0904 12:05:47.697343       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:05:47.697358       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:05:47.697372       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:05:47.697388       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:05:47.697398       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:05:47.697406       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:05:47.697413       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:05:47.697419       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:05:47.697430       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:05:47.697442       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:05:47.697451       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:05:47.697457       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:05:47.697464       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:05:47.697487       1 binpack.go:165] Enter binpack plugin ...
I0904 12:05:47.697501       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:05:47.697505       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:05:47.697510       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:05:47.697513       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:05:47.697518       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:47.697536       1 allocate.go:62] Enter Allocate ...
I0904 12:05:47.697539       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:47.697544       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:05:47.697546       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:05:47.697549       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:05:47.697551       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:05:47.697554       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:05:47.697555       1 allocate.go:83] Leaving Allocate ...
I0904 12:05:47.697558       1 backfill.go:59] Enter Backfill ...
I0904 12:05:47.697561       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:47.697565       1 backfill.go:110] Leaving Backfill ...
I0904 12:05:47.697568       1 reclaim.go:47] Enter Reclaim ...
I0904 12:05:47.697570       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:05:47.697572       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:47.697576       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:05:47.697580       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:05:47.697583       1 preempt.go:103] Enter Preempt ...
I0904 12:05:47.697586       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:47.697589       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:05:47.697593       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:05:47.697597       1 preempt.go:270] Leaving Preempt ...
I0904 12:05:47.697655       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:47.697673       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:05:47.697693       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:05:47.697697       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:05:47.697702       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:05:47.697706       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:47.697721       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:05:47.697725       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:47.697732       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:05:47.697736       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:05:47.697741       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:05:47.697748       1 session.go:361] Session b1da3116-329a-42fb-bf03-dfabc1ecf643 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:05:47.697751       1 session.go:375] Close Session b1da3116-329a-42fb-bf03-dfabc1ecf643
I0904 12:05:47.697755       1 scheduler.go:133] End scheduling ...
I0904 12:05:49.504279       1 cache.go:1179] started sync node integration-control-plane
I0904 12:05:49.504335       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:05:49.504500       1 node_info.go:227] imageStates is map[]
I0904 12:05:57.484268       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:05:57.698460       1 scheduler.go:106] Start scheduling ...
I0904 12:05:57.698903       1 node_info.go:227] imageStates is map[]
I0904 12:05:57.699021       1 node_info.go:227] imageStates is map[]
I0904 12:05:57.699063       1 node_info.go:227] imageStates is map[]
I0904 12:05:57.699093       1 node_info.go:227] imageStates is map[]
I0904 12:05:57.699120       1 node_info.go:227] imageStates is map[]
I0904 12:05:57.699212       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:05:57.699281       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:05:57.699310       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:05:57.699337       1 session.go:230] Open Session 396680f1-1c43-4fae-b710-e0438b91d505 with <1> Job and <5> Queues
I0904 12:05:57.699370       1 session.go:233] Session 396680f1-1c43-4fae-b710-e0438b91d505 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:05:57.699723       1 sla.go:85] Enter sla plugin ...
I0904 12:05:57.699736       1 sla.go:154] Leaving sla plugin.
I0904 12:05:57.699747       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:05:57.699774       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:05:57.699787       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00
I0904 12:05:57.699889       1 factory.go:59] Register preBinder predicates successfully
I0904 12:05:57.699901       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:05:57.699955       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:05:57.700002       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:05:57.700044       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:05:57.700060       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 0.00, memory 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:05:57.700080       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:05:57.700103       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.22>
I0904 12:05:57.700233       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:05:57.700249       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:05:57.700276       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:05:57.700304       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:05:57.700329       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:05:57.700353       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 0.00, memory 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:05:57.700368       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, capability: <cpu 0.00, memory 0.00, nvidia.com/A100 10000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:05:57.700431       1 binpack.go:165] Enter binpack plugin ...
I0904 12:05:57.700439       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:05:57.700451       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:05:57.700461       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:05:57.700467       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:05:57.700479       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:57.700495       1 allocate.go:62] Enter Allocate ...
I0904 12:05:57.700503       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:57.700516       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:05:57.700523       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:05:57.700530       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:05:57.700536       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:05:57.700542       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:05:57.700548       1 allocate.go:83] Leaving Allocate ...
I0904 12:05:57.700555       1 backfill.go:59] Enter Backfill ...
I0904 12:05:57.700562       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:57.700572       1 backfill.go:110] Leaving Backfill ...
I0904 12:05:57.700578       1 reclaim.go:47] Enter Reclaim ...
I0904 12:05:57.700584       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:05:57.700590       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:57.700600       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:05:57.700614       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:05:57.700620       1 preempt.go:103] Enter Preempt ...
I0904 12:05:57.700625       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:05:57.700635       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:05:57.700646       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:05:57.700654       1 preempt.go:270] Leaving Preempt ...
I0904 12:05:57.700755       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:57.700786       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:05:57.700798       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:57.700815       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:05:57.700826       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:05:57.700837       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:05:57.700846       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:05:57.700860       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI} nvidia.com/A100:{{9 0} {<nil>} 9 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI} nvidia.com/A100:{{9000 -3} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:05:57.700903       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:05:57.700910       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:05:57.700923       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:05:57.700942       1 session.go:361] Session 396680f1-1c43-4fae-b710-e0438b91d505 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00, nvidia.com/A100 9000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:05:57.700949       1 session.go:375] Close Session 396680f1-1c43-4fae-b710-e0438b91d505
I0904 12:05:57.700960       1 scheduler.go:133] End scheduling ...
I0904 12:05:59.830137       1 cache.go:1179] started sync node integration-control-plane
I0904 12:05:59.830160       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:05:59.830255       1 node_info.go:227] imageStates is map[]
I0904 12:06:03.373604       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Service" totalItems=7
I0904 12:06:07.701479       1 scheduler.go:106] Start scheduling ...
I0904 12:06:07.701583       1 node_info.go:227] imageStates is map[]
I0904 12:06:07.701621       1 node_info.go:227] imageStates is map[]
I0904 12:06:07.701641       1 node_info.go:227] imageStates is map[]
I0904 12:06:07.701663       1 node_info.go:227] imageStates is map[]
I0904 12:06:07.701673       1 node_info.go:227] imageStates is map[]
I0904 12:06:07.701694       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:06:07.701733       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:06:07.701751       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:06:07.701760       1 session.go:230] Open Session fad10229-c95c-4051-a461-db5e5989d53c with <1> Job and <5> Queues
I0904 12:06:07.701770       1 session.go:233] Session fad10229-c95c-4051-a461-db5e5989d53c operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:06:07.701909       1 sla.go:85] Enter sla plugin ...
I0904 12:06:07.701924       1 sla.go:154] Leaving sla plugin.
I0904 12:06:07.701928       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:06:07.701939       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:06:07.701944       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00
I0904 12:06:07.701989       1 factory.go:59] Register preBinder predicates successfully
I0904 12:06:07.702004       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:06:07.702022       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:06:07.702038       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:06:07.702056       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:06:07.702062       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:06:07.702074       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:06:07.702083       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:06:07.702093       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:06:07.702099       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:06:07.702111       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:06:07.702125       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:06:07.702149       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:06:07.702158       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:06:07.702168       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:06:07.702194       1 binpack.go:165] Enter binpack plugin ...
I0904 12:06:07.702197       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:06:07.702202       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:06:07.702206       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:06:07.702209       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:06:07.702214       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:07.702221       1 allocate.go:62] Enter Allocate ...
I0904 12:06:07.702224       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:07.702228       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:06:07.702231       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:06:07.702234       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:06:07.702237       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:06:07.702239       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:06:07.702241       1 allocate.go:83] Leaving Allocate ...
I0904 12:06:07.702244       1 backfill.go:59] Enter Backfill ...
I0904 12:06:07.702247       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:07.702251       1 backfill.go:110] Leaving Backfill ...
I0904 12:06:07.702254       1 reclaim.go:47] Enter Reclaim ...
I0904 12:06:07.702257       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:06:07.702259       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:07.702262       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:06:07.702267       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:06:07.702272       1 preempt.go:103] Enter Preempt ...
I0904 12:06:07.702274       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:07.702277       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:06:07.702281       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:06:07.702285       1 preempt.go:270] Leaving Preempt ...
I0904 12:06:07.702335       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:07.702348       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:06:07.702352       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:07.702362       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:06:07.702366       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:06:07.702370       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:06:07.702374       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:07.702379       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:06:07.715838       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:06:07.715869       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:06:07.715883       1 session.go:361] Session fad10229-c95c-4051-a461-db5e5989d53c operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:06:07.715887       1 session.go:375] Close Session fad10229-c95c-4051-a461-db5e5989d53c
I0904 12:06:07.715892       1 scheduler.go:133] End scheduling ...
I0904 12:06:17.716667       1 scheduler.go:106] Start scheduling ...
I0904 12:06:17.716949       1 node_info.go:227] imageStates is map[]
I0904 12:06:17.717036       1 node_info.go:227] imageStates is map[]
I0904 12:06:17.717064       1 node_info.go:227] imageStates is map[]
I0904 12:06:17.717109       1 node_info.go:227] imageStates is map[]
I0904 12:06:17.717173       1 node_info.go:227] imageStates is map[]
I0904 12:06:17.717222       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:06:17.717271       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:06:17.717292       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:06:17.717312       1 session.go:230] Open Session 871b574b-89db-40f7-a36f-806786ba956e with <1> Job and <5> Queues
I0904 12:06:17.717336       1 session.go:233] Session 871b574b-89db-40f7-a36f-806786ba956e operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:06:17.717587       1 sla.go:85] Enter sla plugin ...
I0904 12:06:17.717623       1 sla.go:154] Leaving sla plugin.
I0904 12:06:17.717632       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:06:17.717654       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:06:17.717664       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:06:17.717742       1 factory.go:59] Register preBinder predicates successfully
I0904 12:06:17.717775       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 12:06:17.717814       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:06:17.717847       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:06:17.717882       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:06:17.717894       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:06:17.717913       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:06:17.717940       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:06:17.717964       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:06:17.717985       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:06:17.718011       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:06:17.718039       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:06:17.718059       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:06:17.718075       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:06:17.718099       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:06:17.718144       1 binpack.go:165] Enter binpack plugin ...
I0904 12:06:17.718150       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:06:17.718158       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:06:17.718165       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:06:17.718170       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:06:17.718180       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:17.718195       1 allocate.go:62] Enter Allocate ...
I0904 12:06:17.718200       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:17.718210       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:06:17.718219       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:06:17.718227       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:06:17.718232       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:06:17.718237       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:06:17.718242       1 allocate.go:83] Leaving Allocate ...
I0904 12:06:17.718248       1 backfill.go:59] Enter Backfill ...
I0904 12:06:17.718253       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:17.718261       1 backfill.go:110] Leaving Backfill ...
I0904 12:06:17.718267       1 reclaim.go:47] Enter Reclaim ...
I0904 12:06:17.718272       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:06:17.718277       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:17.718285       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:06:17.718300       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:06:17.718306       1 preempt.go:103] Enter Preempt ...
I0904 12:06:17.718311       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:17.718319       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:06:17.718327       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:06:17.718336       1 preempt.go:270] Leaving Preempt ...
I0904 12:06:17.718430       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:06:17.718479       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:06:17.718488       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:17.718499       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:06:17.718544       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:06:17.718552       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:06:17.718561       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:06:17.718569       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:17.718580       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:06:17.718590       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:17.718602       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:06:17.718646       1 session.go:361] Session 871b574b-89db-40f7-a36f-806786ba956e operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:06:17.718653       1 session.go:375] Close Session 871b574b-89db-40f7-a36f-806786ba956e
I0904 12:06:17.718660       1 scheduler.go:133] End scheduling ...
I0904 12:06:25.369108       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Namespace" totalItems=7
I0904 12:06:26.371853       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PodDisruptionBudget" totalItems=8
I0904 12:06:27.484993       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:06:27.719204       1 scheduler.go:106] Start scheduling ...
I0904 12:06:27.719325       1 node_info.go:227] imageStates is map[]
I0904 12:06:27.719362       1 node_info.go:227] imageStates is map[]
I0904 12:06:27.719468       1 node_info.go:227] imageStates is map[]
I0904 12:06:27.719511       1 node_info.go:227] imageStates is map[]
I0904 12:06:27.719530       1 node_info.go:227] imageStates is map[]
I0904 12:06:27.719571       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:06:27.719610       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:06:27.719628       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:06:27.719643       1 session.go:230] Open Session 73902600-9291-4e10-b2e2-c580fc64b769 with <1> Job and <5> Queues
I0904 12:06:27.719663       1 session.go:233] Session 73902600-9291-4e10-b2e2-c580fc64b769 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:06:27.719877       1 sla.go:85] Enter sla plugin ...
I0904 12:06:27.719911       1 sla.go:154] Leaving sla plugin.
I0904 12:06:27.719920       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:06:27.719941       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:06:27.719950       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 12:06:27.720020       1 factory.go:59] Register preBinder predicates successfully
I0904 12:06:27.720051       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:06:27.720090       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:06:27.720281       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:06:27.720316       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:06:27.720330       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:06:27.720350       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:06:27.720374       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:06:27.720392       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:06:27.720413       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:06:27.720432       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:06:27.720478       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:06:27.720499       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:06:27.720516       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:06:27.720541       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:06:27.720593       1 binpack.go:165] Enter binpack plugin ...
I0904 12:06:27.720599       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:06:27.720606       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:06:27.720613       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:06:27.720619       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:06:27.720628       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:27.720641       1 allocate.go:62] Enter Allocate ...
I0904 12:06:27.720645       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:27.720654       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:06:27.720659       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:06:27.720665       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:06:27.720670       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:06:27.720674       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:06:27.720679       1 allocate.go:83] Leaving Allocate ...
I0904 12:06:27.720688       1 backfill.go:59] Enter Backfill ...
I0904 12:06:27.720693       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:27.720700       1 backfill.go:110] Leaving Backfill ...
I0904 12:06:27.720705       1 reclaim.go:47] Enter Reclaim ...
I0904 12:06:27.720709       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:06:27.720713       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:27.720728       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:06:27.720737       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:06:27.720741       1 preempt.go:103] Enter Preempt ...
I0904 12:06:27.720745       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:27.720751       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:06:27.720759       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:06:27.720765       1 preempt.go:270] Leaving Preempt ...
I0904 12:06:27.720858       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:27.720904       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:06:27.720914       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:06:27.720923       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:06:27.720931       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:27.720941       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:06:27.720979       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:06:27.720984       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:06:27.720992       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:06:27.720998       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:27.721008       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:06:27.721025       1 session.go:361] Session 73902600-9291-4e10-b2e2-c580fc64b769 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:06:27.721033       1 session.go:375] Close Session 73902600-9291-4e10-b2e2-c580fc64b769
I0904 12:06:27.721039       1 scheduler.go:133] End scheduling ...
I0904 12:06:30.369906       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PriorityClass" totalItems=10
I0904 12:06:30.827682       1 cache.go:1179] started sync node integration-control-plane
I0904 12:06:30.827715       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:06:30.827862       1 node_info.go:227] imageStates is map[]
I0904 12:06:37.721439       1 scheduler.go:106] Start scheduling ...
I0904 12:06:37.721640       1 node_info.go:227] imageStates is map[]
I0904 12:06:37.721741       1 node_info.go:227] imageStates is map[]
I0904 12:06:37.721814       1 node_info.go:227] imageStates is map[]
I0904 12:06:37.721836       1 node_info.go:227] imageStates is map[]
I0904 12:06:37.721854       1 node_info.go:227] imageStates is map[]
I0904 12:06:37.721940       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:06:37.722045       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:06:37.722064       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:06:37.722080       1 session.go:230] Open Session 3ec237d8-c704-42bd-ac6d-68e094b1eb94 with <1> Job and <5> Queues
I0904 12:06:37.722129       1 session.go:233] Session 3ec237d8-c704-42bd-ac6d-68e094b1eb94 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:06:37.722518       1 sla.go:85] Enter sla plugin ...
I0904 12:06:37.722571       1 sla.go:154] Leaving sla plugin.
I0904 12:06:37.722582       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:06:37.722604       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:06:37.722613       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:06:37.722732       1 factory.go:59] Register preBinder predicates successfully
I0904 12:06:37.722780       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 12:06:37.722821       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:06:37.722867       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:06:37.722893       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:06:37.722938       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:06:37.722969       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:06:37.723022       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:06:37.723056       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:06:37.723083       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:06:37.723103       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:06:37.723160       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:06:37.723184       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:06:37.723208       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:06:37.723230       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:06:37.723365       1 binpack.go:165] Enter binpack plugin ...
I0904 12:06:37.723409       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:06:37.723421       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:06:37.723430       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:06:37.723434       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:06:37.723444       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:37.723489       1 allocate.go:62] Enter Allocate ...
I0904 12:06:37.723544       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:37.723591       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:06:37.723599       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:06:37.723608       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:06:37.723613       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:06:37.723617       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:06:37.723649       1 allocate.go:83] Leaving Allocate ...
I0904 12:06:37.723658       1 backfill.go:59] Enter Backfill ...
I0904 12:06:37.723693       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:37.723705       1 backfill.go:110] Leaving Backfill ...
I0904 12:06:37.723740       1 reclaim.go:47] Enter Reclaim ...
I0904 12:06:37.723774       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:06:37.723781       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:37.723789       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:06:37.723800       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:06:37.723836       1 preempt.go:103] Enter Preempt ...
I0904 12:06:37.723843       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:37.723868       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:06:37.723912       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:06:37.723962       1 preempt.go:270] Leaving Preempt ...
I0904 12:06:37.724165       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:06:37.724226       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:06:37.724260       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:37.724277       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:06:37.724327       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:37.724393       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:06:37.724407       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:06:37.724453       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:06:37.724468       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:37.724489       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:06:37.724565       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:06:37.724589       1 session.go:361] Session 3ec237d8-c704-42bd-ac6d-68e094b1eb94 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:06:37.724596       1 session.go:375] Close Session 3ec237d8-c704-42bd-ac6d-68e094b1eb94
I0904 12:06:37.724606       1 scheduler.go:133] End scheduling ...
I0904 12:06:41.195348       1 cache.go:1179] started sync node integration-control-plane
I0904 12:06:41.195541       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:06:41.195819       1 node_info.go:227] imageStates is map[]
I0904 12:06:47.725588       1 scheduler.go:106] Start scheduling ...
I0904 12:06:47.725783       1 node_info.go:227] imageStates is map[]
I0904 12:06:47.725810       1 node_info.go:227] imageStates is map[]
I0904 12:06:47.725826       1 node_info.go:227] imageStates is map[]
I0904 12:06:47.725869       1 node_info.go:227] imageStates is map[]
I0904 12:06:47.725911       1 node_info.go:227] imageStates is map[]
I0904 12:06:47.725944       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:06:47.725998       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:06:47.726033       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:06:47.726049       1 session.go:230] Open Session abd10d8f-7908-462b-8d1f-31826982461b with <1> Job and <5> Queues
I0904 12:06:47.726065       1 session.go:233] Session abd10d8f-7908-462b-8d1f-31826982461b operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:06:47.726270       1 sla.go:85] Enter sla plugin ...
I0904 12:06:47.726302       1 sla.go:154] Leaving sla plugin.
I0904 12:06:47.726310       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:06:47.726332       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:06:47.726362       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:06:47.726458       1 factory.go:59] Register preBinder predicates successfully
I0904 12:06:47.726472       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:06:47.726512       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:06:47.726544       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:06:47.726595       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:06:47.726609       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:06:47.726654       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:06:47.726675       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:06:47.726692       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:06:47.726712       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:06:47.726730       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:06:47.726760       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:06:47.726779       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:06:47.726805       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:06:47.726823       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:06:47.726909       1 binpack.go:165] Enter binpack plugin ...
I0904 12:06:47.726916       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:06:47.726925       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:06:47.726933       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:06:47.726939       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:06:47.726957       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:47.726974       1 allocate.go:62] Enter Allocate ...
I0904 12:06:47.726982       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:47.726992       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:06:47.726997       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:06:47.727003       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:06:47.727007       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:06:47.727012       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:06:47.727017       1 allocate.go:83] Leaving Allocate ...
I0904 12:06:47.727023       1 backfill.go:59] Enter Backfill ...
I0904 12:06:47.727028       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:47.727036       1 backfill.go:110] Leaving Backfill ...
I0904 12:06:47.727042       1 reclaim.go:47] Enter Reclaim ...
I0904 12:06:47.727046       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:06:47.727049       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:47.727056       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:06:47.727065       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:06:47.727070       1 preempt.go:103] Enter Preempt ...
I0904 12:06:47.727074       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:47.727088       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:06:47.727095       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:06:47.727101       1 preempt.go:270] Leaving Preempt ...
I0904 12:06:47.727222       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:06:47.727266       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:06:47.727274       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:47.727290       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:06:47.727301       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:47.727317       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:06:47.727324       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:06:47.727334       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:06:47.727360       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:47.727388       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:06:47.727452       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:06:47.727473       1 session.go:361] Session abd10d8f-7908-462b-8d1f-31826982461b operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:06:47.727496       1 session.go:375] Close Session abd10d8f-7908-462b-8d1f-31826982461b
I0904 12:06:47.727506       1 scheduler.go:133] End scheduling ...
I0904 12:06:51.249772       1 cache.go:1179] started sync node integration-control-plane
I0904 12:06:51.249883       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:06:51.250024       1 node_info.go:227] imageStates is map[]
I0904 12:06:57.485485       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:06:57.727684       1 scheduler.go:106] Start scheduling ...
I0904 12:06:57.727821       1 node_info.go:227] imageStates is map[]
I0904 12:06:57.727889       1 node_info.go:227] imageStates is map[]
I0904 12:06:57.727949       1 node_info.go:227] imageStates is map[]
I0904 12:06:57.727992       1 node_info.go:227] imageStates is map[]
I0904 12:06:57.728031       1 node_info.go:227] imageStates is map[]
I0904 12:06:57.728068       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:06:57.728139       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:06:57.728174       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:06:57.728189       1 session.go:230] Open Session 666d6761-60b1-428c-a87a-346e12a4cc7d with <1> Job and <5> Queues
I0904 12:06:57.728214       1 session.go:233] Session 666d6761-60b1-428c-a87a-346e12a4cc7d operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:06:57.728425       1 sla.go:85] Enter sla plugin ...
I0904 12:06:57.728433       1 sla.go:154] Leaving sla plugin.
I0904 12:06:57.728440       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:06:57.728457       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:06:57.728466       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00
I0904 12:06:57.728536       1 factory.go:59] Register preBinder predicates successfully
I0904 12:06:57.728577       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>
I0904 12:06:57.728622       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:06:57.728652       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:06:57.728684       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:06:57.728695       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:06:57.728716       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:06:57.728734       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:06:57.728751       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:06:57.728765       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:06:57.728797       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:06:57.728824       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:06:57.728846       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:06:57.728889       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:06:57.728906       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:06:57.728956       1 binpack.go:165] Enter binpack plugin ...
I0904 12:06:57.728962       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:06:57.728969       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:06:57.728977       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:06:57.728981       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:06:57.728994       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:57.729025       1 allocate.go:62] Enter Allocate ...
I0904 12:06:57.729030       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:57.729039       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:06:57.729044       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:06:57.729049       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:06:57.729054       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:06:57.729058       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:06:57.729062       1 allocate.go:83] Leaving Allocate ...
I0904 12:06:57.729067       1 backfill.go:59] Enter Backfill ...
I0904 12:06:57.729071       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:57.729080       1 backfill.go:110] Leaving Backfill ...
I0904 12:06:57.729085       1 reclaim.go:47] Enter Reclaim ...
I0904 12:06:57.729090       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:06:57.729097       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:57.729104       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:06:57.729113       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:06:57.729135       1 preempt.go:103] Enter Preempt ...
I0904 12:06:57.729139       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:06:57.729146       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:06:57.729154       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:06:57.729159       1 preempt.go:270] Leaving Preempt ...
I0904 12:06:57.729271       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:06:57.729309       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:06:57.729317       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:57.729329       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:06:57.729338       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:57.729349       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:06:57.729356       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:06:57.729364       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:06:57.729370       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:06:57.729386       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:06:57.729446       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:06:57.729464       1 session.go:361] Session 666d6761-60b1-428c-a87a-346e12a4cc7d operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:06:57.729470       1 session.go:375] Close Session 666d6761-60b1-428c-a87a-346e12a4cc7d
I0904 12:06:57.729477       1 scheduler.go:133] End scheduling ...
I0904 12:07:01.365840       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSINode" totalItems=10
I0904 12:07:01.428893       1 cache.go:1179] started sync node integration-control-plane
I0904 12:07:01.428945       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:07:01.429533       1 node_info.go:227] imageStates is map[]
I0904 12:07:07.729751       1 scheduler.go:106] Start scheduling ...
I0904 12:07:07.729875       1 node_info.go:227] imageStates is map[]
I0904 12:07:07.729930       1 node_info.go:227] imageStates is map[]
I0904 12:07:07.729965       1 node_info.go:227] imageStates is map[]
I0904 12:07:07.729985       1 node_info.go:227] imageStates is map[]
I0904 12:07:07.730016       1 node_info.go:227] imageStates is map[]
I0904 12:07:07.730058       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:07:07.730089       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:07:07.730169       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:07:07.730197       1 session.go:230] Open Session d9f68b84-509f-492a-865e-5bf9e0fcb3c4 with <1> Job and <5> Queues
I0904 12:07:07.730212       1 session.go:233] Session d9f68b84-509f-492a-865e-5bf9e0fcb3c4 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:07:07.730422       1 sla.go:85] Enter sla plugin ...
I0904 12:07:07.730442       1 sla.go:154] Leaving sla plugin.
I0904 12:07:07.730447       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:07:07.730461       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:07:07.730467       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00
I0904 12:07:07.730517       1 factory.go:59] Register preBinder predicates successfully
I0904 12:07:07.730522       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
I0904 12:07:07.730545       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:07:07.730563       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:07:07.730581       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:07:07.730588       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:07:07.730599       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:07:07.730646       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:07:07.730661       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:07:07.730682       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:07:07.730694       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:07:07.730710       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:07:07.730721       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:07:07.730729       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:07:07.730743       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:07:07.730773       1 binpack.go:165] Enter binpack plugin ...
I0904 12:07:07.730788       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:07:07.730794       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:07:07.730799       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:07:07.730802       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:07:07.730810       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:07.730823       1 allocate.go:62] Enter Allocate ...
I0904 12:07:07.730826       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:07.730831       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:07:07.730834       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:07:07.730837       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:07:07.730840       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:07:07.730842       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:07:07.730844       1 allocate.go:83] Leaving Allocate ...
I0904 12:07:07.730848       1 backfill.go:59] Enter Backfill ...
I0904 12:07:07.730850       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:07.730855       1 backfill.go:110] Leaving Backfill ...
I0904 12:07:07.730859       1 reclaim.go:47] Enter Reclaim ...
I0904 12:07:07.730861       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:07:07.730864       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:07.730868       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:07:07.730873       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:07:07.730877       1 preempt.go:103] Enter Preempt ...
I0904 12:07:07.730879       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:07.730883       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:07:07.730887       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:07:07.730890       1 preempt.go:270] Leaving Preempt ...
I0904 12:07:07.730974       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:07:07.730989       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:07:07.730993       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:07.731000       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:07:07.731005       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:07.731012       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:07:07.731017       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:07:07.731022       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:07:07.731025       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:07.731031       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:07:07.731056       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:07:07.731067       1 session.go:361] Session d9f68b84-509f-492a-865e-5bf9e0fcb3c4 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:07:07.731071       1 session.go:375] Close Session d9f68b84-509f-492a-865e-5bf9e0fcb3c4
I0904 12:07:07.731076       1 scheduler.go:133] End scheduling ...
I0904 12:07:17.731440       1 scheduler.go:106] Start scheduling ...
I0904 12:07:17.731596       1 node_info.go:227] imageStates is map[]
I0904 12:07:17.731654       1 node_info.go:227] imageStates is map[]
I0904 12:07:17.731738       1 node_info.go:227] imageStates is map[]
I0904 12:07:17.731796       1 node_info.go:227] imageStates is map[]
I0904 12:07:17.731843       1 node_info.go:227] imageStates is map[]
I0904 12:07:17.731889       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:07:17.731955       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:07:17.731978       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:07:17.731999       1 session.go:230] Open Session 476d80e5-0c79-42d9-b15a-1e5f731431f5 with <1> Job and <5> Queues
I0904 12:07:17.732021       1 session.go:233] Session 476d80e5-0c79-42d9-b15a-1e5f731431f5 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:07:17.732246       1 sla.go:85] Enter sla plugin ...
I0904 12:07:17.732279       1 sla.go:154] Leaving sla plugin.
I0904 12:07:17.732288       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:07:17.732311       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:07:17.732320       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00
I0904 12:07:17.732404       1 factory.go:59] Register preBinder predicates successfully
I0904 12:07:17.732415       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
I0904 12:07:17.732511       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:07:17.732547       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:07:17.732582       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:07:17.732597       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:07:17.732628       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:07:17.732653       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:07:17.732668       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:07:17.732685       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:07:17.732719       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:07:17.732754       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:07:17.732773       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:07:17.732801       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:07:17.732818       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:07:17.732877       1 binpack.go:165] Enter binpack plugin ...
I0904 12:07:17.732909       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:07:17.732919       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:07:17.732927       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:07:17.732932       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:07:17.732943       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:17.732958       1 allocate.go:62] Enter Allocate ...
I0904 12:07:17.732963       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:17.732974       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:07:17.732980       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:07:17.732986       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:07:17.732991       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:07:17.732996       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:07:17.733000       1 allocate.go:83] Leaving Allocate ...
I0904 12:07:17.733006       1 backfill.go:59] Enter Backfill ...
I0904 12:07:17.733013       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:17.733021       1 backfill.go:110] Leaving Backfill ...
I0904 12:07:17.733031       1 reclaim.go:47] Enter Reclaim ...
I0904 12:07:17.733036       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:07:17.733041       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:17.733049       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:07:17.733058       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:07:17.733063       1 preempt.go:103] Enter Preempt ...
I0904 12:07:17.733068       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:17.733076       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:07:17.733083       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:07:17.733089       1 preempt.go:270] Leaving Preempt ...
I0904 12:07:17.733189       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:07:17.733209       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:07:17.733217       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:17.733228       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:07:17.733284       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:07:17.733291       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:07:17.733305       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:07:17.733316       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:17.733353       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:07:17.733362       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:17.733375       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:07:17.733396       1 session.go:361] Session 476d80e5-0c79-42d9-b15a-1e5f731431f5 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:07:17.733402       1 session.go:375] Close Session 476d80e5-0c79-42d9-b15a-1e5f731431f5
I0904 12:07:17.733410       1 scheduler.go:133] End scheduling ...
I0904 12:07:27.486502       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:07:27.734086       1 scheduler.go:106] Start scheduling ...
I0904 12:07:27.734166       1 node_info.go:227] imageStates is map[]
I0904 12:07:27.734236       1 node_info.go:227] imageStates is map[]
I0904 12:07:27.734263       1 node_info.go:227] imageStates is map[]
I0904 12:07:27.734282       1 node_info.go:227] imageStates is map[]
I0904 12:07:27.734308       1 node_info.go:227] imageStates is map[]
I0904 12:07:27.734339       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:07:27.734379       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:07:27.734404       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:07:27.734418       1 session.go:230] Open Session e88e6806-e967-4154-80b6-47aaae93cb56 with <1> Job and <5> Queues
I0904 12:07:27.734444       1 session.go:233] Session e88e6806-e967-4154-80b6-47aaae93cb56 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:07:27.734621       1 sla.go:85] Enter sla plugin ...
I0904 12:07:27.734642       1 sla.go:154] Leaving sla plugin.
I0904 12:07:27.734649       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:07:27.734762       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:07:27.734794       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00
I0904 12:07:27.734987       1 factory.go:59] Register preBinder predicates successfully
I0904 12:07:27.735038       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:07:27.735083       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:07:27.735112       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:07:27.735158       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:07:27.735174       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:07:27.735198       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:07:27.735211       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:07:27.735222       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:07:27.735237       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:07:27.735260       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:07:27.735288       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:07:27.735305       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:07:27.735514       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:07:27.735550       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:07:27.735621       1 binpack.go:165] Enter binpack plugin ...
I0904 12:07:27.735627       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:07:27.735632       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:07:27.735637       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:07:27.735640       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:07:27.735648       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:27.735662       1 allocate.go:62] Enter Allocate ...
I0904 12:07:27.735666       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:27.735674       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:07:27.735681       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:07:27.735685       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:07:27.735688       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:07:27.735691       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:07:27.735695       1 allocate.go:83] Leaving Allocate ...
I0904 12:07:27.735706       1 backfill.go:59] Enter Backfill ...
I0904 12:07:27.735744       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:27.735756       1 backfill.go:110] Leaving Backfill ...
I0904 12:07:27.735763       1 reclaim.go:47] Enter Reclaim ...
I0904 12:07:27.735769       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:07:27.735775       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:27.735785       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:07:27.735796       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:07:27.735802       1 preempt.go:103] Enter Preempt ...
I0904 12:07:27.735809       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:27.735817       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:07:27.735828       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:07:27.735838       1 preempt.go:270] Leaving Preempt ...
I0904 12:07:27.735986       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:27.736040       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:07:27.736119       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:07:27.736147       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:07:27.736162       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:07:27.736178       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:27.736200       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:07:27.736212       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:27.736230       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:07:27.736240       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:07:27.736251       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:07:27.736278       1 session.go:361] Session e88e6806-e967-4154-80b6-47aaae93cb56 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:07:27.736317       1 session.go:375] Close Session e88e6806-e967-4154-80b6-47aaae93cb56
I0904 12:07:27.736330       1 scheduler.go:133] End scheduling ...
I0904 12:07:37.736734       1 scheduler.go:106] Start scheduling ...
I0904 12:07:37.736867       1 node_info.go:227] imageStates is map[]
I0904 12:07:37.736895       1 node_info.go:227] imageStates is map[]
I0904 12:07:37.736907       1 node_info.go:227] imageStates is map[]
I0904 12:07:37.736917       1 node_info.go:227] imageStates is map[]
I0904 12:07:37.736948       1 node_info.go:227] imageStates is map[]
I0904 12:07:37.736981       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:07:37.737013       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:07:37.737030       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:07:37.737047       1 session.go:230] Open Session ed93fbcb-95d4-40b5-96b0-9cec6d8439fa with <1> Job and <5> Queues
I0904 12:07:37.737066       1 session.go:233] Session ed93fbcb-95d4-40b5-96b0-9cec6d8439fa operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:07:37.737266       1 sla.go:85] Enter sla plugin ...
I0904 12:07:37.737285       1 sla.go:154] Leaving sla plugin.
I0904 12:07:37.737290       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:07:37.737303       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:07:37.737309       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00
I0904 12:07:37.737361       1 factory.go:59] Register preBinder predicates successfully
I0904 12:07:37.737367       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 12:07:37.737387       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:07:37.737403       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:07:37.737421       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:07:37.737429       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:07:37.737469       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:07:37.737498       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:07:37.737521       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:07:37.737533       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:07:37.737542       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:07:37.737560       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:07:37.737569       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:07:37.737579       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:07:37.737587       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:07:37.737618       1 binpack.go:165] Enter binpack plugin ...
I0904 12:07:37.737632       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:07:37.737637       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:07:37.737642       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:07:37.737645       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:07:37.737652       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:37.737662       1 allocate.go:62] Enter Allocate ...
I0904 12:07:37.737664       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:37.737670       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:07:37.737672       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:07:37.737675       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:07:37.737677       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:07:37.737679       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:07:37.737682       1 allocate.go:83] Leaving Allocate ...
I0904 12:07:37.737685       1 backfill.go:59] Enter Backfill ...
I0904 12:07:37.737688       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:37.737691       1 backfill.go:110] Leaving Backfill ...
I0904 12:07:37.737695       1 reclaim.go:47] Enter Reclaim ...
I0904 12:07:37.737697       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:07:37.737699       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:37.737703       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:07:37.737714       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:07:37.737718       1 preempt.go:103] Enter Preempt ...
I0904 12:07:37.737721       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:37.737726       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:07:37.737733       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:07:37.737737       1 preempt.go:270] Leaving Preempt ...
I0904 12:07:37.737814       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:07:37.737851       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:07:37.737877       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:37.737887       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:07:37.737925       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:07:37.737953       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:07:37.737965       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:07:37.737973       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:37.737987       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:07:37.738002       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:37.738031       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:07:37.738062       1 session.go:361] Session ed93fbcb-95d4-40b5-96b0-9cec6d8439fa operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:07:37.738070       1 session.go:375] Close Session ed93fbcb-95d4-40b5-96b0-9cec6d8439fa
I0904 12:07:37.738081       1 scheduler.go:133] End scheduling ...
I0904 12:07:47.738182       1 scheduler.go:106] Start scheduling ...
I0904 12:07:47.738311       1 node_info.go:227] imageStates is map[]
I0904 12:07:47.738340       1 node_info.go:227] imageStates is map[]
I0904 12:07:47.738367       1 node_info.go:227] imageStates is map[]
I0904 12:07:47.738424       1 node_info.go:227] imageStates is map[]
I0904 12:07:47.738473       1 node_info.go:227] imageStates is map[]
I0904 12:07:47.738605       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:07:47.738691       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:07:47.738711       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:07:47.738734       1 session.go:230] Open Session 93b87557-6d82-4cb3-9fe4-4e6c15e9adcf with <1> Job and <5> Queues
I0904 12:07:47.738753       1 session.go:233] Session 93b87557-6d82-4cb3-9fe4-4e6c15e9adcf operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:07:47.739047       1 sla.go:85] Enter sla plugin ...
I0904 12:07:47.739091       1 sla.go:154] Leaving sla plugin.
I0904 12:07:47.739102       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:07:47.739189       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:07:47.739276       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:07:47.739395       1 factory.go:59] Register preBinder predicates successfully
I0904 12:07:47.739413       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:07:47.739466       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:07:47.739508       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:07:47.739606       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:07:47.739631       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:07:47.739675       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:07:47.739706       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:07:47.739726       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:07:47.739749       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:07:47.739779       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:07:47.739812       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:07:47.739847       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:07:47.739876       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:07:47.739901       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:07:47.739981       1 binpack.go:165] Enter binpack plugin ...
I0904 12:07:47.739991       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:07:47.740004       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:07:47.740013       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:07:47.740020       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:07:47.740033       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:47.740055       1 allocate.go:62] Enter Allocate ...
I0904 12:07:47.740062       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:47.740076       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:07:47.740084       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:07:47.740092       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:07:47.740098       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:07:47.740105       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:07:47.740111       1 allocate.go:83] Leaving Allocate ...
I0904 12:07:47.740145       1 backfill.go:59] Enter Backfill ...
I0904 12:07:47.740157       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:47.740170       1 backfill.go:110] Leaving Backfill ...
I0904 12:07:47.740178       1 reclaim.go:47] Enter Reclaim ...
I0904 12:07:47.740183       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:07:47.740189       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:47.740199       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:07:47.740212       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:07:47.740219       1 preempt.go:103] Enter Preempt ...
I0904 12:07:47.740225       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:47.740239       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:07:47.740248       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:07:47.740257       1 preempt.go:270] Leaving Preempt ...
I0904 12:07:47.740404       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:07:47.740492       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:07:47.740519       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:47.740545       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:07:47.740559       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:47.740656       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:07:47.740683       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:07:47.740699       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:07:47.740716       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:47.740732       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:07:47.740793       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:07:47.740819       1 session.go:361] Session 93b87557-6d82-4cb3-9fe4-4e6c15e9adcf operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:07:47.740829       1 session.go:375] Close Session 93b87557-6d82-4cb3-9fe4-4e6c15e9adcf
I0904 12:07:47.740841       1 scheduler.go:133] End scheduling ...
I0904 12:07:57.487912       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:07:57.741692       1 scheduler.go:106] Start scheduling ...
I0904 12:07:57.742046       1 node_info.go:227] imageStates is map[]
I0904 12:07:57.742161       1 node_info.go:227] imageStates is map[]
I0904 12:07:57.742349       1 node_info.go:227] imageStates is map[]
I0904 12:07:57.742421       1 node_info.go:227] imageStates is map[]
I0904 12:07:57.742471       1 node_info.go:227] imageStates is map[]
I0904 12:07:57.742722       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:07:57.743026       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:07:57.743188       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:07:57.743240       1 session.go:230] Open Session f23d4e08-d6c3-4ab6-86aa-7ac92ec56a46 with <1> Job and <5> Queues
I0904 12:07:57.743290       1 session.go:233] Session f23d4e08-d6c3-4ab6-86aa-7ac92ec56a46 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:07:57.743911       1 sla.go:85] Enter sla plugin ...
I0904 12:07:57.744014       1 sla.go:154] Leaving sla plugin.
I0904 12:07:57.744041       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:07:57.744101       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:07:57.744125       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00
I0904 12:07:57.744295       1 factory.go:59] Register preBinder predicates successfully
I0904 12:07:57.744425       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:07:57.744537       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:07:57.744618       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:07:57.744688       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:07:57.744718       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:07:57.744772       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:07:57.744820       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:07:57.744981       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:07:57.745136       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:07:57.745571       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:07:57.745752       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:07:57.745958       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:07:57.746004       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:07:57.746070       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:07:57.746225       1 binpack.go:165] Enter binpack plugin ...
I0904 12:07:57.746243       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:07:57.746264       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:07:57.746280       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:07:57.746289       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:07:57.746307       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:57.746334       1 allocate.go:62] Enter Allocate ...
I0904 12:07:57.746343       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:57.746361       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:07:57.746373       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:07:57.746386       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:07:57.746396       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:07:57.746407       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:07:57.746417       1 allocate.go:83] Leaving Allocate ...
I0904 12:07:57.746429       1 backfill.go:59] Enter Backfill ...
I0904 12:07:57.746440       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:57.746461       1 backfill.go:110] Leaving Backfill ...
I0904 12:07:57.746473       1 reclaim.go:47] Enter Reclaim ...
I0904 12:07:57.746484       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:07:57.746494       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:57.746512       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:07:57.746535       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:07:57.746545       1 preempt.go:103] Enter Preempt ...
I0904 12:07:57.746553       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:07:57.746569       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:07:57.746586       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:07:57.746599       1 preempt.go:270] Leaving Preempt ...
I0904 12:07:57.746910       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:57.747133       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:07:57.747162       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:57.747199       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:07:57.747225       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:07:57.747246       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:07:57.747261       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:07:57.747285       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:07:57.747441       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:07:57.747457       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:07:57.747484       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:07:57.747532       1 session.go:361] Session f23d4e08-d6c3-4ab6-86aa-7ac92ec56a46 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:07:57.747808       1 session.go:375] Close Session f23d4e08-d6c3-4ab6-86aa-7ac92ec56a46
I0904 12:07:57.747852       1 scheduler.go:133] End scheduling ...
I0904 12:08:07.748650       1 scheduler.go:106] Start scheduling ...
I0904 12:08:07.748768       1 node_info.go:227] imageStates is map[]
I0904 12:08:07.748795       1 node_info.go:227] imageStates is map[]
I0904 12:08:07.748804       1 node_info.go:227] imageStates is map[]
I0904 12:08:07.748817       1 node_info.go:227] imageStates is map[]
I0904 12:08:07.748838       1 node_info.go:227] imageStates is map[]
I0904 12:08:07.748851       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:08:07.748893       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:08:07.748905       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:08:07.748915       1 session.go:230] Open Session a89c0e02-c15f-40e6-bf3f-cfe9a235fc4d with <1> Job and <5> Queues
I0904 12:08:07.748928       1 session.go:233] Session a89c0e02-c15f-40e6-bf3f-cfe9a235fc4d operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:08:07.749048       1 sla.go:85] Enter sla plugin ...
I0904 12:08:07.749064       1 sla.go:154] Leaving sla plugin.
I0904 12:08:07.749069       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:08:07.749082       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:08:07.749087       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:08:07.749136       1 factory.go:59] Register preBinder predicates successfully
I0904 12:08:07.749141       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:08:07.749162       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:08:07.749177       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:08:07.749194       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:08:07.749209       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:08:07.749218       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:08:07.749229       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:08:07.749239       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:08:07.749245       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:08:07.749256       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:08:07.749269       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:08:07.749288       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:08:07.749298       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:08:07.749316       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:08:07.749345       1 binpack.go:165] Enter binpack plugin ...
I0904 12:08:07.749348       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:08:07.749353       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:08:07.749357       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:08:07.749360       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:08:07.749366       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:07.749374       1 allocate.go:62] Enter Allocate ...
I0904 12:08:07.749376       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:07.749381       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:08:07.749383       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:08:07.749387       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:08:07.749389       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:08:07.749391       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:08:07.749393       1 allocate.go:83] Leaving Allocate ...
I0904 12:08:07.749396       1 backfill.go:59] Enter Backfill ...
I0904 12:08:07.749398       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:07.749402       1 backfill.go:110] Leaving Backfill ...
I0904 12:08:07.749405       1 reclaim.go:47] Enter Reclaim ...
I0904 12:08:07.749407       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:08:07.749409       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:07.749413       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:08:07.749418       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:08:07.749420       1 preempt.go:103] Enter Preempt ...
I0904 12:08:07.749422       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:07.749425       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:08:07.749429       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:08:07.749432       1 preempt.go:270] Leaving Preempt ...
I0904 12:08:07.749493       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:07.749509       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:08:07.749514       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:07.749521       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:08:07.749540       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:08:07.749550       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:08:07.749555       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:07.749561       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:08:07.749583       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:08:07.749586       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:08:07.749590       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:08:07.749599       1 session.go:361] Session a89c0e02-c15f-40e6-bf3f-cfe9a235fc4d operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:08:07.749602       1 session.go:375] Close Session a89c0e02-c15f-40e6-bf3f-cfe9a235fc4d
I0904 12:08:07.749607       1 scheduler.go:133] End scheduling ...
I0904 12:08:11.374115       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ResourceQuota" totalItems=7
I0904 12:08:13.374263       1 reflector.go:946] "Watch close" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145" type="*v1beta1.PodGroup" totalItems=9
I0904 12:08:17.750482       1 scheduler.go:106] Start scheduling ...
I0904 12:08:17.750791       1 node_info.go:227] imageStates is map[]
I0904 12:08:17.750834       1 node_info.go:227] imageStates is map[]
I0904 12:08:17.750850       1 node_info.go:227] imageStates is map[]
I0904 12:08:17.750880       1 node_info.go:227] imageStates is map[]
I0904 12:08:17.750929       1 node_info.go:227] imageStates is map[]
I0904 12:08:17.750963       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:08:17.751010       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:08:17.751024       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:08:17.751035       1 session.go:230] Open Session 07d9be8c-db5e-49ba-b1c5-3934ef74af9f with <1> Job and <5> Queues
I0904 12:08:17.751049       1 session.go:233] Session 07d9be8c-db5e-49ba-b1c5-3934ef74af9f operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:08:17.751192       1 sla.go:85] Enter sla plugin ...
I0904 12:08:17.751214       1 sla.go:154] Leaving sla plugin.
I0904 12:08:17.751220       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:08:17.751233       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:08:17.751240       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00
I0904 12:08:17.751293       1 factory.go:59] Register preBinder predicates successfully
I0904 12:08:17.751300       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>
I0904 12:08:17.751324       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:08:17.751344       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:08:17.751376       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:08:17.751384       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:08:17.751396       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:08:17.751409       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:08:17.751418       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:08:17.751432       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:08:17.751450       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:08:17.751476       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:08:17.751488       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:08:17.751499       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:08:17.751511       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:08:17.751542       1 binpack.go:165] Enter binpack plugin ...
I0904 12:08:17.751546       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:08:17.751551       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:08:17.751556       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:08:17.751559       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:08:17.751567       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:17.751576       1 allocate.go:62] Enter Allocate ...
I0904 12:08:17.751579       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:17.751585       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:08:17.751589       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:08:17.751593       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:08:17.751595       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:08:17.751598       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:08:17.751601       1 allocate.go:83] Leaving Allocate ...
I0904 12:08:17.751605       1 backfill.go:59] Enter Backfill ...
I0904 12:08:17.751608       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:17.751613       1 backfill.go:110] Leaving Backfill ...
I0904 12:08:17.751617       1 reclaim.go:47] Enter Reclaim ...
I0904 12:08:17.751620       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:08:17.751623       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:17.751628       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:08:17.751634       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:08:17.751638       1 preempt.go:103] Enter Preempt ...
I0904 12:08:17.751641       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:17.751645       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:08:17.751650       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:08:17.751653       1 preempt.go:270] Leaving Preempt ...
I0904 12:08:17.751738       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:17.751754       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:08:17.751761       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:17.751770       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:08:17.751777       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:08:17.751783       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:08:17.751788       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:17.751795       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:08:17.751824       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:08:17.751827       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:08:17.751833       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:08:17.751845       1 session.go:361] Session 07d9be8c-db5e-49ba-b1c5-3934ef74af9f operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:08:17.751849       1 session.go:375] Close Session 07d9be8c-db5e-49ba-b1c5-3934ef74af9f
I0904 12:08:17.751854       1 scheduler.go:133] End scheduling ...
I0904 12:08:27.488703       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:08:27.752900       1 scheduler.go:106] Start scheduling ...
I0904 12:08:27.752984       1 node_info.go:227] imageStates is map[]
I0904 12:08:27.753092       1 node_info.go:227] imageStates is map[]
I0904 12:08:27.753120       1 node_info.go:227] imageStates is map[]
I0904 12:08:27.753130       1 node_info.go:227] imageStates is map[]
I0904 12:08:27.753143       1 node_info.go:227] imageStates is map[]
I0904 12:08:27.753169       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:08:27.753196       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:08:27.753209       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:08:27.753221       1 session.go:230] Open Session dd2ee826-9e07-4105-aadd-80294755546b with <1> Job and <5> Queues
I0904 12:08:27.753233       1 session.go:233] Session dd2ee826-9e07-4105-aadd-80294755546b operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:08:27.753376       1 sla.go:85] Enter sla plugin ...
I0904 12:08:27.753384       1 sla.go:154] Leaving sla plugin.
I0904 12:08:27.753389       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:08:27.753401       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:08:27.753407       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00
I0904 12:08:27.753455       1 factory.go:59] Register preBinder predicates successfully
I0904 12:08:27.753475       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>
I0904 12:08:27.753501       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:08:27.753519       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:08:27.753536       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:08:27.753544       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:08:27.753554       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:08:27.753566       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:08:27.753578       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:08:27.753585       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:08:27.753602       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:08:27.753617       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:08:27.753630       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:08:27.753645       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:08:27.753658       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:08:27.753702       1 binpack.go:165] Enter binpack plugin ...
I0904 12:08:27.753705       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:08:27.753710       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:08:27.753716       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:08:27.753722       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:08:27.753728       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:27.753754       1 allocate.go:62] Enter Allocate ...
I0904 12:08:27.753757       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:27.753763       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:08:27.753766       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:08:27.753769       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:08:27.753772       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:08:27.753775       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:08:27.753778       1 allocate.go:83] Leaving Allocate ...
I0904 12:08:27.753781       1 backfill.go:59] Enter Backfill ...
I0904 12:08:27.753784       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:27.753789       1 backfill.go:110] Leaving Backfill ...
I0904 12:08:27.753792       1 reclaim.go:47] Enter Reclaim ...
I0904 12:08:27.753795       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:08:27.753798       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:27.753802       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:08:27.753807       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:08:27.753814       1 preempt.go:103] Enter Preempt ...
I0904 12:08:27.753816       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:27.753820       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:08:27.753824       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:08:27.753829       1 preempt.go:270] Leaving Preempt ...
I0904 12:08:27.753906       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:27.753928       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:08:27.753955       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:08:27.753958       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:08:27.753964       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:08:27.753968       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:27.753974       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:08:27.753978       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:27.753985       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:08:27.753989       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:08:27.753993       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:08:27.754003       1 session.go:361] Session dd2ee826-9e07-4105-aadd-80294755546b operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:08:27.754007       1 session.go:375] Close Session dd2ee826-9e07-4105-aadd-80294755546b
I0904 12:08:27.754011       1 scheduler.go:133] End scheduling ...
I0904 12:08:37.754781       1 scheduler.go:106] Start scheduling ...
I0904 12:08:37.754939       1 node_info.go:227] imageStates is map[]
I0904 12:08:37.755230       1 node_info.go:227] imageStates is map[]
I0904 12:08:37.755293       1 node_info.go:227] imageStates is map[]
I0904 12:08:37.755337       1 node_info.go:227] imageStates is map[]
I0904 12:08:37.757882       1 node_info.go:227] imageStates is map[]
I0904 12:08:37.757946       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:08:37.757994       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:08:37.758010       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:08:37.758025       1 session.go:230] Open Session b819a0d2-52f7-4aff-862f-0c99cadfd1b1 with <1> Job and <5> Queues
I0904 12:08:37.758049       1 session.go:233] Session b819a0d2-52f7-4aff-862f-0c99cadfd1b1 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:08:37.758677       1 sla.go:85] Enter sla plugin ...
I0904 12:08:37.758702       1 sla.go:154] Leaving sla plugin.
I0904 12:08:37.758708       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:08:37.758787       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:08:37.758807       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00
I0904 12:08:37.759318       1 factory.go:59] Register preBinder predicates successfully
I0904 12:08:37.759391       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>
I0904 12:08:37.759515       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:08:37.759626       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:08:37.759709       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:08:37.759771       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:08:37.759848       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:08:37.759924       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:08:37.760032       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:08:37.760060       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:08:37.760082       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:08:37.760110       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:08:37.760218       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:08:37.760289       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:08:37.760354       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:08:37.760475       1 binpack.go:165] Enter binpack plugin ...
I0904 12:08:37.760528       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:08:37.760616       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:08:37.760636       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:08:37.760645       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:08:37.760720       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:37.760802       1 allocate.go:62] Enter Allocate ...
I0904 12:08:37.760815       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:37.760836       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:08:37.760845       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:08:37.760855       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:08:37.760862       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:08:37.760870       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:08:37.760878       1 allocate.go:83] Leaving Allocate ...
I0904 12:08:37.760887       1 backfill.go:59] Enter Backfill ...
I0904 12:08:37.760897       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:37.760911       1 backfill.go:110] Leaving Backfill ...
I0904 12:08:37.760973       1 reclaim.go:47] Enter Reclaim ...
I0904 12:08:37.760985       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:08:37.760997       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:37.761012       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:08:37.761029       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:08:37.761038       1 preempt.go:103] Enter Preempt ...
I0904 12:08:37.761046       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:37.761059       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:08:37.761070       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:08:37.761079       1 preempt.go:270] Leaving Preempt ...
I0904 12:08:37.761330       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:37.761444       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:08:37.761472       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:08:37.761491       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:08:37.761560       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:37.761591       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:08:37.761713       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:08:37.761766       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:08:37.761965       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:08:37.762009       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:37.762028       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:08:37.762048       1 session.go:361] Session b819a0d2-52f7-4aff-862f-0c99cadfd1b1 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:08:37.762055       1 session.go:375] Close Session b819a0d2-52f7-4aff-862f-0c99cadfd1b1
I0904 12:08:37.762064       1 scheduler.go:133] End scheduling ...
I0904 12:08:43.366452       1 cache.go:1179] started sync node integration-control-plane
I0904 12:08:43.366487       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:08:43.366551       1 node_info.go:227] imageStates is map[]
I0904 12:08:47.763012       1 scheduler.go:106] Start scheduling ...
I0904 12:08:47.763133       1 node_info.go:227] imageStates is map[]
I0904 12:08:47.763171       1 node_info.go:227] imageStates is map[]
I0904 12:08:47.763200       1 node_info.go:227] imageStates is map[]
I0904 12:08:47.763215       1 node_info.go:227] imageStates is map[]
I0904 12:08:47.763227       1 node_info.go:227] imageStates is map[]
I0904 12:08:47.763255       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:08:47.763289       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:08:47.763303       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:08:47.763316       1 session.go:230] Open Session 0d8d4874-bbd1-447b-9799-5bc42bc00fc3 with <1> Job and <5> Queues
I0904 12:08:47.763332       1 session.go:233] Session 0d8d4874-bbd1-447b-9799-5bc42bc00fc3 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:08:47.763493       1 sla.go:85] Enter sla plugin ...
I0904 12:08:47.763515       1 sla.go:154] Leaving sla plugin.
I0904 12:08:47.763522       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:08:47.763537       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:08:47.763543       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00
I0904 12:08:47.763599       1 factory.go:59] Register preBinder predicates successfully
I0904 12:08:47.763612       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:08:47.763633       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:08:47.763648       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:08:47.763665       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:08:47.763671       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:08:47.763682       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:08:47.763691       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:08:47.763698       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:08:47.763705       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:08:47.763717       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:08:47.763730       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:08:47.763751       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:08:47.763761       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:08:47.763770       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:08:47.763794       1 binpack.go:165] Enter binpack plugin ...
I0904 12:08:47.763806       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:08:47.763811       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:08:47.763815       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:08:47.763818       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:08:47.763823       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:47.763840       1 allocate.go:62] Enter Allocate ...
I0904 12:08:47.763843       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:47.763848       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:08:47.763850       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:08:47.763853       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:08:47.763856       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:08:47.763858       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:08:47.763860       1 allocate.go:83] Leaving Allocate ...
I0904 12:08:47.763863       1 backfill.go:59] Enter Backfill ...
I0904 12:08:47.763865       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:47.763869       1 backfill.go:110] Leaving Backfill ...
I0904 12:08:47.763872       1 reclaim.go:47] Enter Reclaim ...
I0904 12:08:47.763874       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:08:47.763876       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:47.763879       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:08:47.763884       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:08:47.763886       1 preempt.go:103] Enter Preempt ...
I0904 12:08:47.763888       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:47.763892       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:08:47.763895       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:08:47.763898       1 preempt.go:270] Leaving Preempt ...
I0904 12:08:47.763959       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:08:47.763979       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:08:47.763983       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:47.763989       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:08:47.763994       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:47.764001       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:08:47.764006       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:08:47.764009       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:08:47.764023       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:47.764029       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:08:47.764070       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:08:47.764079       1 session.go:361] Session 0d8d4874-bbd1-447b-9799-5bc42bc00fc3 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:08:47.764091       1 session.go:375] Close Session 0d8d4874-bbd1-447b-9799-5bc42bc00fc3
I0904 12:08:47.764095       1 scheduler.go:133] End scheduling ...
I0904 12:08:54.378446       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StatefulSet" totalItems=10
I0904 12:08:57.489692       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:08:57.764624       1 scheduler.go:106] Start scheduling ...
I0904 12:08:57.764704       1 node_info.go:227] imageStates is map[]
I0904 12:08:57.764719       1 node_info.go:227] imageStates is map[]
I0904 12:08:57.764731       1 node_info.go:227] imageStates is map[]
I0904 12:08:57.764745       1 node_info.go:227] imageStates is map[]
I0904 12:08:57.764776       1 node_info.go:227] imageStates is map[]
I0904 12:08:57.764804       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:08:57.764843       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:08:57.764857       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:08:57.764870       1 session.go:230] Open Session c0b077f5-98c4-4605-ac45-a4b5d2c520b1 with <1> Job and <5> Queues
I0904 12:08:57.764881       1 session.go:233] Session c0b077f5-98c4-4605-ac45-a4b5d2c520b1 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:08:57.765010       1 sla.go:85] Enter sla plugin ...
I0904 12:08:57.765025       1 sla.go:154] Leaving sla plugin.
I0904 12:08:57.765030       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:08:57.765041       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:08:57.765046       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00
I0904 12:08:57.765102       1 factory.go:59] Register preBinder predicates successfully
I0904 12:08:57.765118       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>
I0904 12:08:57.765147       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:08:57.765177       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:08:57.765193       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:08:57.765200       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:08:57.765221       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:08:57.765234       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:08:57.765248       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:08:57.765265       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:08:57.765274       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:08:57.765297       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:08:57.765308       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:08:57.765317       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:08:57.765324       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:08:57.765353       1 binpack.go:165] Enter binpack plugin ...
I0904 12:08:57.765364       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:08:57.765369       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:08:57.765374       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:08:57.765377       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:08:57.765382       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:57.765392       1 allocate.go:62] Enter Allocate ...
I0904 12:08:57.765395       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:57.765400       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:08:57.765412       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:08:57.765415       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:08:57.765417       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:08:57.765419       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:08:57.765421       1 allocate.go:83] Leaving Allocate ...
I0904 12:08:57.765424       1 backfill.go:59] Enter Backfill ...
I0904 12:08:57.765426       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:57.765431       1 backfill.go:110] Leaving Backfill ...
I0904 12:08:57.765434       1 reclaim.go:47] Enter Reclaim ...
I0904 12:08:57.765436       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:08:57.765438       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:57.765442       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:08:57.765446       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:08:57.765449       1 preempt.go:103] Enter Preempt ...
I0904 12:08:57.765451       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:08:57.765454       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:08:57.765460       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:08:57.765462       1 preempt.go:270] Leaving Preempt ...
I0904 12:08:57.765521       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:08:57.765540       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:08:57.765544       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:57.765550       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:08:57.765554       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:57.765561       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:08:57.765573       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:08:57.765577       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:08:57.765583       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:08:57.765589       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:08:57.765612       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:08:57.765620       1 session.go:361] Session c0b077f5-98c4-4605-ac45-a4b5d2c520b1 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:08:57.765623       1 session.go:375] Close Session c0b077f5-98c4-4605-ac45-a4b5d2c520b1
I0904 12:08:57.765627       1 scheduler.go:133] End scheduling ...
I0904 12:09:03.922551       1 cache.go:1179] started sync node integration-control-plane
I0904 12:09:03.922632       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:09:03.922835       1 node_info.go:227] imageStates is map[]
I0904 12:09:07.766144       1 scheduler.go:106] Start scheduling ...
I0904 12:09:07.766339       1 node_info.go:227] imageStates is map[]
I0904 12:09:07.766443       1 node_info.go:227] imageStates is map[]
I0904 12:09:07.766465       1 node_info.go:227] imageStates is map[]
I0904 12:09:07.766490       1 node_info.go:227] imageStates is map[]
I0904 12:09:07.766512       1 node_info.go:227] imageStates is map[]
I0904 12:09:07.766563       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:09:07.766616       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:09:07.766664       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:09:07.766685       1 session.go:230] Open Session 6f7629c1-ef2f-498a-8f03-eb7a4795ace2 with <1> Job and <5> Queues
I0904 12:09:07.766712       1 session.go:233] Session 6f7629c1-ef2f-498a-8f03-eb7a4795ace2 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:09:07.767079       1 sla.go:85] Enter sla plugin ...
I0904 12:09:07.767115       1 sla.go:154] Leaving sla plugin.
I0904 12:09:07.767125       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:09:07.767151       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:09:07.767161       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:09:07.767247       1 factory.go:59] Register preBinder predicates successfully
I0904 12:09:07.767259       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 12:09:07.767310       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:09:07.767374       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:09:07.767416       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:09:07.767430       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:09:07.767454       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:09:07.767483       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:09:07.767509       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:09:07.767530       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:09:07.767555       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:09:07.767609       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:09:07.767635       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:09:07.767653       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:09:07.767682       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:09:07.767732       1 binpack.go:165] Enter binpack plugin ...
I0904 12:09:07.767738       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:09:07.767749       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:09:07.767758       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:09:07.767763       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:09:07.767773       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:07.767787       1 allocate.go:62] Enter Allocate ...
I0904 12:09:07.767793       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:07.767803       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:09:07.767809       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:09:07.767815       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:09:07.767820       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:09:07.767825       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:09:07.767830       1 allocate.go:83] Leaving Allocate ...
I0904 12:09:07.767836       1 backfill.go:59] Enter Backfill ...
I0904 12:09:07.767842       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:07.767850       1 backfill.go:110] Leaving Backfill ...
I0904 12:09:07.767856       1 reclaim.go:47] Enter Reclaim ...
I0904 12:09:07.767861       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:09:07.767866       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:07.767874       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:09:07.767886       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:09:07.767892       1 preempt.go:103] Enter Preempt ...
I0904 12:09:07.767897       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:07.767927       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:09:07.767936       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:09:07.767942       1 preempt.go:270] Leaving Preempt ...
I0904 12:09:07.768050       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:07.768076       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:09:07.768086       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:09:07.768097       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:09:07.768106       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:07.768119       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:09:07.768171       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:09:07.768177       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:09:07.768188       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:09:07.768196       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:07.768210       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:09:07.768231       1 session.go:361] Session 6f7629c1-ef2f-498a-8f03-eb7a4795ace2 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:09:07.768260       1 session.go:375] Close Session 6f7629c1-ef2f-498a-8f03-eb7a4795ace2
I0904 12:09:07.768271       1 scheduler.go:133] End scheduling ...
I0904 12:09:13.374300       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolume" totalItems=10
I0904 12:09:14.126890       1 cache.go:1179] started sync node integration-control-plane
I0904 12:09:14.126953       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:09:14.127088       1 node_info.go:227] imageStates is map[]
I0904 12:09:17.769359       1 scheduler.go:106] Start scheduling ...
I0904 12:09:17.769503       1 node_info.go:227] imageStates is map[]
I0904 12:09:17.769578       1 node_info.go:227] imageStates is map[]
I0904 12:09:17.769609       1 node_info.go:227] imageStates is map[]
I0904 12:09:17.769628       1 node_info.go:227] imageStates is map[]
I0904 12:09:17.769652       1 node_info.go:227] imageStates is map[]
I0904 12:09:17.769697       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:09:17.769747       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:09:17.769771       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:09:17.769790       1 session.go:230] Open Session 32cc3d9c-c778-4d8f-8ee0-0f86bb7bfce1 with <1> Job and <5> Queues
I0904 12:09:17.769814       1 session.go:233] Session 32cc3d9c-c778-4d8f-8ee0-0f86bb7bfce1 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:09:17.770220       1 sla.go:85] Enter sla plugin ...
I0904 12:09:17.770248       1 sla.go:154] Leaving sla plugin.
I0904 12:09:17.770257       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:09:17.770308       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:09:17.770321       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00
I0904 12:09:17.770405       1 factory.go:59] Register preBinder predicates successfully
I0904 12:09:17.770415       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>
I0904 12:09:17.770460       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:09:17.770500       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:09:17.770541       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:09:17.770560       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:09:17.770592       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:09:17.770627       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:09:17.770655       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:09:17.770672       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:09:17.770724       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:09:17.770763       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:09:17.770784       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:09:17.770816       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:09:17.770897       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:09:17.770966       1 binpack.go:165] Enter binpack plugin ...
I0904 12:09:17.770973       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:09:17.770984       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:09:17.770993       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:09:17.770998       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:09:17.771010       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:17.771029       1 allocate.go:62] Enter Allocate ...
I0904 12:09:17.771035       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:17.771047       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:09:17.771053       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:09:17.771061       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:09:17.771070       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:09:17.771076       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:09:17.771081       1 allocate.go:83] Leaving Allocate ...
I0904 12:09:17.771087       1 backfill.go:59] Enter Backfill ...
I0904 12:09:17.771092       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:17.771102       1 backfill.go:110] Leaving Backfill ...
I0904 12:09:17.771107       1 reclaim.go:47] Enter Reclaim ...
I0904 12:09:17.771112       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:09:17.771118       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:17.771126       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:09:17.771138       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:09:17.771144       1 preempt.go:103] Enter Preempt ...
I0904 12:09:17.771149       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:17.771158       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:09:17.771169       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:09:17.771183       1 preempt.go:270] Leaving Preempt ...
I0904 12:09:17.771309       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:17.771366       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:09:17.771379       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:09:17.771391       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:09:17.771400       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:17.771419       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:09:17.771473       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:09:17.771479       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:09:17.771490       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:09:17.771499       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:17.771512       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:09:17.771537       1 session.go:361] Session 32cc3d9c-c778-4d8f-8ee0-0f86bb7bfce1 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:09:17.771544       1 session.go:375] Close Session 32cc3d9c-c778-4d8f-8ee0-0f86bb7bfce1
I0904 12:09:17.771554       1 scheduler.go:133] End scheduling ...
I0904 12:09:22.372686       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicationController" totalItems=10
I0904 12:09:24.275148       1 cache.go:1179] started sync node integration-control-plane
I0904 12:09:24.275239       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:09:24.275386       1 node_info.go:227] imageStates is map[]
I0904 12:09:27.490309       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:09:27.772074       1 scheduler.go:106] Start scheduling ...
I0904 12:09:27.772342       1 node_info.go:227] imageStates is map[]
I0904 12:09:27.772380       1 node_info.go:227] imageStates is map[]
I0904 12:09:27.772391       1 node_info.go:227] imageStates is map[]
I0904 12:09:27.772418       1 node_info.go:227] imageStates is map[]
I0904 12:09:27.772431       1 node_info.go:227] imageStates is map[]
I0904 12:09:27.772476       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:09:27.772518       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:09:27.772531       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:09:27.772544       1 session.go:230] Open Session 855c46b4-3afb-4e4e-96d3-385e012b1f70 with <1> Job and <5> Queues
I0904 12:09:27.772558       1 session.go:233] Session 855c46b4-3afb-4e4e-96d3-385e012b1f70 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:09:27.772715       1 sla.go:85] Enter sla plugin ...
I0904 12:09:27.772735       1 sla.go:154] Leaving sla plugin.
I0904 12:09:27.772741       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:09:27.772753       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:09:27.772759       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00
I0904 12:09:27.772831       1 factory.go:59] Register preBinder predicates successfully
I0904 12:09:27.772848       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:09:27.772883       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:09:27.772916       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:09:27.772936       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:09:27.772955       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:09:27.772978       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:09:27.773002       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:09:27.773010       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:09:27.773018       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:09:27.773029       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:09:27.773055       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:09:27.773066       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:09:27.773088       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:09:27.773108       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:09:27.773151       1 binpack.go:165] Enter binpack plugin ...
I0904 12:09:27.773154       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:09:27.773159       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:09:27.773164       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:09:27.773202       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:09:27.773215       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:27.773226       1 allocate.go:62] Enter Allocate ...
I0904 12:09:27.773228       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:27.773234       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:09:27.773237       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:09:27.773240       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:09:27.773243       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:09:27.773245       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:09:27.773248       1 allocate.go:83] Leaving Allocate ...
I0904 12:09:27.773251       1 backfill.go:59] Enter Backfill ...
I0904 12:09:27.773254       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:27.773258       1 backfill.go:110] Leaving Backfill ...
I0904 12:09:27.773262       1 reclaim.go:47] Enter Reclaim ...
I0904 12:09:27.773265       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:09:27.773267       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:27.773271       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:09:27.773276       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:09:27.773282       1 preempt.go:103] Enter Preempt ...
I0904 12:09:27.773284       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:27.773288       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:09:27.773292       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:09:27.773297       1 preempt.go:270] Leaving Preempt ...
I0904 12:09:27.773372       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:27.773399       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:09:27.773404       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:27.773413       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:09:27.773419       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:09:27.773423       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:09:27.773427       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:27.773432       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:09:27.773478       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:09:27.773491       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:09:27.773496       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:09:27.773518       1 session.go:361] Session 855c46b4-3afb-4e4e-96d3-385e012b1f70 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:09:27.773531       1 session.go:375] Close Session 855c46b4-3afb-4e4e-96d3-385e012b1f70
I0904 12:09:27.773536       1 scheduler.go:133] End scheduling ...
I0904 12:09:37.774213       1 scheduler.go:106] Start scheduling ...
I0904 12:09:37.774389       1 node_info.go:227] imageStates is map[]
I0904 12:09:37.774452       1 node_info.go:227] imageStates is map[]
I0904 12:09:37.774476       1 node_info.go:227] imageStates is map[]
I0904 12:09:37.774499       1 node_info.go:227] imageStates is map[]
I0904 12:09:37.774517       1 node_info.go:227] imageStates is map[]
I0904 12:09:37.774620       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:09:37.774665       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:09:37.774687       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:09:37.774705       1 session.go:230] Open Session 23230401-9c17-41e1-8457-c08d13e74b3d with <1> Job and <5> Queues
I0904 12:09:37.774730       1 session.go:233] Session 23230401-9c17-41e1-8457-c08d13e74b3d operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:09:37.774996       1 sla.go:85] Enter sla plugin ...
I0904 12:09:37.775040       1 sla.go:154] Leaving sla plugin.
I0904 12:09:37.775049       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:09:37.775076       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:09:37.775098       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:09:37.775162       1 factory.go:59] Register preBinder predicates successfully
I0904 12:09:37.775169       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 12:09:37.775190       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:09:37.775208       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:09:37.775227       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:09:37.775237       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:09:37.775254       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:09:37.775269       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:09:37.775280       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:09:37.775289       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:09:37.775304       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:09:37.775320       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:09:37.775347       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:09:37.775359       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:09:37.775387       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:09:37.775426       1 binpack.go:165] Enter binpack plugin ...
I0904 12:09:37.775442       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:09:37.775449       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:09:37.775465       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:09:37.775468       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:09:37.775476       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:37.775485       1 allocate.go:62] Enter Allocate ...
I0904 12:09:37.775497       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:37.775503       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:09:37.775506       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:09:37.775510       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:09:37.775512       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:09:37.775515       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:09:37.775518       1 allocate.go:83] Leaving Allocate ...
I0904 12:09:37.775522       1 backfill.go:59] Enter Backfill ...
I0904 12:09:37.775525       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:37.775529       1 backfill.go:110] Leaving Backfill ...
I0904 12:09:37.775533       1 reclaim.go:47] Enter Reclaim ...
I0904 12:09:37.775536       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:09:37.775539       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:37.775543       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:09:37.775548       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:09:37.775554       1 preempt.go:103] Enter Preempt ...
I0904 12:09:37.775556       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:37.775560       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:09:37.775564       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:09:37.775567       1 preempt.go:270] Leaving Preempt ...
I0904 12:09:37.775628       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:09:37.775640       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:09:37.775645       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:37.775653       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:09:37.775668       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:37.775677       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:09:37.775681       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:09:37.775686       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:09:37.775690       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:37.775698       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:09:37.775731       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:09:37.775740       1 session.go:361] Session 23230401-9c17-41e1-8457-c08d13e74b3d operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:09:37.775743       1 session.go:375] Close Session 23230401-9c17-41e1-8457-c08d13e74b3d
I0904 12:09:37.775747       1 scheduler.go:133] End scheduling ...
I0904 12:09:46.369103       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolumeClaim" totalItems=10
I0904 12:09:47.776432       1 scheduler.go:106] Start scheduling ...
I0904 12:09:47.776736       1 node_info.go:227] imageStates is map[]
I0904 12:09:47.776839       1 node_info.go:227] imageStates is map[]
I0904 12:09:47.776877       1 node_info.go:227] imageStates is map[]
I0904 12:09:47.776917       1 node_info.go:227] imageStates is map[]
I0904 12:09:47.776952       1 node_info.go:227] imageStates is map[]
I0904 12:09:47.777055       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:09:47.777188       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:09:47.777229       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:09:47.777312       1 session.go:230] Open Session a6377a68-3a7e-4583-bc33-4a24429fc39d with <1> Job and <5> Queues
I0904 12:09:47.777352       1 session.go:233] Session a6377a68-3a7e-4583-bc33-4a24429fc39d operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:09:47.777815       1 sla.go:85] Enter sla plugin ...
I0904 12:09:47.777886       1 sla.go:154] Leaving sla plugin.
I0904 12:09:47.777903       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:09:47.777944       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:09:47.777961       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00
I0904 12:09:47.778097       1 factory.go:59] Register preBinder predicates successfully
I0904 12:09:47.778119       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:09:47.778205       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:09:47.778331       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:09:47.778446       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:09:47.778520       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:09:47.778574       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:09:47.778618       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:09:47.778651       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:09:47.778686       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:09:47.778748       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:09:47.778800       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:09:47.778899       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:09:47.778939       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:09:47.779017       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:09:47.779184       1 binpack.go:165] Enter binpack plugin ...
I0904 12:09:47.779236       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:09:47.779252       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:09:47.779266       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:09:47.779274       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:09:47.779292       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:47.779317       1 allocate.go:62] Enter Allocate ...
I0904 12:09:47.779325       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:47.779343       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:09:47.779449       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:09:47.779463       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:09:47.779473       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:09:47.779483       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:09:47.779491       1 allocate.go:83] Leaving Allocate ...
I0904 12:09:47.779502       1 backfill.go:59] Enter Backfill ...
I0904 12:09:47.779523       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:47.779538       1 backfill.go:110] Leaving Backfill ...
I0904 12:09:47.779553       1 reclaim.go:47] Enter Reclaim ...
I0904 12:09:47.779562       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:09:47.779571       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:47.779586       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:09:47.779615       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:09:47.779624       1 preempt.go:103] Enter Preempt ...
I0904 12:09:47.779636       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:47.779655       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:09:47.779668       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:09:47.779680       1 preempt.go:270] Leaving Preempt ...
I0904 12:09:47.779911       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:09:47.779987       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:09:47.780006       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:47.780028       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:09:47.780053       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:47.780076       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:09:47.780224       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:09:47.780278       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:09:47.780295       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:47.780314       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:09:47.780510       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:09:47.780552       1 session.go:361] Session a6377a68-3a7e-4583-bc33-4a24429fc39d operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:09:47.780563       1 session.go:375] Close Session a6377a68-3a7e-4583-bc33-4a24429fc39d
I0904 12:09:47.780577       1 scheduler.go:133] End scheduling ...
I0904 12:09:54.487060       1 cache.go:1179] started sync node integration-control-plane
I0904 12:09:54.487105       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:09:54.487197       1 node_info.go:227] imageStates is map[]
I0904 12:09:57.491248       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:09:57.781660       1 scheduler.go:106] Start scheduling ...
I0904 12:09:57.781824       1 node_info.go:227] imageStates is map[]
I0904 12:09:57.781867       1 node_info.go:227] imageStates is map[]
I0904 12:09:57.781885       1 node_info.go:227] imageStates is map[]
I0904 12:09:57.781893       1 node_info.go:227] imageStates is map[]
I0904 12:09:57.781904       1 node_info.go:227] imageStates is map[]
I0904 12:09:57.781927       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:09:57.781964       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:09:57.781987       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:09:57.781999       1 session.go:230] Open Session 9ca6a8a6-a519-409d-9fbc-3ca006f29ca8 with <1> Job and <5> Queues
I0904 12:09:57.782011       1 session.go:233] Session 9ca6a8a6-a519-409d-9fbc-3ca006f29ca8 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:09:57.782132       1 sla.go:85] Enter sla plugin ...
I0904 12:09:57.782148       1 sla.go:154] Leaving sla plugin.
I0904 12:09:57.782152       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:09:57.782162       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:09:57.782168       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00
I0904 12:09:57.782217       1 factory.go:59] Register preBinder predicates successfully
I0904 12:09:57.782222       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:09:57.782241       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:09:57.782258       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:09:57.782285       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:09:57.782291       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:09:57.782301       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:09:57.782307       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:09:57.782318       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:09:57.782338       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:09:57.782352       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:09:57.782366       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:09:57.782373       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:09:57.782385       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:09:57.782393       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:09:57.782417       1 binpack.go:165] Enter binpack plugin ...
I0904 12:09:57.782430       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:09:57.782434       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:09:57.782439       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:09:57.782451       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:09:57.782456       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:57.782481       1 allocate.go:62] Enter Allocate ...
I0904 12:09:57.782484       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:57.782489       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:09:57.782492       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:09:57.782495       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:09:57.782497       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:09:57.782500       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:09:57.782502       1 allocate.go:83] Leaving Allocate ...
I0904 12:09:57.782505       1 backfill.go:59] Enter Backfill ...
I0904 12:09:57.782507       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:57.782511       1 backfill.go:110] Leaving Backfill ...
I0904 12:09:57.782514       1 reclaim.go:47] Enter Reclaim ...
I0904 12:09:57.782517       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:09:57.782519       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:57.782522       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:09:57.782527       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:09:57.782530       1 preempt.go:103] Enter Preempt ...
I0904 12:09:57.782532       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:09:57.782535       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:09:57.782538       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:09:57.782541       1 preempt.go:270] Leaving Preempt ...
I0904 12:09:57.782604       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:57.782628       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:09:57.782634       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:57.782640       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:09:57.782644       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:09:57.782649       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:09:57.782653       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:09:57.782659       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:09:57.782678       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:09:57.782680       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:09:57.782684       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:09:57.782694       1 session.go:361] Session 9ca6a8a6-a519-409d-9fbc-3ca006f29ca8 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:09:57.782698       1 session.go:375] Close Session 9ca6a8a6-a519-409d-9fbc-3ca006f29ca8
I0904 12:09:57.782702       1 scheduler.go:133] End scheduling ...
I0904 12:10:07.783616       1 scheduler.go:106] Start scheduling ...
I0904 12:10:07.783784       1 node_info.go:227] imageStates is map[]
I0904 12:10:07.783821       1 node_info.go:227] imageStates is map[]
I0904 12:10:07.783844       1 node_info.go:227] imageStates is map[]
I0904 12:10:07.783863       1 node_info.go:227] imageStates is map[]
I0904 12:10:07.783920       1 node_info.go:227] imageStates is map[]
I0904 12:10:07.783979       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:10:07.784033       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:10:07.784058       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:10:07.784082       1 session.go:230] Open Session b4451582-9615-4d2b-8003-1fbf37546b13 with <1> Job and <5> Queues
I0904 12:10:07.784106       1 session.go:233] Session b4451582-9615-4d2b-8003-1fbf37546b13 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:10:07.784364       1 sla.go:85] Enter sla plugin ...
I0904 12:10:07.784402       1 sla.go:154] Leaving sla plugin.
I0904 12:10:07.784413       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:10:07.784439       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:10:07.784452       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:10:07.784552       1 factory.go:59] Register preBinder predicates successfully
I0904 12:10:07.784589       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>
I0904 12:10:07.784637       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:10:07.784702       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:10:07.784745       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:10:07.784785       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:10:07.784807       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:10:07.784831       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:10:07.784847       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:10:07.784870       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:10:07.784924       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:10:07.784964       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:10:07.784985       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:10:07.785010       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:10:07.785114       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:10:07.785170       1 binpack.go:165] Enter binpack plugin ...
I0904 12:10:07.785204       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:10:07.785214       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:10:07.785225       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:10:07.785255       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:10:07.785270       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:07.785311       1 allocate.go:62] Enter Allocate ...
I0904 12:10:07.785318       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:07.785331       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:10:07.785362       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:10:07.785374       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:10:07.785380       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:10:07.785409       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:10:07.785415       1 allocate.go:83] Leaving Allocate ...
I0904 12:10:07.785422       1 backfill.go:59] Enter Backfill ...
I0904 12:10:07.785428       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:07.785438       1 backfill.go:110] Leaving Backfill ...
I0904 12:10:07.785443       1 reclaim.go:47] Enter Reclaim ...
I0904 12:10:07.785448       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:10:07.785454       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:07.785475       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:07.785509       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:10:07.785515       1 preempt.go:103] Enter Preempt ...
I0904 12:10:07.785521       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:07.785595       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:07.785627       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:10:07.785634       1 preempt.go:270] Leaving Preempt ...
I0904 12:10:07.785757       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:10:07.785806       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:10:07.785816       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:10:07.785829       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:10:07.785860       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:10:07.785876       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:10:07.785885       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:10:07.785896       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:10:07.785927       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:10:07.785940       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:10:07.786111       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:10:07.786130       1 session.go:361] Session b4451582-9615-4d2b-8003-1fbf37546b13 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:10:07.786136       1 session.go:375] Close Session b4451582-9615-4d2b-8003-1fbf37546b13
I0904 12:10:07.786144       1 scheduler.go:133] End scheduling ...
I0904 12:10:14.878881       1 cache.go:1179] started sync node integration-control-plane
I0904 12:10:14.878909       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:10:14.878970       1 node_info.go:227] imageStates is map[]
I0904 12:10:17.786472       1 scheduler.go:106] Start scheduling ...
I0904 12:10:17.786777       1 node_info.go:227] imageStates is map[]
I0904 12:10:17.786921       1 node_info.go:227] imageStates is map[]
I0904 12:10:17.786958       1 node_info.go:227] imageStates is map[]
I0904 12:10:17.786992       1 node_info.go:227] imageStates is map[]
I0904 12:10:17.787023       1 node_info.go:227] imageStates is map[]
I0904 12:10:17.787085       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:10:17.787157       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:10:17.787189       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:10:17.787216       1 session.go:230] Open Session b77a87d2-17c9-4ec8-bc4d-559768715b9a with <1> Job and <5> Queues
I0904 12:10:17.787251       1 session.go:233] Session b77a87d2-17c9-4ec8-bc4d-559768715b9a operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:10:17.787602       1 sla.go:85] Enter sla plugin ...
I0904 12:10:17.787646       1 sla.go:154] Leaving sla plugin.
I0904 12:10:17.787660       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:10:17.787697       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:10:17.787710       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:10:17.787821       1 factory.go:59] Register preBinder predicates successfully
I0904 12:10:17.787835       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>
I0904 12:10:17.787894       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:10:17.787945       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:10:17.788013       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:10:17.788032       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:10:17.788069       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:10:17.788166       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:10:17.788201       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:10:17.788221       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:10:17.788257       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:10:17.788317       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:10:17.788383       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:10:17.788418       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:10:17.788440       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:10:17.788515       1 binpack.go:165] Enter binpack plugin ...
I0904 12:10:17.788524       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:10:17.788537       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:10:17.788547       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:10:17.788610       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:10:17.788630       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:17.788649       1 allocate.go:62] Enter Allocate ...
I0904 12:10:17.788655       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:17.788668       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:10:17.788677       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:10:17.788684       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:10:17.788690       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:10:17.788696       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:10:17.788702       1 allocate.go:83] Leaving Allocate ...
I0904 12:10:17.788709       1 backfill.go:59] Enter Backfill ...
I0904 12:10:17.788716       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:17.788732       1 backfill.go:110] Leaving Backfill ...
I0904 12:10:17.788740       1 reclaim.go:47] Enter Reclaim ...
I0904 12:10:17.788773       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:10:17.788780       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:17.788791       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:17.788805       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:10:17.788811       1 preempt.go:103] Enter Preempt ...
I0904 12:10:17.788818       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:17.788828       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:17.788838       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:10:17.788846       1 preempt.go:270] Leaving Preempt ...
I0904 12:10:17.788960       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:10:17.788985       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:10:17.788996       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:10:17.789011       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:10:17.789075       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:10:17.789095       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:10:17.789108       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:10:17.789117       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:10:17.789132       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:10:17.789142       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:10:17.789159       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:10:17.789184       1 session.go:361] Session b77a87d2-17c9-4ec8-bc4d-559768715b9a operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:10:17.789223       1 session.go:375] Close Session b77a87d2-17c9-4ec8-bc4d-559768715b9a
I0904 12:10:17.789233       1 scheduler.go:133] End scheduling ...
I0904 12:10:20.377615       1 reflector.go:946] "Watch close" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145" type="*v1alpha1.Numatopology" totalItems=6
I0904 12:10:26.379733       1 reflector.go:946] "Watch close" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145" type="*v1alpha1.HyperNode" totalItems=7
I0904 12:10:27.492454       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:10:27.790279       1 scheduler.go:106] Start scheduling ...
I0904 12:10:27.790440       1 node_info.go:227] imageStates is map[]
I0904 12:10:27.790532       1 node_info.go:227] imageStates is map[]
I0904 12:10:27.790558       1 node_info.go:227] imageStates is map[]
I0904 12:10:27.790586       1 node_info.go:227] imageStates is map[]
I0904 12:10:27.790600       1 node_info.go:227] imageStates is map[]
I0904 12:10:27.790675       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:10:27.790742       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:10:27.790769       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:10:27.790793       1 session.go:230] Open Session f75aade7-b5ae-4536-a3ee-6884c70d0c58 with <1> Job and <5> Queues
I0904 12:10:27.790809       1 session.go:233] Session f75aade7-b5ae-4536-a3ee-6884c70d0c58 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:10:27.790982       1 sla.go:85] Enter sla plugin ...
I0904 12:10:27.791000       1 sla.go:154] Leaving sla plugin.
I0904 12:10:27.791005       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:10:27.791029       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:10:27.791035       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00
I0904 12:10:27.791101       1 factory.go:59] Register preBinder predicates successfully
I0904 12:10:27.791119       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 12:10:27.791143       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:10:27.791176       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:10:27.791207       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:10:27.791226       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:10:27.791242       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:10:27.791268       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:10:27.791281       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:10:27.791290       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:10:27.791304       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:10:27.791319       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:10:27.791331       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:10:27.791346       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:10:27.791355       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:10:27.791394       1 binpack.go:165] Enter binpack plugin ...
I0904 12:10:27.791399       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:10:27.791404       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:10:27.791409       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:10:27.791412       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:10:27.791419       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:27.791441       1 allocate.go:62] Enter Allocate ...
I0904 12:10:27.791443       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:27.791449       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:10:27.791453       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:10:27.791468       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:10:27.791471       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:10:27.791474       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:10:27.791476       1 allocate.go:83] Leaving Allocate ...
I0904 12:10:27.791480       1 backfill.go:59] Enter Backfill ...
I0904 12:10:27.791483       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:27.791499       1 backfill.go:110] Leaving Backfill ...
I0904 12:10:27.791503       1 reclaim.go:47] Enter Reclaim ...
I0904 12:10:27.791506       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:10:27.791508       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:27.791513       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:27.791519       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:10:27.791533       1 preempt.go:103] Enter Preempt ...
I0904 12:10:27.791536       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:27.791542       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:27.791547       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:10:27.791550       1 preempt.go:270] Leaving Preempt ...
I0904 12:10:27.791617       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:10:27.791643       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:10:27.791650       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:10:27.791655       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:10:27.791660       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:10:27.791666       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:10:27.791690       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:10:27.791693       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:10:27.791698       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:10:27.791702       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:10:27.791709       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:10:27.791719       1 session.go:361] Session f75aade7-b5ae-4536-a3ee-6884c70d0c58 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:10:27.791724       1 session.go:375] Close Session f75aade7-b5ae-4536-a3ee-6884c70d0c58
I0904 12:10:27.791728       1 scheduler.go:133] End scheduling ...
I0904 12:10:35.344888       1 cache.go:1179] started sync node integration-control-plane
I0904 12:10:35.344923       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:10:35.345022       1 node_info.go:227] imageStates is map[]
I0904 12:10:37.792594       1 scheduler.go:106] Start scheduling ...
I0904 12:10:37.792823       1 node_info.go:227] imageStates is map[]
I0904 12:10:37.792930       1 node_info.go:227] imageStates is map[]
I0904 12:10:37.792980       1 node_info.go:227] imageStates is map[]
I0904 12:10:37.793012       1 node_info.go:227] imageStates is map[]
I0904 12:10:37.793045       1 node_info.go:227] imageStates is map[]
I0904 12:10:37.793120       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:10:37.793188       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:10:37.793255       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:10:37.793281       1 session.go:230] Open Session 497d4d8f-f87f-4681-8ad1-14d1749ba0f0 with <1> Job and <5> Queues
I0904 12:10:37.793313       1 session.go:233] Session 497d4d8f-f87f-4681-8ad1-14d1749ba0f0 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:10:37.793652       1 sla.go:85] Enter sla plugin ...
I0904 12:10:37.793665       1 sla.go:154] Leaving sla plugin.
I0904 12:10:37.793682       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:10:37.793711       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:10:37.793725       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00
I0904 12:10:37.793855       1 factory.go:59] Register preBinder predicates successfully
I0904 12:10:37.793870       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 12:10:37.793926       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:10:37.793979       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:10:37.794031       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:10:37.794049       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:10:37.794085       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:10:37.794122       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:10:37.794158       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:10:37.794181       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:10:37.794209       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:10:37.794287       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:10:37.794329       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:10:37.794353       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:10:37.794381       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>
I0904 12:10:37.794448       1 binpack.go:165] Enter binpack plugin ...
I0904 12:10:37.794457       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:10:37.794470       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:10:37.794480       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:10:37.794487       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:10:37.794500       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:37.794520       1 allocate.go:62] Enter Allocate ...
I0904 12:10:37.794527       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:37.794542       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:10:37.794551       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:10:37.794559       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:10:37.794565       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:10:37.794573       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:10:37.794580       1 allocate.go:83] Leaving Allocate ...
I0904 12:10:37.794601       1 backfill.go:59] Enter Backfill ...
I0904 12:10:37.794610       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:37.794622       1 backfill.go:110] Leaving Backfill ...
I0904 12:10:37.794630       1 reclaim.go:47] Enter Reclaim ...
I0904 12:10:37.794637       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:10:37.794644       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:37.794656       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:37.794670       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:10:37.794677       1 preempt.go:103] Enter Preempt ...
I0904 12:10:37.794684       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:37.794694       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:37.794705       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:10:37.794714       1 preempt.go:270] Leaving Preempt ...
I0904 12:10:37.794868       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:10:37.794903       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:10:37.794917       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:10:37.794936       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:10:37.794948       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:10:37.794961       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:10:37.794971       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:10:37.794988       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:10:37.795080       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:10:37.795135       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:10:37.795160       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:10:37.795193       1 session.go:361] Session 497d4d8f-f87f-4681-8ad1-14d1749ba0f0 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:10:37.795391       1 session.go:375] Close Session 497d4d8f-f87f-4681-8ad1-14d1749ba0f0
I0904 12:10:37.795405       1 scheduler.go:133] End scheduling ...
I0904 12:10:47.796125       1 scheduler.go:106] Start scheduling ...
I0904 12:10:47.796303       1 node_info.go:227] imageStates is map[]
I0904 12:10:47.796337       1 node_info.go:227] imageStates is map[]
I0904 12:10:47.796363       1 node_info.go:227] imageStates is map[]
I0904 12:10:47.796375       1 node_info.go:227] imageStates is map[]
I0904 12:10:47.796386       1 node_info.go:227] imageStates is map[]
I0904 12:10:47.796410       1 cache.go:1419] The priority of job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> is </0>
I0904 12:10:47.796439       1 cache.go:1455] "SnapShot for scheduling" jobNum=1 QueueNum=5 NodeNum=5
I0904 12:10:47.796453       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:10:47.796463       1 session.go:230] Open Session ac381cbc-06bd-4092-b291-6245a51916b3 with <1> Job and <5> Queues
I0904 12:10:47.796475       1 session.go:233] Session ac381cbc-06bd-4092-b291-6245a51916b3 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:10:47.796609       1 sla.go:85] Enter sla plugin ...
I0904 12:10:47.796627       1 sla.go:154] Leaving sla plugin.
I0904 12:10:47.796632       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:10:47.796643       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:10:47.796648       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00
I0904 12:10:47.796693       1 factory.go:59] Register preBinder predicates successfully
I0904 12:10:47.796699       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 12:10:47.796717       1 capacity.go:548] Considering Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>.
I0904 12:10:47.796733       1 capacity.go:596] Queue q1 allocated <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00> inqueue <cpu 0.00, memory 0.00> elastic <cpu 0.00, memory 0.00>
I0904 12:10:47.796771       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:10:47.796787       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:10:47.796800       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:10:47.796816       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, elastic <cpu 0.00, memory 0.00>, share <1.00>
I0904 12:10:47.796827       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:10:47.796834       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>, request <cpu 1000.00, memory 1073741824.00, pods 1.00, nvidia.com/A100 2000.00>, elastic <cpu 0.00, memory 0.00>, share <0.25>
I0904 12:10:47.796845       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:10:47.796858       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:10:47.796867       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:10:47.796876       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 1000.00, memory 1073741824.00, nvidia.com/A100 2000.00, pods 1.00>
I0904 12:10:47.796891       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:10:47.796918       1 binpack.go:165] Enter binpack plugin ...
I0904 12:10:47.796921       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:10:47.796925       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:10:47.796931       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:10:47.796933       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:10:47.796939       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:47.796946       1 allocate.go:62] Enter Allocate ...
I0904 12:10:47.796949       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:47.796953       1 allocate.go:117] Added Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> into Queue <q1>
I0904 12:10:47.796956       1 allocate.go:81] Try to allocate resource to 1 Queues
I0904 12:10:47.796959       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:10:47.796962       1 allocate.go:146] Try to allocate resource to Jobs in Queue <q1>
I0904 12:10:47.796964       1 allocate.go:150] Can not find jobs for queue q1.
I0904 12:10:47.796966       1 allocate.go:83] Leaving Allocate ...
I0904 12:10:47.796969       1 backfill.go:59] Enter Backfill ...
I0904 12:10:47.796971       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:47.796975       1 backfill.go:110] Leaving Backfill ...
I0904 12:10:47.796978       1 reclaim.go:47] Enter Reclaim ...
I0904 12:10:47.796980       1 reclaim.go:56] There are <1> Jobs and <5> Queues in total for scheduling.
I0904 12:10:47.796983       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:47.796987       1 reclaim.go:73] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:47.797002       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:10:47.797005       1 preempt.go:103] Enter Preempt ...
I0904 12:10:47.797009       1 job_info.go:935] job podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6/qkzxnakm actual: map[:1], ji.TaskMinAvailable: map[]
I0904 12:10:47.797013       1 preempt.go:127] Added Queue <q1> for Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:47.797016       1 preempt.go:157] No preemptors in Queue <q1>, break.
I0904 12:10:47.797019       1 preempt.go:270] Leaving Preempt ...
I0904 12:10:47.797090       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:10:47.797115       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:10:47.797120       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:10:47.797125       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:10:47.797129       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:10:47.797135       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]
I0904 12:10:47.797155       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:10:47.797158       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:10:47.797162       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:10:47.797168       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{1000 -3} {<nil>}  DecimalSI} memory:{{1073741824 0} {<nil>}  BinarySI} nvidia.com/A100:{{2000 -3} {<nil>}  DecimalSI} pods:{{1 0} {<nil>}  DecimalSI}]>
I0904 12:10:47.797173       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}]>.
I0904 12:10:47.797183       1 session.go:361] Session ac381cbc-06bd-4092-b291-6245a51916b3 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:10:47.797186       1 session.go:375] Close Session ac381cbc-06bd-4092-b291-6245a51916b3
I0904 12:10:47.797190       1 scheduler.go:133] End scheduling ...
I0904 12:10:54.185910       1 util.go:63] schedulerPodName  is responsible to Pod qkzxnakm/q1-twsxj
I0904 12:10:54.185989       1 util.go:63] schedulerPodName  is responsible to Pod qkzxnakm/q1-twsxj
I0904 12:10:54.186276       1 event_handlers.go:423] Updated pod <qkzxnakm/q1-twsxj> in cache.
I0904 12:10:54.188798       1 util.go:101] schedulerPodName  is responsible to PodGroup qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6
I0904 12:10:54.188834       1 cache.go:1045] Try to delete Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6:qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:54.188866       1 cache.go:1051] Retry to delete Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6:qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:54.192603       1 util.go:63] schedulerPodName  is responsible to Pod qkzxnakm/q1-twsxj
I0904 12:10:54.192713       1 util.go:63] schedulerPodName  is responsible to Pod qkzxnakm/q1-twsxj
I0904 12:10:54.192830       1 cache.go:1045] Try to delete Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6:qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:54.192953       1 event_handlers.go:423] Updated pod <qkzxnakm/q1-twsxj> in cache.
I0904 12:10:54.193010       1 cache.go:1051] Retry to delete Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6:qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:54.194069       1 cache.go:1051] Retry to delete Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6:qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:54.209666       1 util.go:63] schedulerPodName  is responsible to Pod qkzxnakm/q1-twsxj
I0904 12:10:54.209695       1 util.go:63] schedulerPodName  is responsible to Pod qkzxnakm/q1-twsxj
I0904 12:10:54.209739       1 cache.go:1045] Try to delete Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6:qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:54.209762       1 event_handlers.go:423] Updated pod <qkzxnakm/q1-twsxj> in cache.
I0904 12:10:54.209776       1 cache.go:1051] Retry to delete Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6:qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:54.212414       1 util.go:63] schedulerPodName  is responsible to Pod qkzxnakm/q1-twsxj
I0904 12:10:54.212502       1 cache.go:1045] Try to delete Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6:qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>
I0904 12:10:54.212529       1 event_handlers.go:453] Deleted pod <qkzxnakm/q1-twsxj> from cache.
I0904 12:10:54.212570       1 cache.go:1076] Just add pguid:2dca5853-298d-4c9a-958b-ad9779ae5833, try to delete pguid:2dca5853-298d-4c9a-958b-ad9779ae5833
I0904 12:10:54.212587       1 cache.go:1080] Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6:qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6> was deleted.
I0904 12:10:54.214331       1 cache.go:1070] Failed to find Job <qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6:qkzxnakm/podgroup-279389a3-6e3a-4acf-bd0f-b40e471013f6>, ignore it
I0904 12:10:55.544716       1 cache.go:1179] started sync node integration-control-plane
I0904 12:10:55.545158       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:10:55.545541       1 node_info.go:227] imageStates is map[]
I0904 12:10:57.493623       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:10:57.798213       1 scheduler.go:106] Start scheduling ...
I0904 12:10:57.798647       1 node_info.go:227] imageStates is map[]
I0904 12:10:57.798708       1 node_info.go:227] imageStates is map[]
I0904 12:10:57.798751       1 node_info.go:227] imageStates is map[]
I0904 12:10:57.798791       1 node_info.go:227] imageStates is map[]
I0904 12:10:57.799016       1 node_info.go:227] imageStates is map[]
I0904 12:10:57.799090       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:10:57.799128       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:10:57.799163       1 session.go:230] Open Session e4e837c6-f6b5-49dd-b5e4-70b9b8c66432 with <0> Job and <5> Queues
I0904 12:10:57.799209       1 session.go:233] Session e4e837c6-f6b5-49dd-b5e4-70b9b8c66432 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:10:57.799598       1 sla.go:85] Enter sla plugin ...
I0904 12:10:57.799697       1 sla.go:154] Leaving sla plugin.
I0904 12:10:57.799718       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:10:57.799742       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:10:57.799759       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00
I0904 12:10:57.800468       1 factory.go:59] Register preBinder predicates successfully
I0904 12:10:57.800531       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 12:10:57.800651       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:10:57.800670       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:10:57.800750       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:10:57.800776       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:10:57.800818       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:10:57.800838       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:10:57.800864       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:10:57.800894       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:10:57.800926       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:10:57.800947       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:10:57.800971       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:10:57.801039       1 binpack.go:165] Enter binpack plugin ...
I0904 12:10:57.801047       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:10:57.801060       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:10:57.801069       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:10:57.801076       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:10:57.801085       1 allocate.go:62] Enter Allocate ...
I0904 12:10:57.801092       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:10:57.801099       1 allocate.go:83] Leaving Allocate ...
I0904 12:10:57.801106       1 backfill.go:59] Enter Backfill ...
I0904 12:10:57.801115       1 backfill.go:110] Leaving Backfill ...
I0904 12:10:57.801122       1 reclaim.go:47] Enter Reclaim ...
I0904 12:10:57.801130       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:10:57.801141       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:10:57.801152       1 preempt.go:103] Enter Preempt ...
I0904 12:10:57.801161       1 preempt.go:270] Leaving Preempt ...
I0904 12:10:57.801191       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:10:57.801256       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:10:57.801265       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:10:57.811204       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:10:57.816878       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:10:57.816919       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:10:57.816923       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:10:57.816929       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{1 0} {<nil>} 1 DecimalSI} memory:{{1073741824 0} {<nil>} 1Gi BinarySI} nvidia.com/A100:{{2 0} {<nil>} 2 DecimalSI} pods:{{1 0} {<nil>} 1 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:10:57.828429       1 session.go:361] Session e4e837c6-f6b5-49dd-b5e4-70b9b8c66432 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:10:57.828477       1 session.go:375] Close Session e4e837c6-f6b5-49dd-b5e4-70b9b8c66432
I0904 12:10:57.828489       1 scheduler.go:133] End scheduling ...
I0904 12:11:07.829201       1 scheduler.go:106] Start scheduling ...
I0904 12:11:07.829467       1 node_info.go:227] imageStates is map[]
I0904 12:11:07.829585       1 node_info.go:227] imageStates is map[]
I0904 12:11:07.829618       1 node_info.go:227] imageStates is map[]
I0904 12:11:07.829647       1 node_info.go:227] imageStates is map[]
I0904 12:11:07.829675       1 node_info.go:227] imageStates is map[]
I0904 12:11:07.829721       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:11:07.829788       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:11:07.829812       1 session.go:230] Open Session cfea2e15-ebb2-47a9-9777-5e9af9923bde with <0> Job and <5> Queues
I0904 12:11:07.829830       1 session.go:233] Session cfea2e15-ebb2-47a9-9777-5e9af9923bde operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:11:07.829952       1 sla.go:85] Enter sla plugin ...
I0904 12:11:07.829956       1 sla.go:154] Leaving sla plugin.
I0904 12:11:07.829961       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:11:07.829968       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:11:07.829974       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00
I0904 12:11:07.830034       1 factory.go:59] Register preBinder predicates successfully
I0904 12:11:07.830061       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:11:07.830149       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:11:07.830162       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:07.830183       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:07.830201       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:07.830213       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:07.830227       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:07.830243       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:07.830258       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:07.830285       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:07.830295       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:07.830311       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:07.830353       1 binpack.go:165] Enter binpack plugin ...
I0904 12:11:07.830358       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:11:07.830364       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:11:07.830370       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:11:07.830373       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:11:07.830379       1 allocate.go:62] Enter Allocate ...
I0904 12:11:07.830382       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:11:07.830385       1 allocate.go:83] Leaving Allocate ...
I0904 12:11:07.830389       1 backfill.go:59] Enter Backfill ...
I0904 12:11:07.830392       1 backfill.go:110] Leaving Backfill ...
I0904 12:11:07.830396       1 reclaim.go:47] Enter Reclaim ...
I0904 12:11:07.830398       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:11:07.830404       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:11:07.830407       1 preempt.go:103] Enter Preempt ...
I0904 12:11:07.830411       1 preempt.go:270] Leaving Preempt ...
I0904 12:11:07.830428       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:07.830471       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:07.830479       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:07.830486       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:07.830491       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:07.830496       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:07.830499       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:07.830505       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:07.830509       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:07.830516       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:11:07.830550       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:11:07.830562       1 session.go:361] Session cfea2e15-ebb2-47a9-9777-5e9af9923bde operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:11:07.830566       1 session.go:375] Close Session cfea2e15-ebb2-47a9-9777-5e9af9923bde
I0904 12:11:07.830572       1 scheduler.go:133] End scheduling ...
I0904 12:11:15.995046       1 cache.go:1179] started sync node integration-control-plane
I0904 12:11:15.995177       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:11:15.995384       1 node_info.go:227] imageStates is map[]
I0904 12:11:17.831304       1 scheduler.go:106] Start scheduling ...
I0904 12:11:17.831388       1 node_info.go:227] imageStates is map[]
I0904 12:11:17.831408       1 node_info.go:227] imageStates is map[]
I0904 12:11:17.831420       1 node_info.go:227] imageStates is map[]
I0904 12:11:17.831458       1 node_info.go:227] imageStates is map[]
I0904 12:11:17.831475       1 node_info.go:227] imageStates is map[]
I0904 12:11:17.831495       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:11:17.831509       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:11:17.831524       1 session.go:230] Open Session dba8793d-537f-4777-8bb2-d7952b0b2145 with <0> Job and <5> Queues
I0904 12:11:17.831539       1 session.go:233] Session dba8793d-537f-4777-8bb2-d7952b0b2145 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:11:17.831676       1 sla.go:85] Enter sla plugin ...
I0904 12:11:17.831695       1 sla.go:154] Leaving sla plugin.
I0904 12:11:17.831700       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:11:17.831708       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:11:17.831715       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00
I0904 12:11:17.831766       1 factory.go:59] Register preBinder predicates successfully
I0904 12:11:17.831786       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 12:11:17.831826       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:11:17.831846       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:17.831858       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:17.831873       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:17.831890       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:17.831925       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:17.831949       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:17.831969       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:17.831981       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:17.831994       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:17.832005       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:17.832051       1 binpack.go:165] Enter binpack plugin ...
I0904 12:11:17.832096       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:11:17.832104       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:11:17.832111       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:11:17.832115       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:11:17.832121       1 allocate.go:62] Enter Allocate ...
I0904 12:11:17.832125       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:11:17.832128       1 allocate.go:83] Leaving Allocate ...
I0904 12:11:17.832133       1 backfill.go:59] Enter Backfill ...
I0904 12:11:17.832137       1 backfill.go:110] Leaving Backfill ...
I0904 12:11:17.832141       1 reclaim.go:47] Enter Reclaim ...
I0904 12:11:17.832144       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:11:17.832151       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:11:17.832154       1 preempt.go:103] Enter Preempt ...
I0904 12:11:17.832159       1 preempt.go:270] Leaving Preempt ...
I0904 12:11:17.832176       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:17.832200       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:17.832207       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:17.832216       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:17.832223       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:17.832230       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:17.832236       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:17.832245       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:17.832254       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:17.832265       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:11:17.832328       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:11:17.832354       1 session.go:361] Session dba8793d-537f-4777-8bb2-d7952b0b2145 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:11:17.832362       1 session.go:375] Close Session dba8793d-537f-4777-8bb2-d7952b0b2145
I0904 12:11:17.832369       1 scheduler.go:133] End scheduling ...
I0904 12:11:23.283142       1 cache.go:1179] started sync node kwok-node-2
I0904 12:11:23.283204       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-2
I0904 12:11:23.283296       1 node_info.go:227] imageStates is map[]
I0904 12:11:24.423589       1 cache.go:1179] started sync node kwok-node-a100-mate-0
I0904 12:11:24.423630       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-a100-mate-0
I0904 12:11:24.423751       1 node_info.go:227] imageStates is map[]
I0904 12:11:26.202314       1 cache.go:1179] started sync node integration-control-plane
I0904 12:11:26.202352       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:11:26.202476       1 node_info.go:227] imageStates is map[]
I0904 12:11:26.352960       1 cache.go:1179] started sync node kwok-node-1
I0904 12:11:26.353003       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-1
I0904 12:11:26.353079       1 node_info.go:227] imageStates is map[]
I0904 12:11:27.494382       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:11:27.833102       1 scheduler.go:106] Start scheduling ...
I0904 12:11:27.833225       1 node_info.go:227] imageStates is map[]
I0904 12:11:27.833253       1 node_info.go:227] imageStates is map[]
I0904 12:11:27.833277       1 node_info.go:227] imageStates is map[]
I0904 12:11:27.833305       1 node_info.go:227] imageStates is map[]
I0904 12:11:27.833318       1 node_info.go:227] imageStates is map[]
I0904 12:11:27.833333       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:11:27.833344       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:11:27.833352       1 session.go:230] Open Session 5b53fb72-dde4-4a73-97d9-68385b108734 with <0> Job and <5> Queues
I0904 12:11:27.833363       1 session.go:233] Session 5b53fb72-dde4-4a73-97d9-68385b108734 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:11:27.833536       1 sla.go:85] Enter sla plugin ...
I0904 12:11:27.833551       1 sla.go:154] Leaving sla plugin.
I0904 12:11:27.833556       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:11:27.833562       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:11:27.833568       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:11:27.833616       1 factory.go:59] Register preBinder predicates successfully
I0904 12:11:27.833621       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:11:27.833657       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:11:27.833663       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:27.833671       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:27.833683       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:27.833690       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:27.833700       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:27.833711       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:27.833735       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:27.833745       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:27.833753       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:27.833765       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:27.833798       1 binpack.go:165] Enter binpack plugin ...
I0904 12:11:27.833801       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:11:27.833805       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:11:27.833810       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:11:27.833812       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:11:27.833816       1 allocate.go:62] Enter Allocate ...
I0904 12:11:27.833819       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:11:27.833822       1 allocate.go:83] Leaving Allocate ...
I0904 12:11:27.833825       1 backfill.go:59] Enter Backfill ...
I0904 12:11:27.833827       1 backfill.go:110] Leaving Backfill ...
I0904 12:11:27.833830       1 reclaim.go:47] Enter Reclaim ...
I0904 12:11:27.833833       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:11:27.833837       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:11:27.833839       1 preempt.go:103] Enter Preempt ...
I0904 12:11:27.833843       1 preempt.go:270] Leaving Preempt ...
I0904 12:11:27.833854       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:27.833871       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:27.833875       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:27.833879       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:27.833881       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:27.833886       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:27.833889       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:27.833893       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:11:27.833911       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:11:27.833914       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:27.833918       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:27.833927       1 session.go:361] Session 5b53fb72-dde4-4a73-97d9-68385b108734 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:11:27.833942       1 session.go:375] Close Session 5b53fb72-dde4-4a73-97d9-68385b108734
I0904 12:11:27.833945       1 scheduler.go:133] End scheduling ...
I0904 12:11:29.320380       1 cache.go:1179] started sync node kwok-node-0
I0904 12:11:29.320421       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-0
I0904 12:11:29.320545       1 node_info.go:227] imageStates is map[]
I0904 12:11:36.298488       1 cache.go:1179] started sync node integration-control-plane
I0904 12:11:36.298507       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:11:36.298604       1 node_info.go:227] imageStates is map[]
I0904 12:11:37.834647       1 scheduler.go:106] Start scheduling ...
I0904 12:11:37.834797       1 node_info.go:227] imageStates is map[]
I0904 12:11:37.834841       1 node_info.go:227] imageStates is map[]
I0904 12:11:37.834889       1 node_info.go:227] imageStates is map[]
I0904 12:11:37.834912       1 node_info.go:227] imageStates is map[]
I0904 12:11:37.834930       1 node_info.go:227] imageStates is map[]
I0904 12:11:37.834954       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:11:37.834970       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:11:37.834984       1 session.go:230] Open Session 8fec082e-3560-4448-9cf5-bb26c446653a with <0> Job and <5> Queues
I0904 12:11:37.835002       1 session.go:233] Session 8fec082e-3560-4448-9cf5-bb26c446653a operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:11:37.835232       1 sla.go:85] Enter sla plugin ...
I0904 12:11:37.835240       1 sla.go:154] Leaving sla plugin.
I0904 12:11:37.835270       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:11:37.835281       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:11:37.835288       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 12:11:37.835352       1 factory.go:59] Register preBinder predicates successfully
I0904 12:11:37.835360       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:11:37.835415       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:11:37.835425       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:37.835442       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:37.835457       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:37.835472       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:37.835485       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:37.835500       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:37.835522       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:37.835535       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:37.835547       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:37.835564       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:37.835596       1 binpack.go:165] Enter binpack plugin ...
I0904 12:11:37.835601       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:11:37.835614       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:11:37.835620       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:11:37.835624       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:11:37.835630       1 allocate.go:62] Enter Allocate ...
I0904 12:11:37.835634       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:11:37.835637       1 allocate.go:83] Leaving Allocate ...
I0904 12:11:37.835642       1 backfill.go:59] Enter Backfill ...
I0904 12:11:37.835647       1 backfill.go:110] Leaving Backfill ...
I0904 12:11:37.835651       1 reclaim.go:47] Enter Reclaim ...
I0904 12:11:37.835654       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:11:37.835661       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:11:37.835665       1 preempt.go:103] Enter Preempt ...
I0904 12:11:37.835670       1 preempt.go:270] Leaving Preempt ...
I0904 12:11:37.835688       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:37.835713       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:37.835721       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:37.835728       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:37.835734       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:37.835740       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:37.835746       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:37.835752       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:37.835756       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:37.835765       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:11:37.835795       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:11:37.835807       1 session.go:361] Session 8fec082e-3560-4448-9cf5-bb26c446653a operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:11:37.835812       1 session.go:375] Close Session 8fec082e-3560-4448-9cf5-bb26c446653a
I0904 12:11:37.835817       1 scheduler.go:133] End scheduling ...
I0904 12:11:46.425899       1 cache.go:1179] started sync node integration-control-plane
I0904 12:11:46.425947       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:11:46.426038       1 node_info.go:227] imageStates is map[]
I0904 12:11:47.836753       1 scheduler.go:106] Start scheduling ...
I0904 12:11:47.836914       1 node_info.go:227] imageStates is map[]
I0904 12:11:47.836939       1 node_info.go:227] imageStates is map[]
I0904 12:11:47.836990       1 node_info.go:227] imageStates is map[]
I0904 12:11:47.837018       1 node_info.go:227] imageStates is map[]
I0904 12:11:47.837072       1 node_info.go:227] imageStates is map[]
I0904 12:11:47.837102       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:11:47.837126       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:11:47.837175       1 session.go:230] Open Session 43d8954c-4a94-4d20-b9fd-ef48466637d1 with <0> Job and <5> Queues
I0904 12:11:47.837201       1 session.go:233] Session 43d8954c-4a94-4d20-b9fd-ef48466637d1 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:11:47.837365       1 sla.go:85] Enter sla plugin ...
I0904 12:11:47.837410       1 sla.go:154] Leaving sla plugin.
I0904 12:11:47.837419       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:11:47.837429       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:11:47.837436       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00
I0904 12:11:47.837500       1 factory.go:59] Register preBinder predicates successfully
I0904 12:11:47.837509       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>
I0904 12:11:47.837592       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:11:47.837633       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:47.837682       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:47.837731       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:47.837779       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:47.837795       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:47.837811       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:47.837832       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:47.837849       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:47.837916       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:47.837934       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:47.837981       1 binpack.go:165] Enter binpack plugin ...
I0904 12:11:47.837987       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:11:47.837994       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:11:47.838000       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:11:47.838006       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:11:47.838012       1 allocate.go:62] Enter Allocate ...
I0904 12:11:47.838017       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:11:47.838020       1 allocate.go:83] Leaving Allocate ...
I0904 12:11:47.838025       1 backfill.go:59] Enter Backfill ...
I0904 12:11:47.838030       1 backfill.go:110] Leaving Backfill ...
I0904 12:11:47.838034       1 reclaim.go:47] Enter Reclaim ...
I0904 12:11:47.838041       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:11:47.838055       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:11:47.838062       1 preempt.go:103] Enter Preempt ...
I0904 12:11:47.838071       1 preempt.go:270] Leaving Preempt ...
I0904 12:11:47.838096       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:47.838121       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:11:47.838182       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:11:47.838190       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:47.838204       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:47.838215       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:47.838228       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:47.838237       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:47.838248       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:47.838258       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:47.838269       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:47.838292       1 session.go:361] Session 43d8954c-4a94-4d20-b9fd-ef48466637d1 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:11:47.838300       1 session.go:375] Close Session 43d8954c-4a94-4d20-b9fd-ef48466637d1
I0904 12:11:47.838308       1 scheduler.go:133] End scheduling ...
I0904 12:11:57.495649       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:11:57.839497       1 scheduler.go:106] Start scheduling ...
I0904 12:11:57.839685       1 node_info.go:227] imageStates is map[]
I0904 12:11:57.839787       1 node_info.go:227] imageStates is map[]
I0904 12:11:57.839816       1 node_info.go:227] imageStates is map[]
I0904 12:11:57.839838       1 node_info.go:227] imageStates is map[]
I0904 12:11:57.839912       1 node_info.go:227] imageStates is map[]
I0904 12:11:57.839946       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:11:57.839969       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:11:57.839986       1 session.go:230] Open Session 989eedd3-0826-4b80-94ed-b3c9be8f1b06 with <0> Job and <5> Queues
I0904 12:11:57.840009       1 session.go:233] Session 989eedd3-0826-4b80-94ed-b3c9be8f1b06 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:11:57.841165       1 sla.go:85] Enter sla plugin ...
I0904 12:11:57.841190       1 sla.go:154] Leaving sla plugin.
I0904 12:11:57.841196       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:11:57.841205       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:11:57.841211       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:11:57.841266       1 factory.go:59] Register preBinder predicates successfully
I0904 12:11:57.841273       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:11:57.841322       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:11:57.841330       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:57.841357       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:57.841371       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:57.841381       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:57.841392       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:11:57.841404       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:57.841420       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:57.841449       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:57.841463       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:57.841473       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:11:57.841516       1 binpack.go:165] Enter binpack plugin ...
I0904 12:11:57.841520       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:11:57.841526       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:11:57.841531       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:11:57.841534       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:11:57.841540       1 allocate.go:62] Enter Allocate ...
I0904 12:11:57.841543       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:11:57.841547       1 allocate.go:83] Leaving Allocate ...
I0904 12:11:57.841551       1 backfill.go:59] Enter Backfill ...
I0904 12:11:57.841555       1 backfill.go:110] Leaving Backfill ...
I0904 12:11:57.841559       1 reclaim.go:47] Enter Reclaim ...
I0904 12:11:57.841562       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:11:57.841568       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:11:57.841571       1 preempt.go:103] Enter Preempt ...
I0904 12:11:57.841576       1 preempt.go:270] Leaving Preempt ...
I0904 12:11:57.841591       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:57.841613       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:57.841617       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:57.841623       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:57.841626       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:57.841634       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:11:57.841658       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:11:57.841661       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:57.841667       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:57.841671       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:11:57.841676       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:11:57.841687       1 session.go:361] Session 989eedd3-0826-4b80-94ed-b3c9be8f1b06 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:11:57.841705       1 session.go:375] Close Session 989eedd3-0826-4b80-94ed-b3c9be8f1b06
I0904 12:11:57.841710       1 scheduler.go:133] End scheduling ...
I0904 12:12:07.842406       1 scheduler.go:106] Start scheduling ...
I0904 12:12:07.842537       1 node_info.go:227] imageStates is map[]
I0904 12:12:07.842594       1 node_info.go:227] imageStates is map[]
I0904 12:12:07.842631       1 node_info.go:227] imageStates is map[]
I0904 12:12:07.842664       1 node_info.go:227] imageStates is map[]
I0904 12:12:07.842700       1 node_info.go:227] imageStates is map[]
I0904 12:12:07.842723       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:12:07.842738       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:12:07.842751       1 session.go:230] Open Session 151388d8-03d4-44fc-add5-35b8fc6dc26f with <0> Job and <5> Queues
I0904 12:12:07.842772       1 session.go:233] Session 151388d8-03d4-44fc-add5-35b8fc6dc26f operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:12:07.842919       1 sla.go:85] Enter sla plugin ...
I0904 12:12:07.842942       1 sla.go:154] Leaving sla plugin.
I0904 12:12:07.842949       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:12:07.842959       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:12:07.842966       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00
I0904 12:12:07.843335       1 factory.go:59] Register preBinder predicates successfully
I0904 12:12:07.843381       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>
I0904 12:12:07.843459       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:12:07.843470       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:07.843488       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:07.843522       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:07.843535       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:07.843552       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:07.843576       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:07.843602       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:07.843621       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:07.843648       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:07.843670       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:07.843764       1 binpack.go:165] Enter binpack plugin ...
I0904 12:12:07.843774       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:12:07.843783       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:12:07.843792       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:12:07.843797       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:12:07.843805       1 allocate.go:62] Enter Allocate ...
I0904 12:12:07.843811       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:12:07.843816       1 allocate.go:83] Leaving Allocate ...
I0904 12:12:07.843822       1 backfill.go:59] Enter Backfill ...
I0904 12:12:07.843828       1 backfill.go:110] Leaving Backfill ...
I0904 12:12:07.843835       1 reclaim.go:47] Enter Reclaim ...
I0904 12:12:07.843840       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:12:07.843850       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:12:07.843863       1 preempt.go:103] Enter Preempt ...
I0904 12:12:07.843871       1 preempt.go:270] Leaving Preempt ...
I0904 12:12:07.843907       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:07.844013       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:07.844042       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:07.844057       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:07.844069       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:07.844085       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:12:07.844168       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:12:07.844181       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:07.844202       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:07.844220       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:07.844241       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:07.844285       1 session.go:361] Session 151388d8-03d4-44fc-add5-35b8fc6dc26f operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:12:07.844299       1 session.go:375] Close Session 151388d8-03d4-44fc-add5-35b8fc6dc26f
I0904 12:12:07.844314       1 scheduler.go:133] End scheduling ...
I0904 12:12:10.383146       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Pod" totalItems=12
I0904 12:12:12.373853       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Namespace" totalItems=6
I0904 12:12:17.845157       1 scheduler.go:106] Start scheduling ...
I0904 12:12:17.845285       1 node_info.go:227] imageStates is map[]
I0904 12:12:17.845313       1 node_info.go:227] imageStates is map[]
I0904 12:12:17.845380       1 node_info.go:227] imageStates is map[]
I0904 12:12:17.845417       1 node_info.go:227] imageStates is map[]
I0904 12:12:17.845437       1 node_info.go:227] imageStates is map[]
I0904 12:12:17.845461       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:12:17.845480       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:12:17.845496       1 session.go:230] Open Session b1b868b2-738e-4861-b339-db25eb566a9b with <0> Job and <5> Queues
I0904 12:12:17.845524       1 session.go:233] Session b1b868b2-738e-4861-b339-db25eb566a9b operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:12:17.845941       1 sla.go:85] Enter sla plugin ...
I0904 12:12:17.845983       1 sla.go:154] Leaving sla plugin.
I0904 12:12:17.845992       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:12:17.846007       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:12:17.846016       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00
I0904 12:12:17.846092       1 factory.go:59] Register preBinder predicates successfully
I0904 12:12:17.846126       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:12:17.846221       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:12:17.846254       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:17.846275       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:17.846300       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:17.846318       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:17.846334       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:17.846353       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:17.846381       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:17.846401       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:17.846458       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:17.846478       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:17.846537       1 binpack.go:165] Enter binpack plugin ...
I0904 12:12:17.846564       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:12:17.846574       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:12:17.846582       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:12:17.846586       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:12:17.846595       1 allocate.go:62] Enter Allocate ...
I0904 12:12:17.846599       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:12:17.846605       1 allocate.go:83] Leaving Allocate ...
I0904 12:12:17.846610       1 backfill.go:59] Enter Backfill ...
I0904 12:12:17.846616       1 backfill.go:110] Leaving Backfill ...
I0904 12:12:17.846621       1 reclaim.go:47] Enter Reclaim ...
I0904 12:12:17.846626       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:12:17.846635       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:12:17.846641       1 preempt.go:103] Enter Preempt ...
I0904 12:12:17.846648       1 preempt.go:270] Leaving Preempt ...
I0904 12:12:17.846690       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:17.846709       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:12:17.846758       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:12:17.846783       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:17.846796       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:17.846803       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:17.846812       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:17.846818       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:17.846827       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:17.846832       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:17.846841       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:17.846857       1 session.go:361] Session b1b868b2-738e-4861-b339-db25eb566a9b operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:12:17.846863       1 session.go:375] Close Session b1b868b2-738e-4861-b339-db25eb566a9b
I0904 12:12:17.846871       1 scheduler.go:133] End scheduling ...
I0904 12:12:27.496659       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:12:27.847320       1 scheduler.go:106] Start scheduling ...
I0904 12:12:27.847454       1 node_info.go:227] imageStates is map[]
I0904 12:12:27.847495       1 node_info.go:227] imageStates is map[]
I0904 12:12:27.847513       1 node_info.go:227] imageStates is map[]
I0904 12:12:27.847527       1 node_info.go:227] imageStates is map[]
I0904 12:12:27.847549       1 node_info.go:227] imageStates is map[]
I0904 12:12:27.847572       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:12:27.847588       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:12:27.847600       1 session.go:230] Open Session 5d534a71-f9a0-4e87-815f-33b735169ebb with <0> Job and <5> Queues
I0904 12:12:27.847620       1 session.go:233] Session 5d534a71-f9a0-4e87-815f-33b735169ebb operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:12:27.847809       1 sla.go:85] Enter sla plugin ...
I0904 12:12:27.847815       1 sla.go:154] Leaving sla plugin.
I0904 12:12:27.847821       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:12:27.847831       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:12:27.847838       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00
I0904 12:12:27.847898       1 factory.go:59] Register preBinder predicates successfully
I0904 12:12:27.847905       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
I0904 12:12:27.847955       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:12:27.847965       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:27.847979       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:27.847990       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:27.848002       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:27.848016       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:27.848034       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:27.848053       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:27.848067       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:27.848081       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, pods 550.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:27.848116       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:27.848162       1 binpack.go:165] Enter binpack plugin ...
I0904 12:12:27.848167       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:12:27.848177       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:12:27.848183       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:12:27.848186       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:12:27.848192       1 allocate.go:62] Enter Allocate ...
I0904 12:12:27.848200       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:12:27.848204       1 allocate.go:83] Leaving Allocate ...
I0904 12:12:27.848208       1 backfill.go:59] Enter Backfill ...
I0904 12:12:27.848212       1 backfill.go:110] Leaving Backfill ...
I0904 12:12:27.848217       1 reclaim.go:47] Enter Reclaim ...
I0904 12:12:27.848220       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:12:27.848227       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:12:27.848230       1 preempt.go:103] Enter Preempt ...
I0904 12:12:27.848235       1 preempt.go:270] Leaving Preempt ...
I0904 12:12:27.848251       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:27.848292       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:27.848299       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:27.848305       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:27.848310       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:27.848315       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:27.848331       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:27.848337       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:27.848341       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:27.848348       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:12:27.848378       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:12:27.848391       1 session.go:361] Session 5d534a71-f9a0-4e87-815f-33b735169ebb operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:12:27.848395       1 session.go:375] Close Session 5d534a71-f9a0-4e87-815f-33b735169ebb
I0904 12:12:27.848400       1 scheduler.go:133] End scheduling ...
I0904 12:12:37.849303       1 scheduler.go:106] Start scheduling ...
I0904 12:12:37.849406       1 node_info.go:227] imageStates is map[]
I0904 12:12:37.849427       1 node_info.go:227] imageStates is map[]
I0904 12:12:37.849442       1 node_info.go:227] imageStates is map[]
I0904 12:12:37.849508       1 node_info.go:227] imageStates is map[]
I0904 12:12:37.849533       1 node_info.go:227] imageStates is map[]
I0904 12:12:37.849553       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:12:37.849568       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:12:37.849580       1 session.go:230] Open Session 7fd15229-de75-4f94-85c8-2ef0b6fb490d with <0> Job and <5> Queues
I0904 12:12:37.849600       1 session.go:233] Session 7fd15229-de75-4f94-85c8-2ef0b6fb490d operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:12:37.849786       1 sla.go:85] Enter sla plugin ...
I0904 12:12:37.849814       1 sla.go:154] Leaving sla plugin.
I0904 12:12:37.849822       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:12:37.849832       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:12:37.849839       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00
I0904 12:12:37.849902       1 factory.go:59] Register preBinder predicates successfully
I0904 12:12:37.849910       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>
I0904 12:12:37.849969       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:12:37.849998       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:37.850017       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:37.850032       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:37.850043       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:37.850054       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:37.850072       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:37.850302       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:37.850327       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:37.850340       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:37.850358       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:37.850436       1 binpack.go:165] Enter binpack plugin ...
I0904 12:12:37.850443       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:12:37.850450       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:12:37.850457       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:12:37.850460       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:12:37.850471       1 allocate.go:62] Enter Allocate ...
I0904 12:12:37.850476       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:12:37.850481       1 allocate.go:83] Leaving Allocate ...
I0904 12:12:37.850485       1 backfill.go:59] Enter Backfill ...
I0904 12:12:37.850490       1 backfill.go:110] Leaving Backfill ...
I0904 12:12:37.850494       1 reclaim.go:47] Enter Reclaim ...
I0904 12:12:37.850498       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:12:37.850505       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:12:37.850509       1 preempt.go:103] Enter Preempt ...
I0904 12:12:37.850514       1 preempt.go:270] Leaving Preempt ...
I0904 12:12:37.850536       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:37.850560       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:37.850566       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:37.850573       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:37.850578       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:37.850585       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:37.850592       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:37.850600       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:12:37.850650       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:12:37.850655       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:37.850664       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:37.850679       1 session.go:361] Session 7fd15229-de75-4f94-85c8-2ef0b6fb490d operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:12:37.850684       1 session.go:375] Close Session 7fd15229-de75-4f94-85c8-2ef0b6fb490d
I0904 12:12:37.850690       1 scheduler.go:133] End scheduling ...
I0904 12:12:47.319682       1 cache.go:1179] started sync node integration-control-plane
I0904 12:12:47.319718       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:12:47.319818       1 node_info.go:227] imageStates is map[]
I0904 12:12:47.851310       1 scheduler.go:106] Start scheduling ...
I0904 12:12:47.851433       1 node_info.go:227] imageStates is map[]
I0904 12:12:47.851448       1 node_info.go:227] imageStates is map[]
I0904 12:12:47.851460       1 node_info.go:227] imageStates is map[]
I0904 12:12:47.851501       1 node_info.go:227] imageStates is map[]
I0904 12:12:47.851535       1 node_info.go:227] imageStates is map[]
I0904 12:12:47.851556       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:12:47.851566       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:12:47.851575       1 session.go:230] Open Session 4dee9431-b974-4c20-958f-5358fbee3b20 with <0> Job and <5> Queues
I0904 12:12:47.851588       1 session.go:233] Session 4dee9431-b974-4c20-958f-5358fbee3b20 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:12:47.851701       1 sla.go:85] Enter sla plugin ...
I0904 12:12:47.851705       1 sla.go:154] Leaving sla plugin.
I0904 12:12:47.851709       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:12:47.851715       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:12:47.851720       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00
I0904 12:12:47.851770       1 factory.go:59] Register preBinder predicates successfully
I0904 12:12:47.851776       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
I0904 12:12:47.851809       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:12:47.851816       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:47.851825       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:47.851836       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:47.851843       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:47.851852       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:47.851861       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:47.851874       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:47.851885       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:47.851893       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:47.851900       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:47.851922       1 binpack.go:165] Enter binpack plugin ...
I0904 12:12:47.851925       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:12:47.851929       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:12:47.851934       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:12:47.851939       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:12:47.851943       1 allocate.go:62] Enter Allocate ...
I0904 12:12:47.851946       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:12:47.851948       1 allocate.go:83] Leaving Allocate ...
I0904 12:12:47.851952       1 backfill.go:59] Enter Backfill ...
I0904 12:12:47.851954       1 backfill.go:110] Leaving Backfill ...
I0904 12:12:47.851957       1 reclaim.go:47] Enter Reclaim ...
I0904 12:12:47.851959       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:12:47.851964       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:12:47.851980       1 preempt.go:103] Enter Preempt ...
I0904 12:12:47.851984       1 preempt.go:270] Leaving Preempt ...
I0904 12:12:47.851995       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:47.852008       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:12:47.852044       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:12:47.852047       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:47.852052       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:47.852057       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:47.852061       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:47.852065       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:47.852068       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:47.852071       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:47.852074       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:47.852082       1 session.go:361] Session 4dee9431-b974-4c20-958f-5358fbee3b20 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:12:47.852085       1 session.go:375] Close Session 4dee9431-b974-4c20-958f-5358fbee3b20
I0904 12:12:47.852089       1 scheduler.go:133] End scheduling ...
I0904 12:12:57.459002       1 cache.go:1179] started sync node integration-control-plane
I0904 12:12:57.459033       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:12:57.459117       1 node_info.go:227] imageStates is map[]
I0904 12:12:57.497768       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:12:57.852682       1 scheduler.go:106] Start scheduling ...
I0904 12:12:57.852908       1 node_info.go:227] imageStates is map[]
I0904 12:12:57.853045       1 node_info.go:227] imageStates is map[]
I0904 12:12:57.853102       1 node_info.go:227] imageStates is map[]
I0904 12:12:57.853133       1 node_info.go:227] imageStates is map[]
I0904 12:12:57.853156       1 node_info.go:227] imageStates is map[]
I0904 12:12:57.853191       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:12:57.853217       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:12:57.853244       1 session.go:230] Open Session 3039e85a-aba2-488d-96ef-fa9412005aec with <0> Job and <5> Queues
I0904 12:12:57.853352       1 session.go:233] Session 3039e85a-aba2-488d-96ef-fa9412005aec operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:12:57.853649       1 sla.go:85] Enter sla plugin ...
I0904 12:12:57.853688       1 sla.go:154] Leaving sla plugin.
I0904 12:12:57.853699       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:12:57.853715       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:12:57.853727       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:12:57.853818       1 factory.go:59] Register preBinder predicates successfully
I0904 12:12:57.853830       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 12:12:57.853924       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:12:57.853966       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:57.853993       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:57.854021       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:57.854041       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:57.854061       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:12:57.854089       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:57.854119       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:57.854143       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:57.854168       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:57.854190       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:12:57.854257       1 binpack.go:165] Enter binpack plugin ...
I0904 12:12:57.854264       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:12:57.854275       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:12:57.854284       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:12:57.854293       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:12:57.854321       1 allocate.go:62] Enter Allocate ...
I0904 12:12:57.854331       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:12:57.854338       1 allocate.go:83] Leaving Allocate ...
I0904 12:12:57.854380       1 backfill.go:59] Enter Backfill ...
I0904 12:12:57.854390       1 backfill.go:110] Leaving Backfill ...
I0904 12:12:57.854397       1 reclaim.go:47] Enter Reclaim ...
I0904 12:12:57.854404       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:12:57.854420       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:12:57.854426       1 preempt.go:103] Enter Preempt ...
I0904 12:12:57.854434       1 preempt.go:270] Leaving Preempt ...
I0904 12:12:57.854460       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:57.854497       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:57.854507       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:57.854518       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:57.854525       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:57.854534       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:57.854542       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:57.854551       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:12:57.854563       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:12:57.854574       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:12:57.854631       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:12:57.854652       1 session.go:361] Session 3039e85a-aba2-488d-96ef-fa9412005aec operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:12:57.854660       1 session.go:375] Close Session 3039e85a-aba2-488d-96ef-fa9412005aec
I0904 12:12:57.854673       1 scheduler.go:133] End scheduling ...
I0904 12:13:07.854823       1 scheduler.go:106] Start scheduling ...
I0904 12:13:07.855029       1 node_info.go:227] imageStates is map[]
I0904 12:13:07.855074       1 node_info.go:227] imageStates is map[]
I0904 12:13:07.855091       1 node_info.go:227] imageStates is map[]
I0904 12:13:07.855106       1 node_info.go:227] imageStates is map[]
I0904 12:13:07.855163       1 node_info.go:227] imageStates is map[]
I0904 12:13:07.855204       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:13:07.855219       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:13:07.855231       1 session.go:230] Open Session f9857ea4-855a-4ac3-8701-593fc5f83d75 with <0> Job and <5> Queues
I0904 12:13:07.855261       1 session.go:233] Session f9857ea4-855a-4ac3-8701-593fc5f83d75 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:13:07.855470       1 sla.go:85] Enter sla plugin ...
I0904 12:13:07.855488       1 sla.go:154] Leaving sla plugin.
I0904 12:13:07.855494       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:13:07.855502       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:13:07.855508       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00
I0904 12:13:07.855559       1 factory.go:59] Register preBinder predicates successfully
I0904 12:13:07.855566       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>
I0904 12:13:07.855621       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:13:07.855645       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:07.855660       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:07.855675       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:07.855685       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:07.855694       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:07.855707       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:07.855725       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:07.855755       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:07.855768       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:07.855784       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:07.855814       1 binpack.go:165] Enter binpack plugin ...
I0904 12:13:07.855818       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:13:07.855824       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:13:07.855828       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:13:07.855832       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:13:07.855837       1 allocate.go:62] Enter Allocate ...
I0904 12:13:07.855840       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:13:07.855843       1 allocate.go:83] Leaving Allocate ...
I0904 12:13:07.855848       1 backfill.go:59] Enter Backfill ...
I0904 12:13:07.855852       1 backfill.go:110] Leaving Backfill ...
I0904 12:13:07.855856       1 reclaim.go:47] Enter Reclaim ...
I0904 12:13:07.855859       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:13:07.855865       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:13:07.855872       1 preempt.go:103] Enter Preempt ...
I0904 12:13:07.855877       1 preempt.go:270] Leaving Preempt ...
I0904 12:13:07.855893       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:07.855924       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:13:07.855958       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:13:07.855964       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:07.855970       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:07.855975       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:07.855981       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:07.855998       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:07.856004       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:07.856009       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:07.856014       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:07.856025       1 session.go:361] Session f9857ea4-855a-4ac3-8701-593fc5f83d75 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:13:07.856032       1 session.go:375] Close Session f9857ea4-855a-4ac3-8701-593fc5f83d75
I0904 12:13:07.856037       1 scheduler.go:133] End scheduling ...
I0904 12:13:12.368272       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSINode" totalItems=7
I0904 12:13:14.371603       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PriorityClass" totalItems=7
I0904 12:13:17.749003       1 cache.go:1179] started sync node integration-control-plane
I0904 12:13:17.749107       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:13:17.749231       1 node_info.go:227] imageStates is map[]
I0904 12:13:17.856529       1 scheduler.go:106] Start scheduling ...
I0904 12:13:17.856643       1 node_info.go:227] imageStates is map[]
I0904 12:13:17.856677       1 node_info.go:227] imageStates is map[]
I0904 12:13:17.856687       1 node_info.go:227] imageStates is map[]
I0904 12:13:17.856696       1 node_info.go:227] imageStates is map[]
I0904 12:13:17.856704       1 node_info.go:227] imageStates is map[]
I0904 12:13:17.856721       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:13:17.856743       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:13:17.856753       1 session.go:230] Open Session 0901f301-3a89-4aa7-b20b-6b3bf0e7710b with <0> Job and <5> Queues
I0904 12:13:17.856765       1 session.go:233] Session 0901f301-3a89-4aa7-b20b-6b3bf0e7710b operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:13:17.856903       1 sla.go:85] Enter sla plugin ...
I0904 12:13:17.856918       1 sla.go:154] Leaving sla plugin.
I0904 12:13:17.856923       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:13:17.856930       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:13:17.856935       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00
I0904 12:13:17.856978       1 factory.go:59] Register preBinder predicates successfully
I0904 12:13:17.856993       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>
I0904 12:13:17.857028       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:13:17.857043       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:17.857054       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:17.857064       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:17.857070       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:17.857077       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:17.857089       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:17.857111       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:17.857130       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:17.857140       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:17.857148       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:17.857175       1 binpack.go:165] Enter binpack plugin ...
I0904 12:13:17.857178       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:13:17.857183       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:13:17.857189       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:13:17.857192       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:13:17.857196       1 allocate.go:62] Enter Allocate ...
I0904 12:13:17.857198       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:13:17.857201       1 allocate.go:83] Leaving Allocate ...
I0904 12:13:17.857204       1 backfill.go:59] Enter Backfill ...
I0904 12:13:17.857207       1 backfill.go:110] Leaving Backfill ...
I0904 12:13:17.857209       1 reclaim.go:47] Enter Reclaim ...
I0904 12:13:17.857212       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:13:17.857216       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:13:17.857218       1 preempt.go:103] Enter Preempt ...
I0904 12:13:17.857221       1 preempt.go:270] Leaving Preempt ...
I0904 12:13:17.857232       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:17.857248       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:17.857252       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:17.857256       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:17.857262       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:17.857267       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:13:17.857294       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:13:17.857297       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:17.857301       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:17.857306       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:17.857309       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:17.857317       1 session.go:361] Session 0901f301-3a89-4aa7-b20b-6b3bf0e7710b operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:13:17.857320       1 session.go:375] Close Session 0901f301-3a89-4aa7-b20b-6b3bf0e7710b
I0904 12:13:17.857324       1 scheduler.go:133] End scheduling ...
I0904 12:13:27.498959       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:13:27.857677       1 scheduler.go:106] Start scheduling ...
I0904 12:13:27.857816       1 node_info.go:227] imageStates is map[]
I0904 12:13:27.857883       1 node_info.go:227] imageStates is map[]
I0904 12:13:27.857927       1 node_info.go:227] imageStates is map[]
I0904 12:13:27.857967       1 node_info.go:227] imageStates is map[]
I0904 12:13:27.858008       1 node_info.go:227] imageStates is map[]
I0904 12:13:27.858050       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:13:27.858088       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:13:27.858121       1 session.go:230] Open Session 577c58a0-2032-4bc8-9633-df96c7af9003 with <0> Job and <5> Queues
I0904 12:13:27.858158       1 session.go:233] Session 577c58a0-2032-4bc8-9633-df96c7af9003 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:13:27.858348       1 sla.go:85] Enter sla plugin ...
I0904 12:13:27.858377       1 sla.go:154] Leaving sla plugin.
I0904 12:13:27.858385       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:13:27.858398       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:13:27.858406       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00
I0904 12:13:27.858468       1 factory.go:59] Register preBinder predicates successfully
I0904 12:13:27.858478       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>
I0904 12:13:27.858549       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:13:27.858560       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:27.858581       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:27.858600       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:27.858615       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:27.858628       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:27.858645       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:27.858668       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:27.858710       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:27.858749       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:27.858765       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:27.858833       1 binpack.go:165] Enter binpack plugin ...
I0904 12:13:27.858859       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:13:27.858867       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:13:27.858877       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:13:27.858882       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:13:27.858889       1 allocate.go:62] Enter Allocate ...
I0904 12:13:27.858893       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:13:27.858898       1 allocate.go:83] Leaving Allocate ...
I0904 12:13:27.858904       1 backfill.go:59] Enter Backfill ...
I0904 12:13:27.858929       1 backfill.go:110] Leaving Backfill ...
I0904 12:13:27.858936       1 reclaim.go:47] Enter Reclaim ...
I0904 12:13:27.858941       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:13:27.858949       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:13:27.858954       1 preempt.go:103] Enter Preempt ...
I0904 12:13:27.858960       1 preempt.go:270] Leaving Preempt ...
I0904 12:13:27.858979       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:27.859007       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:27.859017       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:27.859026       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:27.859032       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:27.859041       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:13:27.859076       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:13:27.859081       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:27.859090       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:27.859099       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:27.859107       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:27.859128       1 session.go:361] Session 577c58a0-2032-4bc8-9633-df96c7af9003 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:13:27.859137       1 session.go:375] Close Session 577c58a0-2032-4bc8-9633-df96c7af9003
I0904 12:13:27.859144       1 scheduler.go:133] End scheduling ...
I0904 12:13:37.859756       1 scheduler.go:106] Start scheduling ...
I0904 12:13:37.859871       1 node_info.go:227] imageStates is map[]
I0904 12:13:37.859905       1 node_info.go:227] imageStates is map[]
I0904 12:13:37.859950       1 node_info.go:227] imageStates is map[]
I0904 12:13:37.859972       1 node_info.go:227] imageStates is map[]
I0904 12:13:37.860003       1 node_info.go:227] imageStates is map[]
I0904 12:13:37.860023       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:13:37.860037       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:13:37.860050       1 session.go:230] Open Session 3a34dc77-a6d0-4b30-84a2-1a44907819c6 with <0> Job and <5> Queues
I0904 12:13:37.860071       1 session.go:233] Session 3a34dc77-a6d0-4b30-84a2-1a44907819c6 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:13:37.860282       1 sla.go:85] Enter sla plugin ...
I0904 12:13:37.860306       1 sla.go:154] Leaving sla plugin.
I0904 12:13:37.860312       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:13:37.860322       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:13:37.860329       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00
I0904 12:13:37.860385       1 factory.go:59] Register preBinder predicates successfully
I0904 12:13:37.860393       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>
I0904 12:13:37.860444       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:13:37.860452       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:37.860470       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:37.860493       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:37.860521       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:37.860533       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:37.860547       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:37.860568       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:37.860594       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:37.860609       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:37.860621       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:37.860656       1 binpack.go:165] Enter binpack plugin ...
I0904 12:13:37.860661       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:13:37.860668       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:13:37.860674       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:13:37.860678       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:13:37.860683       1 allocate.go:62] Enter Allocate ...
I0904 12:13:37.860687       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:13:37.860690       1 allocate.go:83] Leaving Allocate ...
I0904 12:13:37.860694       1 backfill.go:59] Enter Backfill ...
I0904 12:13:37.860698       1 backfill.go:110] Leaving Backfill ...
I0904 12:13:37.860702       1 reclaim.go:47] Enter Reclaim ...
I0904 12:13:37.860706       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:13:37.860711       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:13:37.860715       1 preempt.go:103] Enter Preempt ...
I0904 12:13:37.860720       1 preempt.go:270] Leaving Preempt ...
I0904 12:13:37.860735       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:37.860757       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:37.860763       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:37.860769       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:37.860773       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:37.860784       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:37.860788       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:37.860795       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:37.860799       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:37.860809       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:13:37.860838       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:13:37.860850       1 session.go:361] Session 3a34dc77-a6d0-4b30-84a2-1a44907819c6 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:13:37.860857       1 session.go:375] Close Session 3a34dc77-a6d0-4b30-84a2-1a44907819c6
I0904 12:13:37.860862       1 scheduler.go:133] End scheduling ...
I0904 12:13:38.435208       1 cache.go:1179] started sync node integration-control-plane
I0904 12:13:38.435686       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:13:38.435863       1 node_info.go:227] imageStates is map[]
I0904 12:13:47.377956       1 reflector.go:946] "Watch close" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145" type="*v1beta1.Queue" totalItems=16
I0904 12:13:47.861560       1 scheduler.go:106] Start scheduling ...
I0904 12:13:47.861721       1 node_info.go:227] imageStates is map[]
I0904 12:13:47.861821       1 node_info.go:227] imageStates is map[]
I0904 12:13:47.861844       1 node_info.go:227] imageStates is map[]
I0904 12:13:47.861865       1 node_info.go:227] imageStates is map[]
I0904 12:13:47.861885       1 node_info.go:227] imageStates is map[]
I0904 12:13:47.861936       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:13:47.861956       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:13:47.861972       1 session.go:230] Open Session 50605c19-8b31-44a1-a299-1d798a6993d4 with <0> Job and <5> Queues
I0904 12:13:47.861997       1 session.go:233] Session 50605c19-8b31-44a1-a299-1d798a6993d4 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:13:47.862247       1 sla.go:85] Enter sla plugin ...
I0904 12:13:47.862281       1 sla.go:154] Leaving sla plugin.
I0904 12:13:47.862285       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:13:47.862292       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:13:47.862297       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:13:47.862353       1 factory.go:59] Register preBinder predicates successfully
I0904 12:13:47.862360       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>
I0904 12:13:47.862398       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:13:47.862415       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:47.862426       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:47.862447       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:47.862455       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:47.862477       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:47.862486       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:47.862504       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:47.862522       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:47.862545       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:47.862554       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:47.862581       1 binpack.go:165] Enter binpack plugin ...
I0904 12:13:47.862595       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:13:47.862599       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:13:47.862604       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:13:47.862607       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:13:47.862612       1 allocate.go:62] Enter Allocate ...
I0904 12:13:47.862614       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:13:47.862617       1 allocate.go:83] Leaving Allocate ...
I0904 12:13:47.862620       1 backfill.go:59] Enter Backfill ...
I0904 12:13:47.862623       1 backfill.go:110] Leaving Backfill ...
I0904 12:13:47.862626       1 reclaim.go:47] Enter Reclaim ...
I0904 12:13:47.862628       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:13:47.862632       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:13:47.862636       1 preempt.go:103] Enter Preempt ...
I0904 12:13:47.862639       1 preempt.go:270] Leaving Preempt ...
I0904 12:13:47.862652       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:47.862672       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:13:47.862700       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:13:47.862702       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:47.862707       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:47.862720       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:47.862724       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:47.862727       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:47.862731       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:47.862734       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:47.862738       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:47.862752       1 session.go:361] Session 50605c19-8b31-44a1-a299-1d798a6993d4 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:13:47.862756       1 session.go:375] Close Session 50605c19-8b31-44a1-a299-1d798a6993d4
I0904 12:13:47.862762       1 scheduler.go:133] End scheduling ...
I0904 12:13:57.499984       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:13:57.863352       1 scheduler.go:106] Start scheduling ...
I0904 12:13:57.863438       1 node_info.go:227] imageStates is map[]
I0904 12:13:57.863454       1 node_info.go:227] imageStates is map[]
I0904 12:13:57.863468       1 node_info.go:227] imageStates is map[]
I0904 12:13:57.863497       1 node_info.go:227] imageStates is map[]
I0904 12:13:57.863514       1 node_info.go:227] imageStates is map[]
I0904 12:13:57.863531       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:13:57.863541       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:13:57.863551       1 session.go:230] Open Session 7e7430a7-1097-4bb9-b143-bbc184b1e886 with <0> Job and <5> Queues
I0904 12:13:57.863562       1 session.go:233] Session 7e7430a7-1097-4bb9-b143-bbc184b1e886 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:13:57.863672       1 sla.go:85] Enter sla plugin ...
I0904 12:13:57.863690       1 sla.go:154] Leaving sla plugin.
I0904 12:13:57.863696       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:13:57.863702       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:13:57.863707       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00
I0904 12:13:57.863769       1 factory.go:59] Register preBinder predicates successfully
I0904 12:13:57.863787       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 12:13:57.863822       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:13:57.863829       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:57.863839       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:57.863848       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:57.863857       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:57.863864       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:13:57.863894       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:57.863911       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:57.863936       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:57.863944       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:57.863952       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:13:57.863982       1 binpack.go:165] Enter binpack plugin ...
I0904 12:13:57.863985       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:13:57.863989       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:13:57.863994       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:13:57.863997       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:13:57.864002       1 allocate.go:62] Enter Allocate ...
I0904 12:13:57.864006       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:13:57.864008       1 allocate.go:83] Leaving Allocate ...
I0904 12:13:57.864011       1 backfill.go:59] Enter Backfill ...
I0904 12:13:57.864014       1 backfill.go:110] Leaving Backfill ...
I0904 12:13:57.864017       1 reclaim.go:47] Enter Reclaim ...
I0904 12:13:57.864019       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:13:57.864024       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:13:57.864026       1 preempt.go:103] Enter Preempt ...
I0904 12:13:57.864029       1 preempt.go:270] Leaving Preempt ...
I0904 12:13:57.864041       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:57.864069       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:57.864073       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:57.864077       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:13:57.864095       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:13:57.864098       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:57.864102       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:57.864107       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:57.864111       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:57.864114       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:13:57.864118       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:13:57.864126       1 session.go:361] Session 7e7430a7-1097-4bb9-b143-bbc184b1e886 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:13:57.864130       1 session.go:375] Close Session 7e7430a7-1097-4bb9-b143-bbc184b1e886
I0904 12:13:57.864134       1 scheduler.go:133] End scheduling ...
I0904 12:13:58.381630       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicaSet" totalItems=9
I0904 12:14:00.374561       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PodDisruptionBudget" totalItems=8
I0904 12:14:07.864826       1 scheduler.go:106] Start scheduling ...
I0904 12:14:07.864984       1 node_info.go:227] imageStates is map[]
I0904 12:14:07.865014       1 node_info.go:227] imageStates is map[]
I0904 12:14:07.865036       1 node_info.go:227] imageStates is map[]
I0904 12:14:07.865047       1 node_info.go:227] imageStates is map[]
I0904 12:14:07.865056       1 node_info.go:227] imageStates is map[]
I0904 12:14:07.865074       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:14:07.865097       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:14:07.865106       1 session.go:230] Open Session 57755827-80bb-4a59-a34c-2d77711647f2 with <0> Job and <5> Queues
I0904 12:14:07.865119       1 session.go:233] Session 57755827-80bb-4a59-a34c-2d77711647f2 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:14:07.865236       1 sla.go:85] Enter sla plugin ...
I0904 12:14:07.865252       1 sla.go:154] Leaving sla plugin.
I0904 12:14:07.865257       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:14:07.865263       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:14:07.865269       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 12:14:07.865315       1 factory.go:59] Register preBinder predicates successfully
I0904 12:14:07.865321       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:14:07.865357       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:14:07.865372       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:07.865384       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:07.865393       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:07.865402       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:07.865408       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:07.865416       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:07.865430       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:07.865438       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:07.865449       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:07.865455       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:07.865483       1 binpack.go:165] Enter binpack plugin ...
I0904 12:14:07.865486       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:14:07.865490       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:14:07.865494       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:14:07.865497       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:14:07.865501       1 allocate.go:62] Enter Allocate ...
I0904 12:14:07.865504       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:14:07.865506       1 allocate.go:83] Leaving Allocate ...
I0904 12:14:07.865509       1 backfill.go:59] Enter Backfill ...
I0904 12:14:07.865512       1 backfill.go:110] Leaving Backfill ...
I0904 12:14:07.865515       1 reclaim.go:47] Enter Reclaim ...
I0904 12:14:07.865517       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:14:07.865521       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:14:07.865524       1 preempt.go:103] Enter Preempt ...
I0904 12:14:07.865526       1 preempt.go:270] Leaving Preempt ...
I0904 12:14:07.865538       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:07.865554       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:07.865558       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:07.865562       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:07.865565       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:07.865568       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:07.865571       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:07.865574       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:07.865578       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:07.865582       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:14:07.865601       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:14:07.865608       1 session.go:361] Session 57755827-80bb-4a59-a34c-2d77711647f2 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:14:07.865611       1 session.go:375] Close Session 57755827-80bb-4a59-a34c-2d77711647f2
I0904 12:14:07.865615       1 scheduler.go:133] End scheduling ...
I0904 12:14:16.370707       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StorageClass" totalItems=11
I0904 12:14:17.866295       1 scheduler.go:106] Start scheduling ...
I0904 12:14:17.866467       1 node_info.go:227] imageStates is map[]
I0904 12:14:17.866515       1 node_info.go:227] imageStates is map[]
I0904 12:14:17.866525       1 node_info.go:227] imageStates is map[]
I0904 12:14:17.866534       1 node_info.go:227] imageStates is map[]
I0904 12:14:17.866546       1 node_info.go:227] imageStates is map[]
I0904 12:14:17.866562       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:14:17.866572       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:14:17.866581       1 session.go:230] Open Session 18415129-7842-4b8a-90a8-5d6c085fc519 with <0> Job and <5> Queues
I0904 12:14:17.866592       1 session.go:233] Session 18415129-7842-4b8a-90a8-5d6c085fc519 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:14:17.866697       1 sla.go:85] Enter sla plugin ...
I0904 12:14:17.866712       1 sla.go:154] Leaving sla plugin.
I0904 12:14:17.866716       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:14:17.866722       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:14:17.866728       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00
I0904 12:14:17.866772       1 factory.go:59] Register preBinder predicates successfully
I0904 12:14:17.866778       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:14:17.866810       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:14:17.866816       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:17.866824       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:17.866836       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:17.866854       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:17.866862       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:17.866872       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:17.866898       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:17.866908       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:17.866917       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:17.866927       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:17.866949       1 binpack.go:165] Enter binpack plugin ...
I0904 12:14:17.866952       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:14:17.866958       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:14:17.866966       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:14:17.866968       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:14:17.866972       1 allocate.go:62] Enter Allocate ...
I0904 12:14:17.866975       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:14:17.866977       1 allocate.go:83] Leaving Allocate ...
I0904 12:14:17.866980       1 backfill.go:59] Enter Backfill ...
I0904 12:14:17.866983       1 backfill.go:110] Leaving Backfill ...
I0904 12:14:17.866986       1 reclaim.go:47] Enter Reclaim ...
I0904 12:14:17.866988       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:14:17.866992       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:14:17.866995       1 preempt.go:103] Enter Preempt ...
I0904 12:14:17.866998       1 preempt.go:270] Leaving Preempt ...
I0904 12:14:17.867010       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:17.867029       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:17.867034       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:17.867038       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:14:17.867056       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:14:17.867058       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:17.867063       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:17.867067       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:17.867071       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:17.867074       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:17.867078       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:17.867086       1 session.go:361] Session 18415129-7842-4b8a-90a8-5d6c085fc519 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:14:17.867089       1 session.go:375] Close Session 18415129-7842-4b8a-90a8-5d6c085fc519
I0904 12:14:17.867092       1 scheduler.go:133] End scheduling ...
I0904 12:14:27.500223       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:14:27.867986       1 scheduler.go:106] Start scheduling ...
I0904 12:14:27.868160       1 node_info.go:227] imageStates is map[]
I0904 12:14:27.868218       1 node_info.go:227] imageStates is map[]
I0904 12:14:27.868233       1 node_info.go:227] imageStates is map[]
I0904 12:14:27.868246       1 node_info.go:227] imageStates is map[]
I0904 12:14:27.868260       1 node_info.go:227] imageStates is map[]
I0904 12:14:27.868280       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:14:27.868294       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:14:27.868305       1 session.go:230] Open Session f193f763-6791-4ddf-9d28-8b0f6392e7a0 with <0> Job and <5> Queues
I0904 12:14:27.868320       1 session.go:233] Session f193f763-6791-4ddf-9d28-8b0f6392e7a0 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:14:27.868455       1 sla.go:85] Enter sla plugin ...
I0904 12:14:27.868479       1 sla.go:154] Leaving sla plugin.
I0904 12:14:27.868485       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:14:27.868494       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:14:27.868501       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 12:14:27.868557       1 factory.go:59] Register preBinder predicates successfully
I0904 12:14:27.868564       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:14:27.868613       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:14:27.868622       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:27.868654       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:27.868666       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:27.868678       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:27.868740       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:27.868762       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:27.868784       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:27.868799       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:27.868814       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:27.868825       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:27.868864       1 binpack.go:165] Enter binpack plugin ...
I0904 12:14:27.868868       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:14:27.868876       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:14:27.868882       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:14:27.868886       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:14:27.868892       1 allocate.go:62] Enter Allocate ...
I0904 12:14:27.868896       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:14:27.868899       1 allocate.go:83] Leaving Allocate ...
I0904 12:14:27.868903       1 backfill.go:59] Enter Backfill ...
I0904 12:14:27.868908       1 backfill.go:110] Leaving Backfill ...
I0904 12:14:27.868911       1 reclaim.go:47] Enter Reclaim ...
I0904 12:14:27.868915       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:14:27.868921       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:14:27.868924       1 preempt.go:103] Enter Preempt ...
I0904 12:14:27.868930       1 preempt.go:270] Leaving Preempt ...
I0904 12:14:27.868945       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:27.868968       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:27.868974       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:27.868982       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:27.868990       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:27.868995       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:27.869000       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:27.869005       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:27.869009       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:27.869018       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:14:27.869053       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:14:27.869065       1 session.go:361] Session f193f763-6791-4ddf-9d28-8b0f6392e7a0 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:14:27.869069       1 session.go:375] Close Session f193f763-6791-4ddf-9d28-8b0f6392e7a0
I0904 12:14:27.869074       1 scheduler.go:133] End scheduling ...
I0904 12:14:37.869895       1 scheduler.go:106] Start scheduling ...
I0904 12:14:37.870004       1 node_info.go:227] imageStates is map[]
I0904 12:14:37.870037       1 node_info.go:227] imageStates is map[]
I0904 12:14:37.870047       1 node_info.go:227] imageStates is map[]
I0904 12:14:37.870060       1 node_info.go:227] imageStates is map[]
I0904 12:14:37.870071       1 node_info.go:227] imageStates is map[]
I0904 12:14:37.870090       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:14:37.870101       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:14:37.870146       1 session.go:230] Open Session 4a8ee894-44a2-4a08-ae66-a9ec656dc94c with <0> Job and <5> Queues
I0904 12:14:37.870159       1 session.go:233] Session 4a8ee894-44a2-4a08-ae66-a9ec656dc94c operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:14:37.870273       1 sla.go:85] Enter sla plugin ...
I0904 12:14:37.870288       1 sla.go:154] Leaving sla plugin.
I0904 12:14:37.870294       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:14:37.870301       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:14:37.870307       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:14:37.870368       1 factory.go:59] Register preBinder predicates successfully
I0904 12:14:37.870384       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>
I0904 12:14:37.870419       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:14:37.870436       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:37.870447       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:37.870455       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:37.870462       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:37.870469       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:37.870479       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:37.870505       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:37.870514       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:37.870575       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:37.870585       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:37.870625       1 binpack.go:165] Enter binpack plugin ...
I0904 12:14:37.870628       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:14:37.870634       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:14:37.870639       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:14:37.870642       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:14:37.870646       1 allocate.go:62] Enter Allocate ...
I0904 12:14:37.870649       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:14:37.870651       1 allocate.go:83] Leaving Allocate ...
I0904 12:14:37.870655       1 backfill.go:59] Enter Backfill ...
I0904 12:14:37.870658       1 backfill.go:110] Leaving Backfill ...
I0904 12:14:37.870661       1 reclaim.go:47] Enter Reclaim ...
I0904 12:14:37.870663       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:14:37.870667       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:14:37.870670       1 preempt.go:103] Enter Preempt ...
I0904 12:14:37.870673       1 preempt.go:270] Leaving Preempt ...
I0904 12:14:37.870684       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:37.870701       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:37.870705       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:37.870709       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:37.870712       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:37.870716       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:14:37.870747       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:14:37.870750       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:37.870755       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:37.870758       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:37.870763       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:37.870771       1 session.go:361] Session 4a8ee894-44a2-4a08-ae66-a9ec656dc94c operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:14:37.870774       1 session.go:375] Close Session 4a8ee894-44a2-4a08-ae66-a9ec656dc94c
I0904 12:14:37.870778       1 scheduler.go:133] End scheduling ...
I0904 12:14:38.377039       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Service" totalItems=9
I0904 12:14:39.560532       1 cache.go:1179] started sync node integration-control-plane
I0904 12:14:39.560745       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:14:39.561133       1 node_info.go:227] imageStates is map[]
I0904 12:14:47.871466       1 scheduler.go:106] Start scheduling ...
I0904 12:14:47.871561       1 node_info.go:227] imageStates is map[]
I0904 12:14:47.871589       1 node_info.go:227] imageStates is map[]
I0904 12:14:47.871601       1 node_info.go:227] imageStates is map[]
I0904 12:14:47.871610       1 node_info.go:227] imageStates is map[]
I0904 12:14:47.871619       1 node_info.go:227] imageStates is map[]
I0904 12:14:47.871636       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:14:47.871647       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:14:47.871655       1 session.go:230] Open Session 7f6d9924-8756-4c4b-b538-eb7846f179ac with <0> Job and <5> Queues
I0904 12:14:47.871677       1 session.go:233] Session 7f6d9924-8756-4c4b-b538-eb7846f179ac operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:14:47.872018       1 sla.go:85] Enter sla plugin ...
I0904 12:14:47.872036       1 sla.go:154] Leaving sla plugin.
I0904 12:14:47.872041       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:14:47.872048       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:14:47.872054       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 12:14:47.872107       1 factory.go:59] Register preBinder predicates successfully
I0904 12:14:47.872113       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:14:47.872148       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:14:47.872163       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:47.872173       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:47.872183       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:47.872190       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:47.872197       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:47.872209       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:47.872224       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:47.872237       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:47.872244       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:47.872252       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:47.872277       1 binpack.go:165] Enter binpack plugin ...
I0904 12:14:47.872280       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:14:47.872285       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:14:47.872292       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:14:47.872295       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:14:47.872301       1 allocate.go:62] Enter Allocate ...
I0904 12:14:47.872304       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:14:47.872306       1 allocate.go:83] Leaving Allocate ...
I0904 12:14:47.872309       1 backfill.go:59] Enter Backfill ...
I0904 12:14:47.872312       1 backfill.go:110] Leaving Backfill ...
I0904 12:14:47.872316       1 reclaim.go:47] Enter Reclaim ...
I0904 12:14:47.872318       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:14:47.872322       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:14:47.872326       1 preempt.go:103] Enter Preempt ...
I0904 12:14:47.872329       1 preempt.go:270] Leaving Preempt ...
I0904 12:14:47.872341       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:47.872364       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:14:47.872390       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:14:47.872394       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:47.872398       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:47.872402       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:47.872635       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:47.872667       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:47.872677       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:47.872684       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:47.872692       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:47.872706       1 session.go:361] Session 7f6d9924-8756-4c4b-b538-eb7846f179ac operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:14:47.872712       1 session.go:375] Close Session 7f6d9924-8756-4c4b-b538-eb7846f179ac
I0904 12:14:47.872718       1 scheduler.go:133] End scheduling ...
I0904 12:14:57.501534       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:14:57.873836       1 scheduler.go:106] Start scheduling ...
I0904 12:14:57.874332       1 node_info.go:227] imageStates is map[]
I0904 12:14:57.874432       1 node_info.go:227] imageStates is map[]
I0904 12:14:57.874470       1 node_info.go:227] imageStates is map[]
I0904 12:14:57.874515       1 node_info.go:227] imageStates is map[]
I0904 12:14:57.874639       1 node_info.go:227] imageStates is map[]
I0904 12:14:57.874725       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:14:57.874759       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:14:57.874788       1 session.go:230] Open Session 137da93d-887b-43c9-be48-e81fa1fdcc0a with <0> Job and <5> Queues
I0904 12:14:57.874825       1 session.go:233] Session 137da93d-887b-43c9-be48-e81fa1fdcc0a operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:14:57.875123       1 sla.go:85] Enter sla plugin ...
I0904 12:14:57.875134       1 sla.go:154] Leaving sla plugin.
I0904 12:14:57.875144       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:14:57.875161       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:14:57.875174       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00
I0904 12:14:57.875272       1 factory.go:59] Register preBinder predicates successfully
I0904 12:14:57.875286       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>
I0904 12:14:57.875380       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:14:57.875440       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:57.875469       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:57.875499       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:57.875533       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:57.875552       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:14:57.875580       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:57.875614       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:57.875662       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:57.875694       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:57.875728       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:14:57.875787       1 binpack.go:165] Enter binpack plugin ...
I0904 12:14:57.875795       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:14:57.875807       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:14:57.875821       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:14:57.875827       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:14:57.875837       1 allocate.go:62] Enter Allocate ...
I0904 12:14:57.875845       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:14:57.875851       1 allocate.go:83] Leaving Allocate ...
I0904 12:14:57.875859       1 backfill.go:59] Enter Backfill ...
I0904 12:14:57.875867       1 backfill.go:110] Leaving Backfill ...
I0904 12:14:57.875874       1 reclaim.go:47] Enter Reclaim ...
I0904 12:14:57.875880       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:14:57.875893       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:14:57.875899       1 preempt.go:103] Enter Preempt ...
I0904 12:14:57.875908       1 preempt.go:270] Leaving Preempt ...
I0904 12:14:57.875934       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:57.875973       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:57.876015       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:57.876034       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:57.876043       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:57.876056       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:14:57.876111       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:14:57.876120       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:57.876132       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:57.876141       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:14:57.876152       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:14:57.876177       1 session.go:361] Session 137da93d-887b-43c9-be48-e81fa1fdcc0a operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:14:57.876185       1 session.go:375] Close Session 137da93d-887b-43c9-be48-e81fa1fdcc0a
I0904 12:14:57.876195       1 scheduler.go:133] End scheduling ...
I0904 12:14:59.877719       1 cache.go:1179] started sync node integration-control-plane
I0904 12:14:59.877763       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:14:59.877867       1 node_info.go:227] imageStates is map[]
I0904 12:15:07.876968       1 scheduler.go:106] Start scheduling ...
I0904 12:15:07.877182       1 node_info.go:227] imageStates is map[]
I0904 12:15:07.877317       1 node_info.go:227] imageStates is map[]
I0904 12:15:07.877344       1 node_info.go:227] imageStates is map[]
I0904 12:15:07.877368       1 node_info.go:227] imageStates is map[]
I0904 12:15:07.877392       1 node_info.go:227] imageStates is map[]
I0904 12:15:07.877424       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:15:07.877447       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:15:07.877467       1 session.go:230] Open Session bbff3d29-b4c3-45f9-9119-7c6e835346c3 with <0> Job and <5> Queues
I0904 12:15:07.877497       1 session.go:233] Session bbff3d29-b4c3-45f9-9119-7c6e835346c3 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:15:07.877730       1 sla.go:85] Enter sla plugin ...
I0904 12:15:07.877769       1 sla.go:154] Leaving sla plugin.
I0904 12:15:07.877778       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:15:07.877793       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:15:07.877804       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00
I0904 12:15:07.877892       1 factory.go:59] Register preBinder predicates successfully
I0904 12:15:07.877905       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
I0904 12:15:07.877987       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:15:07.878006       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:07.878030       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:07.878051       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:07.878098       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:07.878115       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:07.878141       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:07.878166       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:07.878188       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:07.878206       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:07.878231       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:07.878290       1 binpack.go:165] Enter binpack plugin ...
I0904 12:15:07.878297       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:15:07.878306       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:15:07.878315       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:15:07.878320       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:15:07.878329       1 allocate.go:62] Enter Allocate ...
I0904 12:15:07.878335       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:15:07.878340       1 allocate.go:83] Leaving Allocate ...
I0904 12:15:07.878346       1 backfill.go:59] Enter Backfill ...
I0904 12:15:07.878352       1 backfill.go:110] Leaving Backfill ...
I0904 12:15:07.878358       1 reclaim.go:47] Enter Reclaim ...
I0904 12:15:07.878364       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:15:07.878374       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:15:07.878379       1 preempt.go:103] Enter Preempt ...
I0904 12:15:07.878387       1 preempt.go:270] Leaving Preempt ...
I0904 12:15:07.878408       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:07.878441       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:07.878450       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:07.878460       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:07.878469       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:07.878479       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:15:07.878527       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:15:07.878533       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:07.878544       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:07.878554       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:07.878564       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:07.878585       1 session.go:361] Session bbff3d29-b4c3-45f9-9119-7c6e835346c3 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:15:07.878592       1 session.go:375] Close Session bbff3d29-b4c3-45f9-9119-7c6e835346c3
I0904 12:15:07.878601       1 scheduler.go:133] End scheduling ...
I0904 12:15:13.376398       1 reflector.go:946] "Watch close" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145" type="*v1beta1.PodGroup" totalItems=9
I0904 12:15:17.879674       1 scheduler.go:106] Start scheduling ...
I0904 12:15:17.879957       1 node_info.go:227] imageStates is map[]
I0904 12:15:17.880036       1 node_info.go:227] imageStates is map[]
I0904 12:15:17.880093       1 node_info.go:227] imageStates is map[]
I0904 12:15:17.880208       1 node_info.go:227] imageStates is map[]
I0904 12:15:17.880263       1 node_info.go:227] imageStates is map[]
I0904 12:15:17.880325       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:15:17.880417       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:15:17.880437       1 session.go:230] Open Session 0c4a6b10-a546-4252-a635-c8ac27665c06 with <0> Job and <5> Queues
I0904 12:15:17.880466       1 session.go:233] Session 0c4a6b10-a546-4252-a635-c8ac27665c06 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:15:17.880643       1 sla.go:85] Enter sla plugin ...
I0904 12:15:17.880657       1 sla.go:154] Leaving sla plugin.
I0904 12:15:17.880662       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:15:17.880668       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:15:17.880673       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00
I0904 12:15:17.880726       1 factory.go:59] Register preBinder predicates successfully
I0904 12:15:17.880733       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 12:15:17.880766       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:15:17.880785       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:17.880797       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:17.880807       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:17.880815       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:17.880822       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:17.880830       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:17.880889       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:17.880909       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:17.880922       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:17.880931       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:17.880971       1 binpack.go:165] Enter binpack plugin ...
I0904 12:15:17.880984       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:15:17.880988       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:15:17.880993       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:15:17.880996       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:15:17.881001       1 allocate.go:62] Enter Allocate ...
I0904 12:15:17.881003       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:15:17.881006       1 allocate.go:83] Leaving Allocate ...
I0904 12:15:17.881009       1 backfill.go:59] Enter Backfill ...
I0904 12:15:17.881011       1 backfill.go:110] Leaving Backfill ...
I0904 12:15:17.881014       1 reclaim.go:47] Enter Reclaim ...
I0904 12:15:17.881016       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:15:17.881020       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:15:17.881023       1 preempt.go:103] Enter Preempt ...
I0904 12:15:17.881026       1 preempt.go:270] Leaving Preempt ...
I0904 12:15:17.881039       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:17.881056       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:17.881059       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:17.881064       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:17.881067       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:17.881071       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:17.881075       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:17.881079       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:15:17.881118       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:15:17.881121       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:17.881125       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:17.881135       1 session.go:361] Session 0c4a6b10-a546-4252-a635-c8ac27665c06 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:15:17.881137       1 session.go:375] Close Session 0c4a6b10-a546-4252-a635-c8ac27665c06
I0904 12:15:17.881149       1 scheduler.go:133] End scheduling ...
I0904 12:15:18.375902       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Node" totalItems=40
I0904 12:15:20.523905       1 cache.go:1179] started sync node integration-control-plane
I0904 12:15:20.523948       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:15:20.524024       1 node_info.go:227] imageStates is map[]
I0904 12:15:27.502192       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:15:27.881513       1 scheduler.go:106] Start scheduling ...
I0904 12:15:27.881641       1 node_info.go:227] imageStates is map[]
I0904 12:15:27.881694       1 node_info.go:227] imageStates is map[]
I0904 12:15:27.881738       1 node_info.go:227] imageStates is map[]
I0904 12:15:27.881780       1 node_info.go:227] imageStates is map[]
I0904 12:15:27.881853       1 node_info.go:227] imageStates is map[]
I0904 12:15:27.881908       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:15:27.881929       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:15:27.881961       1 session.go:230] Open Session b01436b5-0a11-4a50-b57e-87f77d6e3f0c with <0> Job and <5> Queues
I0904 12:15:27.881983       1 session.go:233] Session b01436b5-0a11-4a50-b57e-87f77d6e3f0c operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:15:27.882235       1 sla.go:85] Enter sla plugin ...
I0904 12:15:27.882265       1 sla.go:154] Leaving sla plugin.
I0904 12:15:27.882273       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:15:27.882284       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:15:27.882293       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:15:27.882473       1 factory.go:59] Register preBinder predicates successfully
I0904 12:15:27.882482       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:15:27.882568       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:15:27.882578       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:27.882595       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:27.882612       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:27.882630       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:27.882642       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:27.882675       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:27.882698       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:27.882718       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:27.882747       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:27.882770       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:27.882807       1 binpack.go:165] Enter binpack plugin ...
I0904 12:15:27.882812       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:15:27.882819       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:15:27.882826       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:15:27.882830       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:15:27.882837       1 allocate.go:62] Enter Allocate ...
I0904 12:15:27.882842       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:15:27.882846       1 allocate.go:83] Leaving Allocate ...
I0904 12:15:27.882857       1 backfill.go:59] Enter Backfill ...
I0904 12:15:27.882864       1 backfill.go:110] Leaving Backfill ...
I0904 12:15:27.882869       1 reclaim.go:47] Enter Reclaim ...
I0904 12:15:27.882873       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:15:27.882881       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:15:27.882885       1 preempt.go:103] Enter Preempt ...
I0904 12:15:27.882890       1 preempt.go:270] Leaving Preempt ...
I0904 12:15:27.882906       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:27.882953       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:27.882962       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:27.882969       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:27.882975       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:27.882982       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:27.882986       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:27.882992       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:27.882997       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:27.883004       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:15:27.883049       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:15:27.883064       1 session.go:361] Session b01436b5-0a11-4a50-b57e-87f77d6e3f0c operated with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:15:27.883072       1 session.go:375] Close Session b01436b5-0a11-4a50-b57e-87f77d6e3f0c
I0904 12:15:27.883079       1 scheduler.go:133] End scheduling ...
I0904 12:15:30.662663       1 cache.go:1179] started sync node integration-control-plane
I0904 12:15:30.662763       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:15:30.662959       1 node_info.go:227] imageStates is map[]
I0904 12:15:37.884409       1 scheduler.go:106] Start scheduling ...
I0904 12:15:37.884680       1 node_info.go:227] imageStates is map[]
I0904 12:15:37.884801       1 node_info.go:227] imageStates is map[]
I0904 12:15:37.884843       1 node_info.go:227] imageStates is map[]
I0904 12:15:37.885090       1 node_info.go:227] imageStates is map[]
I0904 12:15:37.885209       1 node_info.go:227] imageStates is map[]
I0904 12:15:37.885268       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:15:37.885317       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:15:37.885362       1 session.go:230] Open Session 1b0c4a88-6a3c-473c-ba28-46b18c78199e with <0> Job and <5> Queues
I0904 12:15:37.885389       1 session.go:233] Session 1b0c4a88-6a3c-473c-ba28-46b18c78199e operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:15:37.885701       1 sla.go:85] Enter sla plugin ...
I0904 12:15:37.885737       1 sla.go:154] Leaving sla plugin.
I0904 12:15:37.885747       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:15:37.885763       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:15:37.885775       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 12:15:37.885899       1 factory.go:59] Register preBinder predicates successfully
I0904 12:15:37.885912       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>
I0904 12:15:37.885994       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:15:37.886030       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:37.886055       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:37.886073       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:37.886093       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:37.886111       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:37.886133       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:37.886182       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:37.886207       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:37.886228       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:37.886251       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:37.886312       1 binpack.go:165] Enter binpack plugin ...
I0904 12:15:37.886343       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:15:37.886353       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:15:37.886363       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:15:37.886369       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:15:37.886379       1 allocate.go:62] Enter Allocate ...
I0904 12:15:37.886385       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:15:37.886412       1 allocate.go:83] Leaving Allocate ...
I0904 12:15:37.886419       1 backfill.go:59] Enter Backfill ...
I0904 12:15:37.886427       1 backfill.go:110] Leaving Backfill ...
I0904 12:15:37.886433       1 reclaim.go:47] Enter Reclaim ...
I0904 12:15:37.886438       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:15:37.886449       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:15:37.886454       1 preempt.go:103] Enter Preempt ...
I0904 12:15:37.886462       1 preempt.go:270] Leaving Preempt ...
I0904 12:15:37.886487       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:37.886521       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:37.886530       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:37.886540       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:37.886548       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:37.886559       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:15:37.886602       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:15:37.886612       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:37.886623       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:37.886631       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:37.886640       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:37.886661       1 session.go:361] Session 1b0c4a88-6a3c-473c-ba28-46b18c78199e operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:15:37.886689       1 session.go:375] Close Session 1b0c4a88-6a3c-473c-ba28-46b18c78199e
I0904 12:15:37.886698       1 scheduler.go:133] End scheduling ...
I0904 12:15:38.372088       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolumeClaim" totalItems=7
I0904 12:15:47.887332       1 scheduler.go:106] Start scheduling ...
I0904 12:15:47.887466       1 node_info.go:227] imageStates is map[]
I0904 12:15:47.887539       1 node_info.go:227] imageStates is map[]
I0904 12:15:47.887569       1 node_info.go:227] imageStates is map[]
I0904 12:15:47.887589       1 node_info.go:227] imageStates is map[]
I0904 12:15:47.887606       1 node_info.go:227] imageStates is map[]
I0904 12:15:47.887631       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:15:47.887649       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:15:47.887664       1 session.go:230] Open Session 128ac5e7-9e36-4262-b886-e1aae97b67d5 with <0> Job and <5> Queues
I0904 12:15:47.887687       1 session.go:233] Session 128ac5e7-9e36-4262-b886-e1aae97b67d5 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:15:47.887943       1 sla.go:85] Enter sla plugin ...
I0904 12:15:47.887952       1 sla.go:154] Leaving sla plugin.
I0904 12:15:47.887961       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:15:47.887973       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:15:47.887982       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:15:47.888053       1 factory.go:59] Register preBinder predicates successfully
I0904 12:15:47.888062       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>
I0904 12:15:47.888117       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:15:47.888127       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:47.888140       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:47.888154       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:47.889436       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:47.889543       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:47.889581       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:47.889616       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:47.889658       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:47.889686       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:47.889872       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:47.890026       1 binpack.go:165] Enter binpack plugin ...
I0904 12:15:47.890035       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:15:47.890048       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:15:47.890058       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:15:47.890064       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:15:47.890074       1 allocate.go:62] Enter Allocate ...
I0904 12:15:47.890080       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:15:47.890095       1 allocate.go:83] Leaving Allocate ...
I0904 12:15:47.890101       1 backfill.go:59] Enter Backfill ...
I0904 12:15:47.890159       1 backfill.go:110] Leaving Backfill ...
I0904 12:15:47.890170       1 reclaim.go:47] Enter Reclaim ...
I0904 12:15:47.890175       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:15:47.890185       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:15:47.890191       1 preempt.go:103] Enter Preempt ...
I0904 12:15:47.890199       1 preempt.go:270] Leaving Preempt ...
I0904 12:15:47.890251       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:47.890315       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:47.890338       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:47.890366       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:47.890383       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:47.890454       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:47.890475       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:47.890653       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:15:47.890851       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:15:47.890898       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:47.890936       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:47.891019       1 session.go:361] Session 128ac5e7-9e36-4262-b886-e1aae97b67d5 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:15:47.891045       1 session.go:375] Close Session 128ac5e7-9e36-4262-b886-e1aae97b67d5
I0904 12:15:47.891073       1 scheduler.go:133] End scheduling ...
I0904 12:15:57.376227       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ResourceQuota" totalItems=8
I0904 12:15:57.502766       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:15:57.891850       1 scheduler.go:106] Start scheduling ...
I0904 12:15:57.892000       1 node_info.go:227] imageStates is map[]
I0904 12:15:57.892031       1 node_info.go:227] imageStates is map[]
I0904 12:15:57.892087       1 node_info.go:227] imageStates is map[]
I0904 12:15:57.892115       1 node_info.go:227] imageStates is map[]
I0904 12:15:57.892133       1 node_info.go:227] imageStates is map[]
I0904 12:15:57.892158       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:15:57.892179       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:15:57.892195       1 session.go:230] Open Session 9c163a83-4810-4a41-a8fe-9a6fc68318dc with <0> Job and <5> Queues
I0904 12:15:57.892217       1 session.go:233] Session 9c163a83-4810-4a41-a8fe-9a6fc68318dc operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:15:57.892416       1 sla.go:85] Enter sla plugin ...
I0904 12:15:57.892452       1 sla.go:154] Leaving sla plugin.
I0904 12:15:57.892460       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:15:57.892472       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:15:57.892481       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:15:57.892552       1 factory.go:59] Register preBinder predicates successfully
I0904 12:15:57.892562       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 12:15:57.892633       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:15:57.892646       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:57.892663       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:57.892680       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:57.892696       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:57.892713       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:15:57.892732       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:57.892763       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:57.892780       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:57.892795       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:57.892818       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:15:57.892874       1 binpack.go:165] Enter binpack plugin ...
I0904 12:15:57.892881       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:15:57.892890       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:15:57.892898       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:15:57.892902       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:15:57.892909       1 allocate.go:62] Enter Allocate ...
I0904 12:15:57.892915       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:15:57.892920       1 allocate.go:83] Leaving Allocate ...
I0904 12:15:57.892925       1 backfill.go:59] Enter Backfill ...
I0904 12:15:57.892932       1 backfill.go:110] Leaving Backfill ...
I0904 12:15:57.892937       1 reclaim.go:47] Enter Reclaim ...
I0904 12:15:57.892942       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:15:57.892951       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:15:57.892955       1 preempt.go:103] Enter Preempt ...
I0904 12:15:57.892963       1 preempt.go:270] Leaving Preempt ...
I0904 12:15:57.893000       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:57.893031       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:57.893038       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:57.893047       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:15:57.893089       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:15:57.893100       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:57.893116       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:57.893124       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:57.893132       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:57.893144       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:15:57.893153       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:15:57.893171       1 session.go:361] Session 9c163a83-4810-4a41-a8fe-9a6fc68318dc operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:15:57.893201       1 session.go:375] Close Session 9c163a83-4810-4a41-a8fe-9a6fc68318dc
I0904 12:15:57.893209       1 scheduler.go:133] End scheduling ...
I0904 12:16:07.893838       1 scheduler.go:106] Start scheduling ...
I0904 12:16:07.893917       1 node_info.go:227] imageStates is map[]
I0904 12:16:07.893932       1 node_info.go:227] imageStates is map[]
I0904 12:16:07.893952       1 node_info.go:227] imageStates is map[]
I0904 12:16:07.893982       1 node_info.go:227] imageStates is map[]
I0904 12:16:07.894007       1 node_info.go:227] imageStates is map[]
I0904 12:16:07.894024       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:16:07.894034       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:16:07.894052       1 session.go:230] Open Session e9582514-e481-44d6-b7a9-be9acbfac700 with <0> Job and <5> Queues
I0904 12:16:07.894064       1 session.go:233] Session e9582514-e481-44d6-b7a9-be9acbfac700 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:16:07.894169       1 sla.go:85] Enter sla plugin ...
I0904 12:16:07.894184       1 sla.go:154] Leaving sla plugin.
I0904 12:16:07.894189       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:16:07.894196       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:16:07.894201       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 12:16:07.894247       1 factory.go:59] Register preBinder predicates successfully
I0904 12:16:07.894262       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:16:07.894298       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:16:07.894305       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:07.894316       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:07.894324       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:07.894331       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:07.894339       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:07.894349       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:07.894371       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:07.894380       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:07.894388       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:07.894399       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:07.894424       1 binpack.go:165] Enter binpack plugin ...
I0904 12:16:07.894439       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:16:07.894443       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:16:07.894448       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:16:07.894450       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:16:07.894454       1 allocate.go:62] Enter Allocate ...
I0904 12:16:07.894457       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:16:07.894459       1 allocate.go:83] Leaving Allocate ...
I0904 12:16:07.894462       1 backfill.go:59] Enter Backfill ...
I0904 12:16:07.894465       1 backfill.go:110] Leaving Backfill ...
I0904 12:16:07.894468       1 reclaim.go:47] Enter Reclaim ...
I0904 12:16:07.894470       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:16:07.894474       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:16:07.894476       1 preempt.go:103] Enter Preempt ...
I0904 12:16:07.894479       1 preempt.go:270] Leaving Preempt ...
I0904 12:16:07.894489       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:07.894506       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:07.894510       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:07.894514       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:07.894519       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:07.894523       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:16:07.894552       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:16:07.894554       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:07.894559       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:07.894563       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:07.894567       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:07.894575       1 session.go:361] Session e9582514-e481-44d6-b7a9-be9acbfac700 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:16:07.894578       1 session.go:375] Close Session e9582514-e481-44d6-b7a9-be9acbfac700
I0904 12:16:07.894582       1 scheduler.go:133] End scheduling ...
I0904 12:16:17.895482       1 scheduler.go:106] Start scheduling ...
I0904 12:16:17.895622       1 node_info.go:227] imageStates is map[]
I0904 12:16:17.895700       1 node_info.go:227] imageStates is map[]
I0904 12:16:17.895720       1 node_info.go:227] imageStates is map[]
I0904 12:16:17.895739       1 node_info.go:227] imageStates is map[]
I0904 12:16:17.895756       1 node_info.go:227] imageStates is map[]
I0904 12:16:17.895783       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:16:17.895804       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:16:17.895820       1 session.go:230] Open Session b0b3a924-8ba1-4201-b670-0d18e8e9e741 with <0> Job and <5> Queues
I0904 12:16:17.895866       1 session.go:233] Session b0b3a924-8ba1-4201-b670-0d18e8e9e741 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:16:17.896272       1 sla.go:85] Enter sla plugin ...
I0904 12:16:17.896310       1 sla.go:154] Leaving sla plugin.
I0904 12:16:17.896318       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:16:17.896331       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:16:17.896339       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00
I0904 12:16:17.896420       1 factory.go:59] Register preBinder predicates successfully
I0904 12:16:17.896430       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>
I0904 12:16:17.896494       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:16:17.896527       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:17.896547       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:17.896569       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:17.896584       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:17.896596       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:17.896613       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:17.896637       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:17.896654       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:17.896699       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:17.896718       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:17.896759       1 binpack.go:165] Enter binpack plugin ...
I0904 12:16:17.896781       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:16:17.896790       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:16:17.896797       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:16:17.896802       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:16:17.896824       1 allocate.go:62] Enter Allocate ...
I0904 12:16:17.896829       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:16:17.896834       1 allocate.go:83] Leaving Allocate ...
I0904 12:16:17.896842       1 backfill.go:59] Enter Backfill ...
I0904 12:16:17.896848       1 backfill.go:110] Leaving Backfill ...
I0904 12:16:17.896852       1 reclaim.go:47] Enter Reclaim ...
I0904 12:16:17.896856       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:16:17.896865       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:16:17.896886       1 preempt.go:103] Enter Preempt ...
I0904 12:16:17.896892       1 preempt.go:270] Leaving Preempt ...
I0904 12:16:17.896912       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:17.896957       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:17.896965       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:17.896973       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:17.896980       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:17.896987       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:17.896992       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:17.897001       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:16:17.897067       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:16:17.897072       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:17.897081       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:17.897098       1 session.go:361] Session b0b3a924-8ba1-4201-b670-0d18e8e9e741 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:16:17.897106       1 session.go:375] Close Session b0b3a924-8ba1-4201-b670-0d18e8e9e741
I0904 12:16:17.897113       1 scheduler.go:133] End scheduling ...
I0904 12:16:27.503681       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:16:27.897794       1 scheduler.go:106] Start scheduling ...
I0904 12:16:27.897954       1 node_info.go:227] imageStates is map[]
I0904 12:16:27.898009       1 node_info.go:227] imageStates is map[]
I0904 12:16:27.898030       1 node_info.go:227] imageStates is map[]
I0904 12:16:27.898052       1 node_info.go:227] imageStates is map[]
I0904 12:16:27.898103       1 node_info.go:227] imageStates is map[]
I0904 12:16:27.898132       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:16:27.898155       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:16:27.898171       1 session.go:230] Open Session 6f96a610-2c91-4cc7-a65c-8486eea78c2f with <0> Job and <5> Queues
I0904 12:16:27.898195       1 session.go:233] Session 6f96a610-2c91-4cc7-a65c-8486eea78c2f operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:16:27.898425       1 sla.go:85] Enter sla plugin ...
I0904 12:16:27.898459       1 sla.go:154] Leaving sla plugin.
I0904 12:16:27.898468       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:16:27.898482       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:16:27.898493       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00
I0904 12:16:27.898572       1 factory.go:59] Register preBinder predicates successfully
I0904 12:16:27.898584       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 12:16:27.898666       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:16:27.898703       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:27.898726       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:27.898750       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:27.898773       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:27.898790       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:27.898812       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:27.898860       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:27.898906       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:27.898930       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:27.898950       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:27.899052       1 binpack.go:165] Enter binpack plugin ...
I0904 12:16:27.899061       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:16:27.899070       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:16:27.899078       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:16:27.899090       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:16:27.899098       1 allocate.go:62] Enter Allocate ...
I0904 12:16:27.899105       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:16:27.899115       1 allocate.go:83] Leaving Allocate ...
I0904 12:16:27.899121       1 backfill.go:59] Enter Backfill ...
I0904 12:16:27.899128       1 backfill.go:110] Leaving Backfill ...
I0904 12:16:27.899134       1 reclaim.go:47] Enter Reclaim ...
I0904 12:16:27.899140       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:16:27.899149       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:16:27.899159       1 preempt.go:103] Enter Preempt ...
I0904 12:16:27.899166       1 preempt.go:270] Leaving Preempt ...
I0904 12:16:27.899208       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:27.899252       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:16:27.899462       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:16:27.899470       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:27.899482       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:27.899495       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:27.899504       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:27.899514       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:27.899526       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:27.899533       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:27.899541       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:27.899561       1 session.go:361] Session 6f96a610-2c91-4cc7-a65c-8486eea78c2f operated with TotalResource: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:16:27.899590       1 session.go:375] Close Session 6f96a610-2c91-4cc7-a65c-8486eea78c2f
I0904 12:16:27.899599       1 scheduler.go:133] End scheduling ...
I0904 12:16:37.900224       1 scheduler.go:106] Start scheduling ...
I0904 12:16:37.900431       1 node_info.go:227] imageStates is map[]
I0904 12:16:37.900481       1 node_info.go:227] imageStates is map[]
I0904 12:16:37.900499       1 node_info.go:227] imageStates is map[]
I0904 12:16:37.900521       1 node_info.go:227] imageStates is map[]
I0904 12:16:37.900564       1 node_info.go:227] imageStates is map[]
I0904 12:16:37.900591       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:16:37.900616       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:16:37.900632       1 session.go:230] Open Session 281e063b-52cf-4d21-8f66-4d4f6bb528c6 with <0> Job and <5> Queues
I0904 12:16:37.900646       1 session.go:233] Session 281e063b-52cf-4d21-8f66-4d4f6bb528c6 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:16:37.900801       1 sla.go:85] Enter sla plugin ...
I0904 12:16:37.900823       1 sla.go:154] Leaving sla plugin.
I0904 12:16:37.900829       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:16:37.900837       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:16:37.900843       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:16:37.900919       1 factory.go:59] Register preBinder predicates successfully
I0904 12:16:37.900940       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>
I0904 12:16:37.900989       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:16:37.900997       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:37.901008       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:37.901019       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:37.901032       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:37.901132       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:37.901152       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:37.901172       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:37.901193       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:37.901203       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, pods 550.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:37.901213       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, pods 550.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:37.901273       1 binpack.go:165] Enter binpack plugin ...
I0904 12:16:37.901291       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:16:37.901297       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:16:37.901302       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:16:37.901306       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:16:37.901312       1 allocate.go:62] Enter Allocate ...
I0904 12:16:37.901315       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:16:37.901319       1 allocate.go:83] Leaving Allocate ...
I0904 12:16:37.901323       1 backfill.go:59] Enter Backfill ...
I0904 12:16:37.901327       1 backfill.go:110] Leaving Backfill ...
I0904 12:16:37.901331       1 reclaim.go:47] Enter Reclaim ...
I0904 12:16:37.901334       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:16:37.901341       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:16:37.901346       1 preempt.go:103] Enter Preempt ...
I0904 12:16:37.901355       1 preempt.go:270] Leaving Preempt ...
I0904 12:16:37.901384       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:37.901406       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:37.901425       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:37.901433       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:16:37.901460       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:16:37.901463       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:37.901469       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:37.901473       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:37.901477       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:37.901482       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:37.901487       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:37.901497       1 session.go:361] Session 281e063b-52cf-4d21-8f66-4d4f6bb528c6 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 550.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:16:37.901501       1 session.go:375] Close Session 281e063b-52cf-4d21-8f66-4d4f6bb528c6
I0904 12:16:37.901510       1 scheduler.go:133] End scheduling ...
I0904 12:16:41.563209       1 cache.go:1179] started sync node integration-control-plane
I0904 12:16:41.563236       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:16:41.563293       1 node_info.go:227] imageStates is map[]
I0904 12:16:47.380501       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StatefulSet" totalItems=8
I0904 12:16:47.902306       1 scheduler.go:106] Start scheduling ...
I0904 12:16:47.902953       1 node_info.go:227] imageStates is map[]
I0904 12:16:47.903172       1 node_info.go:227] imageStates is map[]
I0904 12:16:47.903230       1 node_info.go:227] imageStates is map[]
I0904 12:16:47.903273       1 node_info.go:227] imageStates is map[]
I0904 12:16:47.903311       1 node_info.go:227] imageStates is map[]
I0904 12:16:47.903364       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:16:47.903483       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:16:47.903524       1 session.go:230] Open Session 36f963a4-d372-42e9-af69-07f9d0b70f4b with <0> Job and <5> Queues
I0904 12:16:47.903577       1 session.go:233] Session 36f963a4-d372-42e9-af69-07f9d0b70f4b operates with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:16:47.904102       1 sla.go:85] Enter sla plugin ...
I0904 12:16:47.904216       1 sla.go:154] Leaving sla plugin.
I0904 12:16:47.904239       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:16:47.904268       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:16:47.904285       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00
I0904 12:16:47.904428       1 factory.go:59] Register preBinder predicates successfully
I0904 12:16:47.904530       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>
I0904 12:16:47.904674       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:16:47.904787       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:47.904841       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:47.904879       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:47.904918       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:47.904946       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:47.904984       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:47.905028       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:47.905144       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:47.905193       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 550.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:47.905224       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:47.905320       1 binpack.go:165] Enter binpack plugin ...
I0904 12:16:47.905333       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:16:47.905348       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:16:47.905361       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:16:47.905370       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:16:47.905384       1 allocate.go:62] Enter Allocate ...
I0904 12:16:47.905404       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:16:47.905413       1 allocate.go:83] Leaving Allocate ...
I0904 12:16:47.905424       1 backfill.go:59] Enter Backfill ...
I0904 12:16:47.905435       1 backfill.go:110] Leaving Backfill ...
I0904 12:16:47.905444       1 reclaim.go:47] Enter Reclaim ...
I0904 12:16:47.905452       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:16:47.905468       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:16:47.905477       1 preempt.go:103] Enter Preempt ...
I0904 12:16:47.905489       1 preempt.go:270] Leaving Preempt ...
I0904 12:16:47.905525       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:47.905631       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:16:47.905736       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:16:47.905818       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:47.905855       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:47.905876       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:47.905895       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:47.905909       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:47.905926       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:47.905938       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:47.905954       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:47.905991       1 session.go:361] Session 36f963a4-d372-42e9-af69-07f9d0b70f4b operated with TotalResource: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:16:47.906005       1 session.go:375] Close Session 36f963a4-d372-42e9-af69-07f9d0b70f4b
I0904 12:16:47.906018       1 scheduler.go:133] End scheduling ...
I0904 12:16:51.974294       1 cache.go:1179] started sync node integration-control-plane
I0904 12:16:51.974537       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:16:51.974728       1 node_info.go:227] imageStates is map[]
I0904 12:16:57.503965       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:16:57.906721       1 scheduler.go:106] Start scheduling ...
I0904 12:16:57.906844       1 node_info.go:227] imageStates is map[]
I0904 12:16:57.906895       1 node_info.go:227] imageStates is map[]
I0904 12:16:57.906916       1 node_info.go:227] imageStates is map[]
I0904 12:16:57.906934       1 node_info.go:227] imageStates is map[]
I0904 12:16:57.906989       1 node_info.go:227] imageStates is map[]
I0904 12:16:57.907025       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=5
I0904 12:16:57.907068       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:16:57.907085       1 session.go:230] Open Session d4b57812-2615-4f6c-9415-122abe5d0324 with <0> Job and <5> Queues
I0904 12:16:57.907110       1 session.go:233] Session d4b57812-2615-4f6c-9415-122abe5d0324 operates with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:16:57.907373       1 sla.go:85] Enter sla plugin ...
I0904 12:16:57.907414       1 sla.go:154] Leaving sla plugin.
I0904 12:16:57.907425       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:16:57.907439       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:16:57.907451       1 drf.go:190] Total Allocatable cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00
I0904 12:16:57.907555       1 factory.go:59] Register preBinder predicates successfully
I0904 12:16:57.907571       1 capacity.go:108] The total resource is <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>
I0904 12:16:57.907677       1 capacity.go:615] Successfully checked queue's hierarchical structure.
I0904 12:16:57.907745       1 capacity.go:624] The attributes of hierarchical queue <q1> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:57.907770       1 capacity.go:624] The attributes of hierarchical queue <parent-a> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, realCapability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:57.907798       1 capacity.go:624] The attributes of hierarchical queue <root> in capacity: deserved <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00>, capability <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:57.907821       1 capacity.go:624] The attributes of hierarchical queue <q2> in capacity: deserved <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:57.907838       1 capacity.go:624] The attributes of hierarchical queue <default> in capacity: deserved <cpu 0.00, memory 0.00>, capability <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability <cpu 44000.00, memory 50970411008.00, pods 550.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, allocate <cpu 0.00, memory 0.00>, request <cpu 0.00, memory 0.00>, elastic <cpu 0.00, memory 0.00>, share <0.00>
I0904 12:16:57.907860       1 capacity.go:631] Record metrics for hierarchical queue <default>, deserved: <cpu 0.00, memory 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:57.907892       1 capacity.go:631] Record metrics for hierarchical queue <parent-a>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 8000.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:57.907913       1 capacity.go:631] Record metrics for hierarchical queue <q1>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:57.907935       1 capacity.go:631] Record metrics for hierarchical queue <q2>, deserved: <cpu 0.00, memory 0.00, nvidia.com/A100 2000.00>, capability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, realCapability: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:57.907954       1 capacity.go:631] Record metrics for hierarchical queue <root>, deserved: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, capability: <cpu 44000.00, memory 50970411008.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00>, realCapability: <cpu 44000.00, memory 50970411008.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00>, allocated: <cpu 0.00, memory 0.00>
I0904 12:16:57.908025       1 binpack.go:165] Enter binpack plugin ...
I0904 12:16:57.908061       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:16:57.908072       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:16:57.908082       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:16:57.908088       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:16:57.908099       1 allocate.go:62] Enter Allocate ...
I0904 12:16:57.908106       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:16:57.908112       1 allocate.go:83] Leaving Allocate ...
I0904 12:16:57.908119       1 backfill.go:59] Enter Backfill ...
I0904 12:16:57.908126       1 backfill.go:110] Leaving Backfill ...
I0904 12:16:57.908132       1 reclaim.go:47] Enter Reclaim ...
I0904 12:16:57.908138       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:16:57.908148       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:16:57.908154       1 preempt.go:103] Enter Preempt ...
I0904 12:16:57.908163       1 preempt.go:270] Leaving Preempt ...
I0904 12:16:57.908219       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:57.908263       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:57.908299       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:57.908311       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:57.908319       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:57.908331       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:57.908338       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:57.908348       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:16:57.908356       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:16:57.908368       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{44000 -3} {<nil>}  DecimalSI} ephemeral-storage:{{1081101176832000 -3} {<nil>}  DecimalSI} hugepages-1Gi:{{0 -3} {<nil>}  DecimalSI} hugepages-2Mi:{{0 -3} {<nil>}  DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8000 -3} {<nil>}  DecimalSI} pods:{{550 0} {<nil>}  DecimalSI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:16:57.908416       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:16:57.908438       1 session.go:361] Session d4b57812-2615-4f6c-9415-122abe5d0324 operated with TotalResource: <cpu 44000.00, memory 50970411008.00, nvidia.com/A100 8000.00, pods 550.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 44000.00, memory 50970411008.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 550.00, ephemeral-storage 1081101176832000.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:16:57.908445       1 session.go:375] Close Session d4b57812-2615-4f6c-9415-122abe5d0324
I0904 12:16:57.908455       1 scheduler.go:133] End scheduling ...
I0904 12:17:02.909298       1 cache.go:1199] started sync hyperNode node/kwok-node-a100-mate-0
I0904 12:17:02.909331       1 cache.go:1179] started sync node kwok-node-a100-mate-0
I0904 12:17:02.909349       1 event_handlers.go:734] "No need to update hyperNode cache when node added or deleted"
I0904 12:17:02.909367       1 event_handlers.go:613] Node <kwok-node-a100-mate-0> was deleted, removed from cache.
I0904 12:17:07.909352       1 scheduler.go:106] Start scheduling ...
I0904 12:17:07.909480       1 node_info.go:227] imageStates is map[]
I0904 12:17:07.909511       1 node_info.go:227] imageStates is map[]
I0904 12:17:07.909562       1 node_info.go:227] imageStates is map[]
I0904 12:17:07.909622       1 node_info.go:227] imageStates is map[]
I0904 12:17:07.909657       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:17:07.909699       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:17:07.909765       1 session.go:230] Open Session ad713e1a-7b37-450d-9752-67b2f1669b55 with <0> Job and <5> Queues
I0904 12:17:07.909791       1 session.go:233] Session ad713e1a-7b37-450d-9752-67b2f1669b55 operates with TotalResource: <cpu 36000.00, memory 42380476416.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:17:07.909969       1 sla.go:85] Enter sla plugin ...
I0904 12:17:07.910001       1 sla.go:154] Leaving sla plugin.
I0904 12:17:07.910009       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:17:07.910021       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:17:07.910030       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00
I0904 12:17:07.910095       1 factory.go:59] Register preBinder predicates successfully
I0904 12:17:07.910103       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
E0904 12:17:07.910178       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>
I0904 12:17:07.910222       1 binpack.go:165] Enter binpack plugin ...
I0904 12:17:07.910243       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:17:07.910250       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:17:07.910256       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:17:07.910259       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:17:07.910282       1 allocate.go:62] Enter Allocate ...
I0904 12:17:07.910288       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:17:07.910292       1 allocate.go:83] Leaving Allocate ...
I0904 12:17:07.910298       1 backfill.go:59] Enter Backfill ...
I0904 12:17:07.910304       1 backfill.go:110] Leaving Backfill ...
I0904 12:17:07.910308       1 reclaim.go:47] Enter Reclaim ...
I0904 12:17:07.910312       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:17:07.910319       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:17:07.910322       1 preempt.go:103] Enter Preempt ...
I0904 12:17:07.910328       1 preempt.go:270] Leaving Preempt ...
I0904 12:17:07.910345       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:07.910371       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:07.910382       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:07.910389       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:07.910395       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:07.910403       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:07.910410       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:07.910415       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:07.910420       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:07.910427       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{44 0} {<nil>} 44 DecimalSI} ephemeral-storage:{{1081101176832 0} {<nil>} 1081101176832 DecimalSI} hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI} memory:{{50970411008 0} {<nil>}  BinarySI} nvidia.com/A100:{{8 0} {<nil>} 8 DecimalSI} pods:{{550 0} {<nil>} 550 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:17:07.940987       1 session.go:361] Session ad713e1a-7b37-450d-9752-67b2f1669b55 operated with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:17:07.941087       1 session.go:375] Close Session ad713e1a-7b37-450d-9752-67b2f1669b55
I0904 12:17:07.941106       1 scheduler.go:133] End scheduling ...
I0904 12:17:11.377316       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolume" totalItems=8
I0904 12:17:17.941888       1 scheduler.go:106] Start scheduling ...
I0904 12:17:17.942141       1 node_info.go:227] imageStates is map[]
I0904 12:17:17.942242       1 node_info.go:227] imageStates is map[]
I0904 12:17:17.942265       1 node_info.go:227] imageStates is map[]
I0904 12:17:17.942286       1 node_info.go:227] imageStates is map[]
I0904 12:17:17.942344       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:17:17.942365       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:17:17.942379       1 session.go:230] Open Session 30452453-e089-4de2-b3e0-11bf520cc91b with <0> Job and <5> Queues
I0904 12:17:17.942401       1 session.go:233] Session 30452453-e089-4de2-b3e0-11bf520cc91b operates with TotalResource: <cpu 36000.00, memory 42380476416.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:17:17.942574       1 sla.go:85] Enter sla plugin ...
I0904 12:17:17.942618       1 sla.go:154] Leaving sla plugin.
I0904 12:17:17.942629       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:17:17.942641       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:17:17.942649       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00
I0904 12:17:17.942718       1 factory.go:59] Register preBinder predicates successfully
I0904 12:17:17.942764       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00>
E0904 12:17:17.942821       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 440.00>
I0904 12:17:17.942853       1 binpack.go:165] Enter binpack plugin ...
I0904 12:17:17.942861       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:17:17.942867       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:17:17.942874       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:17:17.942879       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:17:17.942885       1 allocate.go:62] Enter Allocate ...
I0904 12:17:17.942889       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:17:17.942893       1 allocate.go:83] Leaving Allocate ...
I0904 12:17:17.942900       1 backfill.go:59] Enter Backfill ...
I0904 12:17:17.942905       1 backfill.go:110] Leaving Backfill ...
I0904 12:17:17.942910       1 reclaim.go:47] Enter Reclaim ...
I0904 12:17:17.942915       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:17:17.942923       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:17:17.942932       1 preempt.go:103] Enter Preempt ...
I0904 12:17:17.942939       1 preempt.go:270] Leaving Preempt ...
I0904 12:17:17.942960       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:17.942987       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:17.942994       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:17.943003       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:17.943009       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:17.943017       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:17.943024       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:17.943032       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:17.943038       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:17.943047       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:17:17.943071       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:17:17.943082       1 session.go:361] Session 30452453-e089-4de2-b3e0-11bf520cc91b operated with TotalResource: <cpu 36000.00, memory 42380476416.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:17:17.943087       1 session.go:375] Close Session 30452453-e089-4de2-b3e0-11bf520cc91b
I0904 12:17:17.943093       1 scheduler.go:133] End scheduling ...
I0904 12:17:27.504152       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:17:27.943367       1 scheduler.go:106] Start scheduling ...
I0904 12:17:27.943486       1 node_info.go:227] imageStates is map[]
I0904 12:17:27.943521       1 node_info.go:227] imageStates is map[]
I0904 12:17:27.943534       1 node_info.go:227] imageStates is map[]
I0904 12:17:27.943548       1 node_info.go:227] imageStates is map[]
I0904 12:17:27.943570       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:17:27.943585       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:17:27.943596       1 session.go:230] Open Session 92e25f36-0de7-41fe-a074-f65e9c9d7a11 with <0> Job and <5> Queues
I0904 12:17:27.943612       1 session.go:233] Session 92e25f36-0de7-41fe-a074-f65e9c9d7a11 operates with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 6000.00, pods 440.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:17:27.943792       1 sla.go:85] Enter sla plugin ...
I0904 12:17:27.943886       1 sla.go:154] Leaving sla plugin.
I0904 12:17:27.943905       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:17:27.943914       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:17:27.943920       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 6000.00, pods 440.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:17:27.944013       1 factory.go:59] Register preBinder predicates successfully
I0904 12:17:27.944034       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 6000.00, pods 440.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
E0904 12:17:27.944089       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 6000.00, pods 440.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, pods 440.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:17:27.944141       1 binpack.go:165] Enter binpack plugin ...
I0904 12:17:27.944147       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:17:27.944152       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:17:27.944158       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:17:27.944162       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:17:27.944173       1 allocate.go:62] Enter Allocate ...
I0904 12:17:27.944176       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:17:27.944180       1 allocate.go:83] Leaving Allocate ...
I0904 12:17:27.944184       1 backfill.go:59] Enter Backfill ...
I0904 12:17:27.944188       1 backfill.go:110] Leaving Backfill ...
I0904 12:17:27.944192       1 reclaim.go:47] Enter Reclaim ...
I0904 12:17:27.944194       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:17:27.944199       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:17:27.944203       1 preempt.go:103] Enter Preempt ...
I0904 12:17:27.944209       1 preempt.go:270] Leaving Preempt ...
I0904 12:17:27.944226       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:27.944261       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:27.944266       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:27.944271       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:27.944275       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:27.944279       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:27.944283       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:27.944287       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:27.944291       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:27.944306       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:17:27.944337       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:17:27.944345       1 session.go:361] Session 92e25f36-0de7-41fe-a074-f65e9c9d7a11 operated with TotalResource: <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, pods 440.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:17:27.944349       1 session.go:375] Close Session 92e25f36-0de7-41fe-a074-f65e9c9d7a11
I0904 12:17:27.944354       1 scheduler.go:133] End scheduling ...
I0904 12:17:37.945357       1 scheduler.go:106] Start scheduling ...
I0904 12:17:37.945444       1 node_info.go:227] imageStates is map[]
I0904 12:17:37.945484       1 node_info.go:227] imageStates is map[]
I0904 12:17:37.945512       1 node_info.go:227] imageStates is map[]
I0904 12:17:37.945536       1 node_info.go:227] imageStates is map[]
I0904 12:17:37.945555       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:17:37.945565       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:17:37.945575       1 session.go:230] Open Session c25549c9-5bcf-419c-9aa6-31dc2d28c925 with <0> Job and <5> Queues
I0904 12:17:37.945593       1 session.go:233] Session c25549c9-5bcf-419c-9aa6-31dc2d28c925 operates with TotalResource: <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:17:37.945700       1 sla.go:85] Enter sla plugin ...
I0904 12:17:37.945704       1 sla.go:154] Leaving sla plugin.
I0904 12:17:37.945709       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:17:37.945716       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:17:37.945722       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 12:17:37.945770       1 factory.go:59] Register preBinder predicates successfully
I0904 12:17:37.945778       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00>
E0904 12:17:37.945806       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 8000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:17:37.945838       1 binpack.go:165] Enter binpack plugin ...
I0904 12:17:37.945843       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:17:37.945848       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:17:37.945852       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:17:37.945855       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:17:37.945860       1 allocate.go:62] Enter Allocate ...
I0904 12:17:37.945865       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:17:37.945867       1 allocate.go:83] Leaving Allocate ...
I0904 12:17:37.945872       1 backfill.go:59] Enter Backfill ...
I0904 12:17:37.945876       1 backfill.go:110] Leaving Backfill ...
I0904 12:17:37.945879       1 reclaim.go:47] Enter Reclaim ...
I0904 12:17:37.945881       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:17:37.945886       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:17:37.945892       1 preempt.go:103] Enter Preempt ...
I0904 12:17:37.945895       1 preempt.go:270] Leaving Preempt ...
I0904 12:17:37.945909       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:37.945922       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:17:37.945943       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:17:37.945946       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:37.945951       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:37.945956       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:37.945960       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:37.945964       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:37.945968       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:37.945971       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:37.945975       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:37.945982       1 session.go:361] Session c25549c9-5bcf-419c-9aa6-31dc2d28c925 operated with TotalResource: <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:17:37.945986       1 session.go:375] Close Session c25549c9-5bcf-419c-9aa6-31dc2d28c925
I0904 12:17:37.945990       1 scheduler.go:133] End scheduling ...
I0904 12:17:47.946632       1 scheduler.go:106] Start scheduling ...
I0904 12:17:47.946747       1 node_info.go:227] imageStates is map[]
I0904 12:17:47.946809       1 node_info.go:227] imageStates is map[]
I0904 12:17:47.946860       1 node_info.go:227] imageStates is map[]
I0904 12:17:47.946901       1 node_info.go:227] imageStates is map[]
I0904 12:17:47.946943       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:17:47.946962       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:17:47.946976       1 session.go:230] Open Session bac7a768-7191-40c9-b606-2fdbcd2ab7d8 with <0> Job and <5> Queues
I0904 12:17:47.946995       1 session.go:233] Session bac7a768-7191-40c9-b606-2fdbcd2ab7d8 operates with TotalResource: <cpu 36000.00, memory 42380476416.00, pods 440.00, nvidia.com/A100 6000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:17:47.947168       1 sla.go:85] Enter sla plugin ...
I0904 12:17:47.947199       1 sla.go:154] Leaving sla plugin.
I0904 12:17:47.947206       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:17:47.947217       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:17:47.947226       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 440.00, nvidia.com/A100 6000.00, hugepages-1Gi 0.00
I0904 12:17:47.947287       1 factory.go:59] Register preBinder predicates successfully
I0904 12:17:47.947315       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 440.00, nvidia.com/A100 6000.00>
E0904 12:17:47.947367       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 440.00, nvidia.com/A100 6000.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 8000.00, pods 440.00, hugepages-1Gi 0.00>
I0904 12:17:47.947394       1 binpack.go:165] Enter binpack plugin ...
I0904 12:17:47.947401       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:17:47.947408       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:17:47.947415       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:17:47.947419       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:17:47.947425       1 allocate.go:62] Enter Allocate ...
I0904 12:17:47.947430       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:17:47.947434       1 allocate.go:83] Leaving Allocate ...
I0904 12:17:47.947439       1 backfill.go:59] Enter Backfill ...
I0904 12:17:47.947445       1 backfill.go:110] Leaving Backfill ...
I0904 12:17:47.947449       1 reclaim.go:47] Enter Reclaim ...
I0904 12:17:47.947454       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:17:47.947462       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:17:47.947466       1 preempt.go:103] Enter Preempt ...
I0904 12:17:47.947472       1 preempt.go:270] Leaving Preempt ...
I0904 12:17:47.947489       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:47.947516       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:47.947523       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:47.947530       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:17:47.947551       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:17:47.947558       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:47.947566       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:47.947574       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:47.947582       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:47.947588       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:47.947596       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:47.947608       1 session.go:361] Session bac7a768-7191-40c9-b606-2fdbcd2ab7d8 operated with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 440.00, nvidia.com/A100 6000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:17:47.947615       1 session.go:375] Close Session bac7a768-7191-40c9-b606-2fdbcd2ab7d8
I0904 12:17:47.947623       1 scheduler.go:133] End scheduling ...
I0904 12:17:53.398939       1 cache.go:1179] started sync node integration-control-plane
I0904 12:17:53.401359       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:17:53.401528       1 node_info.go:227] imageStates is map[]
I0904 12:17:54.050157       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-a100-mate-0
I0904 12:17:54.050182       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-a100-mate-0
W0904 12:17:54.050220       1 event_handlers.go:370] Failed to delete task: errors:  1: task kube-system/kindnet-9vg9h has null jobID
W0904 12:17:54.050276       1 node_info.go:346] received argument of nil node, no need to set other resources for 
W0904 12:17:54.050281       1 node_info.go:241] the argument node is null.
I0904 12:17:54.050285       1 event_handlers.go:231] Pod <kube-system/kindnet-9vg9h> is in status Failed.
I0904 12:17:54.050288       1 event_handlers.go:71] Pod kube-system/kindnet-9vg9h will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 12:17:54.050296       1 event_handlers.go:423] Updated pod <kube-system/kindnet-9vg9h> in cache.
I0904 12:17:54.057345       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-a100-mate-0
I0904 12:17:54.057418       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-a100-mate-0
W0904 12:17:54.057447       1 node_info.go:466] failed to find task <kube-system/kindnet-9vg9h> on host <kwok-node-a100-mate-0>
W0904 12:17:54.057458       1 event_handlers.go:370] Failed to delete task: errors:  1: task kube-system/kindnet-9vg9h has null jobID
I0904 12:17:54.057467       1 event_handlers.go:231] Pod <kube-system/kindnet-9vg9h> is in status Failed.
I0904 12:17:54.057473       1 event_handlers.go:71] Pod kube-system/kindnet-9vg9h will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 12:17:54.057484       1 event_handlers.go:423] Updated pod <kube-system/kindnet-9vg9h> in cache.
I0904 12:17:54.064181       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-a100-mate-0
W0904 12:17:54.064238       1 node_info.go:466] failed to find task <kube-system/kindnet-9vg9h> on host <kwok-node-a100-mate-0>
W0904 12:17:54.064252       1 event_handlers.go:370] Failed to delete task: errors:  1: task kube-system/kindnet-9vg9h has null jobID
I0904 12:17:54.064285       1 event_handlers.go:453] Deleted pod <kube-system/kindnet-9vg9h> from cache.
I0904 12:17:54.076188       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-a100-mate-0
I0904 12:17:54.076234       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-a100-mate-0
W0904 12:17:54.076257       1 node_info.go:466] failed to find task <kube-system/kube-proxy-5v27l> on host <kwok-node-a100-mate-0>
W0904 12:17:54.076268       1 event_handlers.go:370] Failed to delete task: errors:  1: task kube-system/kube-proxy-5v27l has null jobID
I0904 12:17:54.076276       1 event_handlers.go:231] Pod <kube-system/kube-proxy-5v27l> is in status Failed.
I0904 12:17:54.076281       1 event_handlers.go:71] Pod kube-system/kube-proxy-5v27l will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 12:17:54.076290       1 event_handlers.go:423] Updated pod <kube-system/kube-proxy-5v27l> in cache.
I0904 12:17:54.084264       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-a100-mate-0
I0904 12:17:54.084287       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-a100-mate-0
W0904 12:17:54.084306       1 node_info.go:466] failed to find task <kube-system/kube-proxy-5v27l> on host <kwok-node-a100-mate-0>
W0904 12:17:54.084313       1 event_handlers.go:370] Failed to delete task: errors:  1: task kube-system/kube-proxy-5v27l has null jobID
I0904 12:17:54.084322       1 event_handlers.go:231] Pod <kube-system/kube-proxy-5v27l> is in status Failed.
I0904 12:17:54.084325       1 event_handlers.go:71] Pod kube-system/kube-proxy-5v27l will not scheduled by []string{"volcano"}, skip creating PodGroup and Job for it
I0904 12:17:54.084334       1 event_handlers.go:423] Updated pod <kube-system/kube-proxy-5v27l> in cache.
I0904 12:17:54.090836       1 util.go:79] schedulerPodName  is responsible to Node kwok-node-a100-mate-0
W0904 12:17:54.090924       1 node_info.go:466] failed to find task <kube-system/kube-proxy-5v27l> on host <kwok-node-a100-mate-0>
W0904 12:17:54.090940       1 event_handlers.go:370] Failed to delete task: errors:  1: task kube-system/kube-proxy-5v27l has null jobID
I0904 12:17:54.090945       1 event_handlers.go:453] Deleted pod <kube-system/kube-proxy-5v27l> from cache.
I0904 12:17:57.504246       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:17:57.948148       1 scheduler.go:106] Start scheduling ...
I0904 12:17:57.948306       1 node_info.go:227] imageStates is map[]
I0904 12:17:57.948357       1 node_info.go:227] imageStates is map[]
I0904 12:17:57.948377       1 node_info.go:227] imageStates is map[]
I0904 12:17:57.948397       1 node_info.go:227] imageStates is map[]
I0904 12:17:57.948423       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:17:57.948444       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:17:57.948459       1 session.go:230] Open Session 26ad53c2-42fd-4b65-a062-11082fabc059 with <0> Job and <5> Queues
I0904 12:17:57.948481       1 session.go:233] Session 26ad53c2-42fd-4b65-a062-11082fabc059 operates with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 6000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:17:57.948655       1 sla.go:85] Enter sla plugin ...
I0904 12:17:57.948695       1 sla.go:154] Leaving sla plugin.
I0904 12:17:57.948703       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:17:57.948715       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:17:57.948724       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 12:17:57.948793       1 factory.go:59] Register preBinder predicates successfully
I0904 12:17:57.948826       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 6000.00>
E0904 12:17:57.948897       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00>
I0904 12:17:57.948951       1 binpack.go:165] Enter binpack plugin ...
I0904 12:17:57.948959       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:17:57.948967       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:17:57.948975       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:17:57.948981       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:17:57.948990       1 allocate.go:62] Enter Allocate ...
I0904 12:17:57.949016       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:17:57.949022       1 allocate.go:83] Leaving Allocate ...
I0904 12:17:57.949030       1 backfill.go:59] Enter Backfill ...
I0904 12:17:57.949058       1 backfill.go:110] Leaving Backfill ...
I0904 12:17:57.949064       1 reclaim.go:47] Enter Reclaim ...
I0904 12:17:57.949068       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:17:57.949078       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:17:57.949083       1 preempt.go:103] Enter Preempt ...
I0904 12:17:57.949090       1 preempt.go:270] Leaving Preempt ...
I0904 12:17:57.949112       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:57.949163       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:57.949173       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:57.949184       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:57.949191       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:57.949199       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:57.949207       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:57.949215       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:17:57.949221       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:17:57.949230       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:17:57.949259       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:17:57.949272       1 session.go:361] Session 26ad53c2-42fd-4b65-a062-11082fabc059 operated with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:17:57.949279       1 session.go:375] Close Session 26ad53c2-42fd-4b65-a062-11082fabc059
I0904 12:17:57.949287       1 scheduler.go:133] End scheduling ...
I0904 12:18:03.425126       1 cache.go:1179] started sync node integration-control-plane
I0904 12:18:03.425157       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:18:03.425235       1 node_info.go:227] imageStates is map[]
I0904 12:18:07.949803       1 scheduler.go:106] Start scheduling ...
I0904 12:18:07.949903       1 node_info.go:227] imageStates is map[]
I0904 12:18:07.949939       1 node_info.go:227] imageStates is map[]
I0904 12:18:07.949952       1 node_info.go:227] imageStates is map[]
I0904 12:18:07.949963       1 node_info.go:227] imageStates is map[]
I0904 12:18:07.949982       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:18:07.950005       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:18:07.950014       1 session.go:230] Open Session 18a1bc40-1cf6-48ee-aac6-aae281e5c440 with <0> Job and <5> Queues
I0904 12:18:07.950027       1 session.go:233] Session 18a1bc40-1cf6-48ee-aac6-aae281e5c440 operates with TotalResource: <cpu 36000.00, memory 42380476416.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:18:07.950214       1 sla.go:85] Enter sla plugin ...
I0904 12:18:07.950228       1 sla.go:154] Leaving sla plugin.
I0904 12:18:07.950233       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:18:07.950239       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:18:07.950247       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00
I0904 12:18:07.950294       1 factory.go:59] Register preBinder predicates successfully
I0904 12:18:07.950300       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00>
E0904 12:18:07.950338       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 6000.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:18:07.950369       1 binpack.go:165] Enter binpack plugin ...
I0904 12:18:07.950372       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:18:07.950376       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:18:07.950380       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:18:07.950382       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:18:07.950387       1 allocate.go:62] Enter Allocate ...
I0904 12:18:07.950389       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:18:07.950392       1 allocate.go:83] Leaving Allocate ...
I0904 12:18:07.950395       1 backfill.go:59] Enter Backfill ...
I0904 12:18:07.950398       1 backfill.go:110] Leaving Backfill ...
I0904 12:18:07.950401       1 reclaim.go:47] Enter Reclaim ...
I0904 12:18:07.950403       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:18:07.950407       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:18:07.950411       1 preempt.go:103] Enter Preempt ...
I0904 12:18:07.950414       1 preempt.go:270] Leaving Preempt ...
I0904 12:18:07.950426       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:07.950442       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:07.950446       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:07.950449       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:07.950452       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:07.950456       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:07.950460       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:07.950463       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:18:07.950476       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:18:07.950509       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:07.950516       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:07.950524       1 session.go:361] Session 18a1bc40-1cf6-48ee-aac6-aae281e5c440 operated with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 6000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:18:07.950529       1 session.go:375] Close Session 18a1bc40-1cf6-48ee-aac6-aae281e5c440
I0904 12:18:07.950535       1 scheduler.go:133] End scheduling ...
I0904 12:18:13.490345       1 cache.go:1179] started sync node integration-control-plane
I0904 12:18:13.490367       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:18:13.490480       1 node_info.go:227] imageStates is map[]
I0904 12:18:17.950648       1 scheduler.go:106] Start scheduling ...
I0904 12:18:17.950824       1 node_info.go:227] imageStates is map[]
I0904 12:18:17.950856       1 node_info.go:227] imageStates is map[]
I0904 12:18:17.950877       1 node_info.go:227] imageStates is map[]
I0904 12:18:17.950963       1 node_info.go:227] imageStates is map[]
I0904 12:18:17.951033       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:18:17.951057       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:18:17.951082       1 session.go:230] Open Session 5971b67f-ce7a-4c0e-a223-1d4813bb155a with <0> Job and <5> Queues
I0904 12:18:17.951108       1 session.go:233] Session 5971b67f-ce7a-4c0e-a223-1d4813bb155a operates with TotalResource: <cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, pods 440.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:18:17.951296       1 sla.go:85] Enter sla plugin ...
I0904 12:18:17.951311       1 sla.go:154] Leaving sla plugin.
I0904 12:18:17.951318       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:18:17.951325       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:18:17.951335       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, pods 440.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00
I0904 12:18:17.951402       1 factory.go:59] Register preBinder predicates successfully
I0904 12:18:17.951412       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, pods 440.00>
E0904 12:18:17.951447       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, pods 440.00, nvidia.com/A100 6000.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, pods 440.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>
I0904 12:18:17.951464       1 binpack.go:165] Enter binpack plugin ...
I0904 12:18:17.951467       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:18:17.951471       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:18:17.951475       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:18:17.951478       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:18:17.951483       1 allocate.go:62] Enter Allocate ...
I0904 12:18:17.951487       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:18:17.951489       1 allocate.go:83] Leaving Allocate ...
I0904 12:18:17.951493       1 backfill.go:59] Enter Backfill ...
I0904 12:18:17.951496       1 backfill.go:110] Leaving Backfill ...
I0904 12:18:17.951500       1 reclaim.go:47] Enter Reclaim ...
I0904 12:18:17.951504       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:18:17.951508       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:18:17.951510       1 preempt.go:103] Enter Preempt ...
I0904 12:18:17.951513       1 preempt.go:270] Leaving Preempt ...
I0904 12:18:17.951525       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:17.951535       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:18:17.951555       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:18:17.951567       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:17.951573       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:17.951577       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:17.951581       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:17.951583       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:17.951587       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:17.951592       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:17.951596       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:17.951602       1 session.go:361] Session 5971b67f-ce7a-4c0e-a223-1d4813bb155a operated with TotalResource: <cpu 36000.00, memory 42380476416.00, pods 440.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:18:17.951606       1 session.go:375] Close Session 5971b67f-ce7a-4c0e-a223-1d4813bb155a
I0904 12:18:17.951610       1 scheduler.go:133] End scheduling ...
I0904 12:18:23.823360       1 cache.go:1179] started sync node integration-control-plane
I0904 12:18:23.823408       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:18:23.823487       1 node_info.go:227] imageStates is map[]
I0904 12:18:27.504766       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:18:27.952601       1 scheduler.go:106] Start scheduling ...
I0904 12:18:27.952729       1 node_info.go:227] imageStates is map[]
I0904 12:18:27.952767       1 node_info.go:227] imageStates is map[]
I0904 12:18:27.952781       1 node_info.go:227] imageStates is map[]
I0904 12:18:27.952797       1 node_info.go:227] imageStates is map[]
I0904 12:18:27.952818       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:18:27.952833       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:18:27.952845       1 session.go:230] Open Session a7c346a5-e74c-4840-bc17-48b3253c45cf with <0> Job and <5> Queues
I0904 12:18:27.952862       1 session.go:233] Session a7c346a5-e74c-4840-bc17-48b3253c45cf operates with TotalResource: <cpu 36000.00, memory 42380476416.00, pods 440.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:18:27.953071       1 sla.go:85] Enter sla plugin ...
I0904 12:18:27.953097       1 sla.go:154] Leaving sla plugin.
I0904 12:18:27.953103       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:18:27.953113       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:18:27.953120       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, pods 440.00, nvidia.com/A100 6000.00
I0904 12:18:27.953180       1 factory.go:59] Register preBinder predicates successfully
I0904 12:18:27.953203       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, pods 440.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
E0904 12:18:27.953249       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, pods 440.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00, pods 440.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
I0904 12:18:27.953273       1 binpack.go:165] Enter binpack plugin ...
I0904 12:18:27.953278       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:18:27.953283       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:18:27.953289       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:18:27.953292       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:18:27.953298       1 allocate.go:62] Enter Allocate ...
I0904 12:18:27.953301       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:18:27.953306       1 allocate.go:83] Leaving Allocate ...
I0904 12:18:27.953311       1 backfill.go:59] Enter Backfill ...
I0904 12:18:27.953315       1 backfill.go:110] Leaving Backfill ...
I0904 12:18:27.953319       1 reclaim.go:47] Enter Reclaim ...
I0904 12:18:27.953322       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:18:27.953329       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:18:27.953333       1 preempt.go:103] Enter Preempt ...
I0904 12:18:27.953338       1 preempt.go:270] Leaving Preempt ...
I0904 12:18:27.953352       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:27.953393       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:27.953398       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:27.953403       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:27.953408       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:27.953413       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:27.953447       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:27.953454       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:18:27.953472       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:18:27.953475       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:27.953481       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:27.953490       1 session.go:361] Session a7c346a5-e74c-4840-bc17-48b3253c45cf operated with TotalResource: <cpu 36000.00, memory 42380476416.00, pods 440.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:18:27.953496       1 session.go:375] Close Session a7c346a5-e74c-4840-bc17-48b3253c45cf
I0904 12:18:27.953501       1 scheduler.go:133] End scheduling ...
I0904 12:18:31.373994       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PriorityClass" totalItems=6
I0904 12:18:33.852937       1 cache.go:1179] started sync node integration-control-plane
I0904 12:18:33.852988       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:18:33.853062       1 node_info.go:227] imageStates is map[]
I0904 12:18:35.380017       1 reflector.go:946] "Watch close" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145" type="*v1alpha1.Numatopology" totalItems=9
I0904 12:18:37.954222       1 scheduler.go:106] Start scheduling ...
I0904 12:18:37.954323       1 node_info.go:227] imageStates is map[]
I0904 12:18:37.954337       1 node_info.go:227] imageStates is map[]
I0904 12:18:37.954371       1 node_info.go:227] imageStates is map[]
I0904 12:18:37.954385       1 node_info.go:227] imageStates is map[]
I0904 12:18:37.954401       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:18:37.954414       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:18:37.954423       1 session.go:230] Open Session be68cd14-3b6d-421b-99a1-e1da4c0a0dee with <0> Job and <5> Queues
I0904 12:18:37.954436       1 session.go:233] Session be68cd14-3b6d-421b-99a1-e1da4c0a0dee operates with TotalResource: <cpu 36000.00, memory 42380476416.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:18:37.954548       1 sla.go:85] Enter sla plugin ...
I0904 12:18:37.954563       1 sla.go:154] Leaving sla plugin.
I0904 12:18:37.954567       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:18:37.954573       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:18:37.954578       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00
I0904 12:18:37.954623       1 factory.go:59] Register preBinder predicates successfully
I0904 12:18:37.954629       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00>
E0904 12:18:37.954659       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:18:37.954674       1 binpack.go:165] Enter binpack plugin ...
I0904 12:18:37.954687       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:18:37.954691       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:18:37.954696       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:18:37.954698       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:18:37.954703       1 allocate.go:62] Enter Allocate ...
I0904 12:18:37.954706       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:18:37.954708       1 allocate.go:83] Leaving Allocate ...
I0904 12:18:37.954712       1 backfill.go:59] Enter Backfill ...
I0904 12:18:37.954714       1 backfill.go:110] Leaving Backfill ...
I0904 12:18:37.954718       1 reclaim.go:47] Enter Reclaim ...
I0904 12:18:37.954720       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:18:37.954725       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:18:37.954727       1 preempt.go:103] Enter Preempt ...
I0904 12:18:37.954731       1 preempt.go:270] Leaving Preempt ...
I0904 12:18:37.954743       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:37.954772       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:37.954775       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:37.954780       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:37.954783       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:37.954787       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:37.954791       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:37.954794       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:18:37.954809       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:18:37.954812       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:37.954816       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:37.954823       1 session.go:361] Session be68cd14-3b6d-421b-99a1-e1da4c0a0dee operated with TotalResource: <cpu 36000.00, memory 42380476416.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:18:37.954827       1 session.go:375] Close Session be68cd14-3b6d-421b-99a1-e1da4c0a0dee
I0904 12:18:37.954831       1 scheduler.go:133] End scheduling ...
I0904 12:18:40.375447       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicationController" totalItems=11
I0904 12:18:43.885413       1 cache.go:1179] started sync node integration-control-plane
I0904 12:18:43.885569       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:18:43.885723       1 node_info.go:227] imageStates is map[]
I0904 12:18:47.955117       1 scheduler.go:106] Start scheduling ...
I0904 12:18:47.955413       1 node_info.go:227] imageStates is map[]
I0904 12:18:47.955495       1 node_info.go:227] imageStates is map[]
I0904 12:18:47.955638       1 node_info.go:227] imageStates is map[]
I0904 12:18:47.955728       1 node_info.go:227] imageStates is map[]
I0904 12:18:47.955791       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:18:47.955834       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:18:47.955868       1 session.go:230] Open Session 31dc9e79-0a50-4088-81cb-509a0b25a7c7 with <0> Job and <5> Queues
I0904 12:18:47.955918       1 session.go:233] Session 31dc9e79-0a50-4088-81cb-509a0b25a7c7 operates with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 6000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:18:47.956313       1 sla.go:85] Enter sla plugin ...
I0904 12:18:47.956337       1 sla.go:154] Leaving sla plugin.
I0904 12:18:47.956356       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:18:47.956385       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:18:47.956437       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 6000.00, hugepages-1Gi 0.00
I0904 12:18:47.956611       1 factory.go:59] Register preBinder predicates successfully
I0904 12:18:47.956674       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, pods 440.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 6000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
E0904 12:18:47.956793       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, pods 440.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 6000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:18:47.956899       1 binpack.go:165] Enter binpack plugin ...
I0904 12:18:47.956919       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:18:47.956941       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:18:47.956982       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:18:47.956999       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:18:47.957017       1 allocate.go:62] Enter Allocate ...
I0904 12:18:47.957029       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:18:47.957041       1 allocate.go:83] Leaving Allocate ...
I0904 12:18:47.957055       1 backfill.go:59] Enter Backfill ...
I0904 12:18:47.957068       1 backfill.go:110] Leaving Backfill ...
I0904 12:18:47.957081       1 reclaim.go:47] Enter Reclaim ...
I0904 12:18:47.957092       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:18:47.957111       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:18:47.957125       1 preempt.go:103] Enter Preempt ...
I0904 12:18:47.957142       1 preempt.go:270] Leaving Preempt ...
I0904 12:18:47.957192       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:47.957402       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:18:47.957508       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:18:47.957530       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:47.957560       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:47.957579       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:47.957601       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:47.957621       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:47.957649       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:47.957665       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:47.957687       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:47.957726       1 session.go:361] Session 31dc9e79-0a50-4088-81cb-509a0b25a7c7 operated with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 6000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:18:47.957745       1 session.go:375] Close Session 31dc9e79-0a50-4088-81cb-509a0b25a7c7
I0904 12:18:47.957766       1 scheduler.go:133] End scheduling ...
I0904 12:18:57.381204       1 reflector.go:946] "Watch close" reflector="volcano.sh/apis/pkg/client/informers/externalversions/factory.go:145" type="*v1alpha1.HyperNode" totalItems=10
I0904 12:18:57.505223       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:18:57.958707       1 scheduler.go:106] Start scheduling ...
I0904 12:18:57.958917       1 node_info.go:227] imageStates is map[]
I0904 12:18:57.958976       1 node_info.go:227] imageStates is map[]
I0904 12:18:57.959110       1 node_info.go:227] imageStates is map[]
I0904 12:18:57.959164       1 node_info.go:227] imageStates is map[]
I0904 12:18:57.959265       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:18:57.959298       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:18:57.959320       1 session.go:230] Open Session 1e364fbe-7043-4955-bbc8-410979b00e3b with <0> Job and <5> Queues
I0904 12:18:57.959354       1 session.go:233] Session 1e364fbe-7043-4955-bbc8-410979b00e3b operates with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 440.00, nvidia.com/A100 6000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:18:57.959716       1 sla.go:85] Enter sla plugin ...
I0904 12:18:57.959763       1 sla.go:154] Leaving sla plugin.
I0904 12:18:57.959775       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:18:57.959794       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:18:57.959807       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, pods 440.00, nvidia.com/A100 6000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00
I0904 12:18:57.959917       1 factory.go:59] Register preBinder predicates successfully
I0904 12:18:57.959932       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 440.00, nvidia.com/A100 6000.00>
E0904 12:18:57.960024       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, pods 440.00, nvidia.com/A100 6000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 440.00, hugepages-1Gi 0.00>
I0904 12:18:57.960071       1 binpack.go:165] Enter binpack plugin ...
I0904 12:18:57.960082       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:18:57.960099       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:18:57.960205       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:18:57.960216       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:18:57.960367       1 allocate.go:62] Enter Allocate ...
I0904 12:18:57.960413       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:18:57.960421       1 allocate.go:83] Leaving Allocate ...
I0904 12:18:57.960432       1 backfill.go:59] Enter Backfill ...
I0904 12:18:57.960441       1 backfill.go:110] Leaving Backfill ...
I0904 12:18:57.960450       1 reclaim.go:47] Enter Reclaim ...
I0904 12:18:57.960458       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:18:57.960472       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:18:57.960480       1 preempt.go:103] Enter Preempt ...
I0904 12:18:57.960492       1 preempt.go:270] Leaving Preempt ...
I0904 12:18:57.960525       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:57.960573       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:57.960585       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:57.960602       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:57.960612       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:57.960625       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:57.960637       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:57.960654       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:18:57.960664       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:18:57.960677       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:18:57.960714       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:18:57.960737       1 session.go:361] Session 1e364fbe-7043-4955-bbc8-410979b00e3b operated with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, pods 440.00, nvidia.com/A100 6000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:18:57.960746       1 session.go:375] Close Session 1e364fbe-7043-4955-bbc8-410979b00e3b
I0904 12:18:57.960756       1 scheduler.go:133] End scheduling ...
I0904 12:19:06.384325       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicaSet" totalItems=6
I0904 12:19:07.961888       1 scheduler.go:106] Start scheduling ...
I0904 12:19:07.962092       1 node_info.go:227] imageStates is map[]
I0904 12:19:07.962157       1 node_info.go:227] imageStates is map[]
I0904 12:19:07.962185       1 node_info.go:227] imageStates is map[]
I0904 12:19:07.962259       1 node_info.go:227] imageStates is map[]
I0904 12:19:07.962301       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:19:07.962326       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:19:07.962343       1 session.go:230] Open Session 6ab40ce1-9e83-49c7-bc42-406ac4af6bb0 with <0> Job and <5> Queues
I0904 12:19:07.962371       1 session.go:233] Session 6ab40ce1-9e83-49c7-bc42-406ac4af6bb0 operates with TotalResource: <cpu 36000.00, memory 42380476416.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:19:07.962608       1 sla.go:85] Enter sla plugin ...
I0904 12:19:07.962654       1 sla.go:154] Leaving sla plugin.
I0904 12:19:07.962666       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:19:07.962684       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:19:07.962697       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00
I0904 12:19:07.962796       1 factory.go:59] Register preBinder predicates successfully
I0904 12:19:07.962810       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
E0904 12:19:07.962900       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:19:07.962942       1 binpack.go:165] Enter binpack plugin ...
I0904 12:19:07.962953       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:19:07.962964       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:19:07.962975       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:19:07.962982       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:19:07.962992       1 allocate.go:62] Enter Allocate ...
I0904 12:19:07.963000       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:19:07.963007       1 allocate.go:83] Leaving Allocate ...
I0904 12:19:07.963016       1 backfill.go:59] Enter Backfill ...
I0904 12:19:07.963025       1 backfill.go:110] Leaving Backfill ...
I0904 12:19:07.963032       1 reclaim.go:47] Enter Reclaim ...
I0904 12:19:07.963041       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:19:07.963054       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:19:07.963060       1 preempt.go:103] Enter Preempt ...
I0904 12:19:07.963070       1 preempt.go:270] Leaving Preempt ...
I0904 12:19:07.963099       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:07.963137       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:07.963159       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:07.963174       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:07.963184       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:07.963199       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:07.963209       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:07.963222       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:07.963231       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:07.963244       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:19:07.963292       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:19:07.963342       1 session.go:361] Session 6ab40ce1-9e83-49c7-bc42-406ac4af6bb0 operated with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:19:07.963355       1 session.go:375] Close Session 6ab40ce1-9e83-49c7-bc42-406ac4af6bb0
I0904 12:19:07.963366       1 scheduler.go:133] End scheduling ...
I0904 12:19:14.306296       1 cache.go:1179] started sync node integration-control-plane
I0904 12:19:14.306452       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:19:14.306707       1 node_info.go:227] imageStates is map[]
I0904 12:19:17.963602       1 scheduler.go:106] Start scheduling ...
I0904 12:19:17.963747       1 node_info.go:227] imageStates is map[]
I0904 12:19:17.963779       1 node_info.go:227] imageStates is map[]
I0904 12:19:17.963832       1 node_info.go:227] imageStates is map[]
I0904 12:19:17.963922       1 node_info.go:227] imageStates is map[]
I0904 12:19:17.963965       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:19:17.964013       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:19:17.964031       1 session.go:230] Open Session 0803481e-f5e4-4719-a0b8-fe026df7ce1c with <0> Job and <5> Queues
I0904 12:19:17.964084       1 session.go:233] Session 0803481e-f5e4-4719-a0b8-fe026df7ce1c operates with TotalResource: <cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 6000.00, pods 440.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:19:17.964254       1 sla.go:85] Enter sla plugin ...
I0904 12:19:17.964260       1 sla.go:154] Leaving sla plugin.
I0904 12:19:17.964266       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:19:17.964276       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:19:17.964283       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, pods 440.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00
I0904 12:19:17.964339       1 factory.go:59] Register preBinder predicates successfully
I0904 12:19:17.964367       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, pods 440.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 6000.00>
E0904 12:19:17.964413       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00, nvidia.com/A100 6000.00, pods 440.00, hugepages-1Gi 0.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 8000.00, pods 440.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>
I0904 12:19:17.964437       1 binpack.go:165] Enter binpack plugin ...
I0904 12:19:17.964443       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:19:17.964449       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:19:17.964455       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:19:17.964460       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:19:17.964465       1 allocate.go:62] Enter Allocate ...
I0904 12:19:17.964469       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:19:17.964473       1 allocate.go:83] Leaving Allocate ...
I0904 12:19:17.964478       1 backfill.go:59] Enter Backfill ...
I0904 12:19:17.964484       1 backfill.go:110] Leaving Backfill ...
I0904 12:19:17.964488       1 reclaim.go:47] Enter Reclaim ...
I0904 12:19:17.964492       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:19:17.964500       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:19:17.964510       1 preempt.go:103] Enter Preempt ...
I0904 12:19:17.964515       1 preempt.go:270] Leaving Preempt ...
I0904 12:19:17.964533       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:17.964556       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:17.964582       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:17.964590       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:17.964596       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:17.964602       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:17.964607       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:17.964618       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:17.964628       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:17.964645       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:19:17.964689       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:19:17.964712       1 session.go:361] Session 0803481e-f5e4-4719-a0b8-fe026df7ce1c operated with TotalResource: <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, pods 440.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:19:17.964722       1 session.go:375] Close Session 0803481e-f5e4-4719-a0b8-fe026df7ce1c
I0904 12:19:17.964735       1 scheduler.go:133] End scheduling ...
I0904 12:19:22.370924       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSINode" totalItems=7
I0904 12:19:24.575603       1 cache.go:1179] started sync node integration-control-plane
I0904 12:19:24.575645       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:19:24.575746       1 node_info.go:227] imageStates is map[]
I0904 12:19:27.505760       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:19:27.965340       1 scheduler.go:106] Start scheduling ...
I0904 12:19:27.965471       1 node_info.go:227] imageStates is map[]
I0904 12:19:27.965508       1 node_info.go:227] imageStates is map[]
I0904 12:19:27.965553       1 node_info.go:227] imageStates is map[]
I0904 12:19:27.965569       1 node_info.go:227] imageStates is map[]
I0904 12:19:27.965588       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:19:27.965602       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:19:27.965613       1 session.go:230] Open Session 5e2cca59-714d-44e1-9caf-9c84e516de98 with <0> Job and <5> Queues
I0904 12:19:27.965630       1 session.go:233] Session 5e2cca59-714d-44e1-9caf-9c84e516de98 operates with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:19:27.965757       1 sla.go:85] Enter sla plugin ...
I0904 12:19:27.965762       1 sla.go:154] Leaving sla plugin.
I0904 12:19:27.965767       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:19:27.965775       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:19:27.965781       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00
I0904 12:19:27.965837       1 factory.go:59] Register preBinder predicates successfully
I0904 12:19:27.965844       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
E0904 12:19:27.965882       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 8000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:19:27.965904       1 binpack.go:165] Enter binpack plugin ...
I0904 12:19:27.965910       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:19:27.965914       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:19:27.965920       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:19:27.965923       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:19:27.965928       1 allocate.go:62] Enter Allocate ...
I0904 12:19:27.965931       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:19:27.965936       1 allocate.go:83] Leaving Allocate ...
I0904 12:19:27.965940       1 backfill.go:59] Enter Backfill ...
I0904 12:19:27.965944       1 backfill.go:110] Leaving Backfill ...
I0904 12:19:27.965947       1 reclaim.go:47] Enter Reclaim ...
I0904 12:19:27.965950       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:19:27.965956       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:19:27.965959       1 preempt.go:103] Enter Preempt ...
I0904 12:19:27.965964       1 preempt.go:270] Leaving Preempt ...
I0904 12:19:27.965978       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:27.965998       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:27.966004       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:27.966010       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:19:27.966031       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:19:27.966035       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:27.966042       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:27.966048       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:27.966055       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:27.966059       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:27.966065       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:27.966074       1 session.go:361] Session 5e2cca59-714d-44e1-9caf-9c84e516de98 operated with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:19:27.966079       1 session.go:375] Close Session 5e2cca59-714d-44e1-9caf-9c84e516de98
I0904 12:19:27.966083       1 scheduler.go:133] End scheduling ...
I0904 12:19:37.967102       1 scheduler.go:106] Start scheduling ...
I0904 12:19:37.967272       1 node_info.go:227] imageStates is map[]
I0904 12:19:37.967310       1 node_info.go:227] imageStates is map[]
I0904 12:19:37.967367       1 node_info.go:227] imageStates is map[]
I0904 12:19:37.967447       1 node_info.go:227] imageStates is map[]
I0904 12:19:37.967494       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:19:37.967518       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:19:37.967538       1 session.go:230] Open Session 2d9dfcda-b104-453e-a9f4-313aec2c949c with <0> Job and <5> Queues
I0904 12:19:37.967567       1 session.go:233] Session 2d9dfcda-b104-453e-a9f4-313aec2c949c operates with TotalResource: <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:19:37.967783       1 sla.go:85] Enter sla plugin ...
I0904 12:19:37.967830       1 sla.go:154] Leaving sla plugin.
I0904 12:19:37.967845       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:19:37.967862       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:19:37.967873       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00
I0904 12:19:37.967963       1 factory.go:59] Register preBinder predicates successfully
I0904 12:19:37.967977       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00>
E0904 12:19:37.968058       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 8000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:19:37.968395       1 binpack.go:165] Enter binpack plugin ...
I0904 12:19:37.968412       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:19:37.968426       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:19:37.968436       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:19:37.968443       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:19:37.968454       1 allocate.go:62] Enter Allocate ...
I0904 12:19:37.968461       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:19:37.968477       1 allocate.go:83] Leaving Allocate ...
I0904 12:19:37.968485       1 backfill.go:59] Enter Backfill ...
I0904 12:19:37.968494       1 backfill.go:110] Leaving Backfill ...
I0904 12:19:37.968501       1 reclaim.go:47] Enter Reclaim ...
I0904 12:19:37.968508       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:19:37.968552       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:19:37.968560       1 preempt.go:103] Enter Preempt ...
I0904 12:19:37.968569       1 preempt.go:270] Leaving Preempt ...
I0904 12:19:37.968805       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:37.968855       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:37.968874       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:37.968893       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:19:37.971890       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:19:37.971946       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:37.972002       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:37.972082       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:37.972112       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:37.972129       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:37.972139       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:37.972168       1 session.go:361] Session 2d9dfcda-b104-453e-a9f4-313aec2c949c operated with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:19:37.972176       1 session.go:375] Close Session 2d9dfcda-b104-453e-a9f4-313aec2c949c
I0904 12:19:37.972186       1 scheduler.go:133] End scheduling ...
I0904 12:19:45.094552       1 cache.go:1179] started sync node integration-control-plane
I0904 12:19:45.094715       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:19:45.094947       1 node_info.go:227] imageStates is map[]
I0904 12:19:47.380843       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Service" totalItems=7
I0904 12:19:47.973104       1 scheduler.go:106] Start scheduling ...
I0904 12:19:47.973273       1 node_info.go:227] imageStates is map[]
I0904 12:19:47.973315       1 node_info.go:227] imageStates is map[]
I0904 12:19:47.973332       1 node_info.go:227] imageStates is map[]
I0904 12:19:47.973348       1 node_info.go:227] imageStates is map[]
I0904 12:19:47.973371       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:19:47.973386       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:19:47.973398       1 session.go:230] Open Session 3ceea25e-9d86-40b1-8b42-921a379f836e with <0> Job and <5> Queues
I0904 12:19:47.973421       1 session.go:233] Session 3ceea25e-9d86-40b1-8b42-921a379f836e operates with TotalResource: <cpu 36000.00, memory 42380476416.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:19:47.973575       1 sla.go:85] Enter sla plugin ...
I0904 12:19:47.973602       1 sla.go:154] Leaving sla plugin.
I0904 12:19:47.973610       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:19:47.973620       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:19:47.973629       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00
I0904 12:19:47.973740       1 factory.go:59] Register preBinder predicates successfully
I0904 12:19:47.973767       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
E0904 12:19:47.973815       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 8000.00>
I0904 12:19:47.973842       1 binpack.go:165] Enter binpack plugin ...
I0904 12:19:47.973849       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:19:47.973856       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:19:47.973862       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:19:47.973866       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:19:47.973873       1 allocate.go:62] Enter Allocate ...
I0904 12:19:47.973877       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:19:47.973881       1 allocate.go:83] Leaving Allocate ...
I0904 12:19:47.973887       1 backfill.go:59] Enter Backfill ...
I0904 12:19:47.973892       1 backfill.go:110] Leaving Backfill ...
I0904 12:19:47.973896       1 reclaim.go:47] Enter Reclaim ...
I0904 12:19:47.973900       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:19:47.973910       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:19:47.973914       1 preempt.go:103] Enter Preempt ...
I0904 12:19:47.973920       1 preempt.go:270] Leaving Preempt ...
I0904 12:19:47.973944       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:47.973969       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:47.973977       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:47.973984       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:47.973991       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:47.973997       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:47.974005       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:47.974013       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:47.974037       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:47.974049       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:19:47.974071       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:19:47.974083       1 session.go:361] Session 3ceea25e-9d86-40b1-8b42-921a379f836e operated with TotalResource: <cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:19:47.974088       1 session.go:375] Close Session 3ceea25e-9d86-40b1-8b42-921a379f836e
I0904 12:19:47.974095       1 scheduler.go:133] End scheduling ...
I0904 12:19:55.128533       1 cache.go:1179] started sync node integration-control-plane
I0904 12:19:55.128613       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:19:55.128829       1 node_info.go:227] imageStates is map[]
I0904 12:19:57.506352       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:19:57.974731       1 scheduler.go:106] Start scheduling ...
I0904 12:19:57.974904       1 node_info.go:227] imageStates is map[]
I0904 12:19:57.974943       1 node_info.go:227] imageStates is map[]
I0904 12:19:57.974968       1 node_info.go:227] imageStates is map[]
I0904 12:19:57.975043       1 node_info.go:227] imageStates is map[]
I0904 12:19:57.975098       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:19:57.975129       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:19:57.975150       1 session.go:230] Open Session baee40c2-03a6-4016-b4f9-54551c7846a8 with <0> Job and <5> Queues
I0904 12:19:57.975180       1 session.go:233] Session baee40c2-03a6-4016-b4f9-54551c7846a8 operates with TotalResource: <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:19:57.975462       1 sla.go:85] Enter sla plugin ...
I0904 12:19:57.975527       1 sla.go:154] Leaving sla plugin.
I0904 12:19:57.975544       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:19:57.975562       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:19:57.975575       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00
I0904 12:19:57.975670       1 factory.go:59] Register preBinder predicates successfully
I0904 12:19:57.975684       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
E0904 12:19:57.975772       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 8000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00>
I0904 12:19:57.975815       1 binpack.go:165] Enter binpack plugin ...
I0904 12:19:57.975827       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:19:57.975839       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:19:57.975849       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:19:57.975856       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:19:57.975866       1 allocate.go:62] Enter Allocate ...
I0904 12:19:57.975877       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:19:57.975884       1 allocate.go:83] Leaving Allocate ...
I0904 12:19:57.975894       1 backfill.go:59] Enter Backfill ...
I0904 12:19:57.975904       1 backfill.go:110] Leaving Backfill ...
I0904 12:19:57.975912       1 reclaim.go:47] Enter Reclaim ...
I0904 12:19:57.975920       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:19:57.975934       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:19:57.975943       1 preempt.go:103] Enter Preempt ...
I0904 12:19:57.975954       1 preempt.go:270] Leaving Preempt ...
I0904 12:19:57.975992       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:57.976100       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:57.976113       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:57.976127       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:19:57.976163       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:19:57.976173       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:57.976186       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:57.976196       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:57.976208       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:57.976218       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:19:57.976230       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:19:57.976251       1 session.go:361] Session baee40c2-03a6-4016-b4f9-54551c7846a8 operated with TotalResource: <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:19:57.976261       1 session.go:375] Close Session baee40c2-03a6-4016-b4f9-54551c7846a8
I0904 12:19:57.976272       1 scheduler.go:133] End scheduling ...
I0904 12:20:07.976557       1 scheduler.go:106] Start scheduling ...
I0904 12:20:07.976836       1 node_info.go:227] imageStates is map[]
I0904 12:20:07.976950       1 node_info.go:227] imageStates is map[]
I0904 12:20:07.976987       1 node_info.go:227] imageStates is map[]
I0904 12:20:07.977021       1 node_info.go:227] imageStates is map[]
I0904 12:20:07.977063       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:20:07.977095       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:20:07.977118       1 session.go:230] Open Session 742d4467-f5d1-428d-8ec3-d1c4e97f855c with <0> Job and <5> Queues
I0904 12:20:07.977150       1 session.go:233] Session 742d4467-f5d1-428d-8ec3-d1c4e97f855c operates with TotalResource: <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:20:07.977408       1 sla.go:85] Enter sla plugin ...
I0904 12:20:07.977464       1 sla.go:154] Leaving sla plugin.
I0904 12:20:07.977476       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:20:07.977494       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:20:07.977507       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00
I0904 12:20:07.977615       1 factory.go:59] Register preBinder predicates successfully
I0904 12:20:07.977632       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 6000.00, hugepages-2Mi 0.00>
E0904 12:20:07.977719       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 6000.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 440.00>
I0904 12:20:07.977755       1 binpack.go:165] Enter binpack plugin ...
I0904 12:20:07.977767       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:20:07.977777       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], memory[1], cpu[1] ...
I0904 12:20:07.977788       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:20:07.977794       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:20:07.977804       1 allocate.go:62] Enter Allocate ...
I0904 12:20:07.977817       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:20:07.977826       1 allocate.go:83] Leaving Allocate ...
I0904 12:20:07.977835       1 backfill.go:59] Enter Backfill ...
I0904 12:20:07.977844       1 backfill.go:110] Leaving Backfill ...
I0904 12:20:07.977851       1 reclaim.go:47] Enter Reclaim ...
I0904 12:20:07.977859       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:20:07.977872       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:20:07.977880       1 preempt.go:103] Enter Preempt ...
I0904 12:20:07.977890       1 preempt.go:270] Leaving Preempt ...
I0904 12:20:07.977917       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:07.977964       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:07.977974       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:07.977987       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:07.977995       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:07.978006       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:20:07.978038       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:20:07.978047       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:07.978060       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:07.978071       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:07.978082       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:07.978099       1 session.go:361] Session 742d4467-f5d1-428d-8ec3-d1c4e97f855c operated with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, nvidia.com/A100 6000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:20:07.978109       1 session.go:375] Close Session 742d4467-f5d1-428d-8ec3-d1c4e97f855c
I0904 12:20:07.978120       1 scheduler.go:133] End scheduling ...
I0904 12:20:17.978654       1 scheduler.go:106] Start scheduling ...
I0904 12:20:17.978811       1 node_info.go:227] imageStates is map[]
I0904 12:20:17.978845       1 node_info.go:227] imageStates is map[]
I0904 12:20:17.978896       1 node_info.go:227] imageStates is map[]
I0904 12:20:17.978986       1 node_info.go:227] imageStates is map[]
I0904 12:20:17.979044       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:20:17.979065       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:20:17.979079       1 session.go:230] Open Session 03e1640d-93b9-4729-a182-52f09e36b504 with <0> Job and <5> Queues
I0904 12:20:17.979102       1 session.go:233] Session 03e1640d-93b9-4729-a182-52f09e36b504 operates with TotalResource: <cpu 36000.00, memory 42380476416.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:20:17.979295       1 sla.go:85] Enter sla plugin ...
I0904 12:20:17.979327       1 sla.go:154] Leaving sla plugin.
I0904 12:20:17.979334       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:20:17.979346       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:20:17.979353       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00
I0904 12:20:17.979420       1 factory.go:59] Register preBinder predicates successfully
I0904 12:20:17.979432       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00>
E0904 12:20:17.979597       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, nvidia.com/A100 8000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:20:17.979655       1 binpack.go:165] Enter binpack plugin ...
I0904 12:20:17.979662       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:20:17.979670       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:20:17.979677       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:20:17.979682       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:20:17.979691       1 allocate.go:62] Enter Allocate ...
I0904 12:20:17.979696       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:20:17.979701       1 allocate.go:83] Leaving Allocate ...
I0904 12:20:17.979707       1 backfill.go:59] Enter Backfill ...
I0904 12:20:17.979714       1 backfill.go:110] Leaving Backfill ...
I0904 12:20:17.979719       1 reclaim.go:47] Enter Reclaim ...
I0904 12:20:17.979723       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:20:17.979732       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:20:17.979737       1 preempt.go:103] Enter Preempt ...
I0904 12:20:17.979743       1 preempt.go:270] Leaving Preempt ...
I0904 12:20:17.979764       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:17.979806       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:17.979815       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:17.979826       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:17.979832       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:17.979840       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:17.979849       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:17.979856       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:20:17.979880       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:20:17.979886       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:17.979894       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:17.979908       1 session.go:361] Session 03e1640d-93b9-4729-a182-52f09e36b504 operated with TotalResource: <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:20:17.979974       1 session.go:375] Close Session 03e1640d-93b9-4729-a182-52f09e36b504
I0904 12:20:17.980007       1 scheduler.go:133] End scheduling ...
I0904 12:20:27.386830       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Pod" totalItems=16
I0904 12:20:27.507345       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:20:27.980999       1 scheduler.go:106] Start scheduling ...
I0904 12:20:27.981076       1 node_info.go:227] imageStates is map[]
I0904 12:20:27.981092       1 node_info.go:227] imageStates is map[]
I0904 12:20:27.981134       1 node_info.go:227] imageStates is map[]
I0904 12:20:27.981312       1 node_info.go:227] imageStates is map[]
I0904 12:20:27.981453       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:20:27.981473       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:20:27.981487       1 session.go:230] Open Session 3bc7beab-a236-45cc-b34f-bfb4a5120d01 with <0> Job and <5> Queues
I0904 12:20:27.981534       1 session.go:233] Session 3bc7beab-a236-45cc-b34f-bfb4a5120d01 operates with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:20:27.985713       1 sla.go:85] Enter sla plugin ...
I0904 12:20:27.987361       1 sla.go:154] Leaving sla plugin.
I0904 12:20:27.987393       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:20:27.987404       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:20:27.987411       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00
I0904 12:20:27.987494       1 factory.go:59] Register preBinder predicates successfully
I0904 12:20:27.987517       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
E0904 12:20:27.987568       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 8000.00, hugepages-2Mi 0.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>
I0904 12:20:27.987614       1 binpack.go:165] Enter binpack plugin ...
I0904 12:20:27.987620       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:20:27.987627       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:20:27.987632       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:20:27.987635       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:20:27.987641       1 allocate.go:62] Enter Allocate ...
I0904 12:20:27.987644       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:20:27.987646       1 allocate.go:83] Leaving Allocate ...
I0904 12:20:27.987651       1 backfill.go:59] Enter Backfill ...
I0904 12:20:27.987655       1 backfill.go:110] Leaving Backfill ...
I0904 12:20:27.987659       1 reclaim.go:47] Enter Reclaim ...
I0904 12:20:27.987663       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:20:27.987668       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:20:27.987671       1 preempt.go:103] Enter Preempt ...
I0904 12:20:27.987675       1 preempt.go:270] Leaving Preempt ...
I0904 12:20:27.987694       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:27.987730       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:20:27.987759       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:20:27.987780       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:27.987846       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:27.987855       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:27.987884       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:27.987902       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:27.987909       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:27.987913       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:27.987918       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:27.987930       1 session.go:361] Session 3bc7beab-a236-45cc-b34f-bfb4a5120d01 operated with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:20:27.987937       1 session.go:375] Close Session 3bc7beab-a236-45cc-b34f-bfb4a5120d01
I0904 12:20:27.987945       1 scheduler.go:133] End scheduling ...
I0904 12:20:37.988856       1 scheduler.go:106] Start scheduling ...
I0904 12:20:37.989090       1 node_info.go:227] imageStates is map[]
I0904 12:20:37.989142       1 node_info.go:227] imageStates is map[]
I0904 12:20:37.989273       1 node_info.go:227] imageStates is map[]
I0904 12:20:37.989362       1 node_info.go:227] imageStates is map[]
I0904 12:20:37.989411       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:20:37.989445       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:20:37.989470       1 session.go:230] Open Session cf83b00f-c26e-4f4a-92a6-8a4349ed3f73 with <0> Job and <5> Queues
I0904 12:20:37.989506       1 session.go:233] Session cf83b00f-c26e-4f4a-92a6-8a4349ed3f73 operates with TotalResource: <cpu 36000.00, memory 42380476416.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:20:37.989812       1 sla.go:85] Enter sla plugin ...
I0904 12:20:37.989874       1 sla.go:154] Leaving sla plugin.
I0904 12:20:37.989893       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:20:37.989913       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:20:37.989926       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00
I0904 12:20:37.990033       1 factory.go:59] Register preBinder predicates successfully
I0904 12:20:37.990048       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00>
E0904 12:20:37.990194       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, pods 440.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00>
I0904 12:20:37.990250       1 binpack.go:165] Enter binpack plugin ...
I0904 12:20:37.990260       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:20:37.990273       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:20:37.990287       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:20:37.990294       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:20:37.990335       1 allocate.go:62] Enter Allocate ...
I0904 12:20:37.990345       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:20:37.990352       1 allocate.go:83] Leaving Allocate ...
I0904 12:20:37.990362       1 backfill.go:59] Enter Backfill ...
I0904 12:20:37.990372       1 backfill.go:110] Leaving Backfill ...
I0904 12:20:37.990380       1 reclaim.go:47] Enter Reclaim ...
I0904 12:20:37.990388       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:20:37.990402       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:20:37.990410       1 preempt.go:103] Enter Preempt ...
I0904 12:20:37.990421       1 preempt.go:270] Leaving Preempt ...
I0904 12:20:37.990460       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:37.990504       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:37.990518       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:37.990532       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:37.990541       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:37.990554       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:37.990563       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:37.990575       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:20:37.990626       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:20:37.990636       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:37.990650       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:37.990700       1 session.go:361] Session cf83b00f-c26e-4f4a-92a6-8a4349ed3f73 operated with TotalResource: <cpu 36000.00, memory 42380476416.00, pods 440.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, nvidia.com/A100 6000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:20:37.990710       1 session.go:375] Close Session cf83b00f-c26e-4f4a-92a6-8a4349ed3f73
I0904 12:20:37.990721       1 scheduler.go:133] End scheduling ...
I0904 12:20:45.954875       1 cache.go:1179] started sync node integration-control-plane
I0904 12:20:45.954908       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:20:45.954981       1 node_info.go:227] imageStates is map[]
I0904 12:20:47.377251       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PodDisruptionBudget" totalItems=7
I0904 12:20:47.991034       1 scheduler.go:106] Start scheduling ...
I0904 12:20:47.991414       1 node_info.go:227] imageStates is map[]
I0904 12:20:47.991510       1 node_info.go:227] imageStates is map[]
I0904 12:20:47.991554       1 node_info.go:227] imageStates is map[]
I0904 12:20:47.991732       1 node_info.go:227] imageStates is map[]
I0904 12:20:47.991801       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:20:47.991939       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:20:47.991983       1 session.go:230] Open Session 96ecf927-4bbd-4eb1-aadd-cada6b374a03 with <0> Job and <5> Queues
I0904 12:20:47.992029       1 session.go:233] Session 96ecf927-4bbd-4eb1-aadd-cada6b374a03 operates with TotalResource: <cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:20:47.992725       1 sla.go:85] Enter sla plugin ...
I0904 12:20:47.992808       1 sla.go:154] Leaving sla plugin.
I0904 12:20:47.992836       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:20:47.992861       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:20:47.992877       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00
I0904 12:20:47.993009       1 factory.go:59] Register preBinder predicates successfully
I0904 12:20:47.993025       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00>
E0904 12:20:47.993131       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00>
I0904 12:20:47.993176       1 binpack.go:165] Enter binpack plugin ...
I0904 12:20:47.993229       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:20:47.993243       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:20:47.993256       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:20:47.993263       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:20:47.993275       1 allocate.go:62] Enter Allocate ...
I0904 12:20:47.993284       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:20:47.993292       1 allocate.go:83] Leaving Allocate ...
I0904 12:20:47.993308       1 backfill.go:59] Enter Backfill ...
I0904 12:20:47.993318       1 backfill.go:110] Leaving Backfill ...
I0904 12:20:47.993327       1 reclaim.go:47] Enter Reclaim ...
I0904 12:20:47.993336       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:20:47.993350       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:20:47.993358       1 preempt.go:103] Enter Preempt ...
I0904 12:20:47.993369       1 preempt.go:270] Leaving Preempt ...
I0904 12:20:47.993401       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:47.993449       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:47.993462       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:47.993477       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:47.993491       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:47.993505       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:47.993517       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:47.993528       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:47.993540       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:47.993553       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:20:47.993594       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:20:47.993615       1 session.go:361] Session 96ecf927-4bbd-4eb1-aadd-cada6b374a03 operated with TotalResource: <cpu 36000.00, memory 42380476416.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:20:47.993628       1 session.go:375] Close Session 96ecf927-4bbd-4eb1-aadd-cada6b374a03
I0904 12:20:47.993655       1 scheduler.go:133] End scheduling ...
I0904 12:20:49.378058       1 reflector.go:946] "Watch close" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Node" totalItems=22
I0904 12:20:56.362222       1 cache.go:1179] started sync node integration-control-plane
I0904 12:20:56.362256       1 util.go:79] schedulerPodName  is responsible to Node integration-control-plane
I0904 12:20:56.362333       1 node_info.go:227] imageStates is map[]
I0904 12:20:57.507863       1 cache.go:1612] The metrics type is not set in the volcano scheduler configmap file. As a result, the CPU and memory load information of the node is not collected.
I0904 12:20:57.994646       1 scheduler.go:106] Start scheduling ...
I0904 12:20:57.994902       1 node_info.go:227] imageStates is map[]
I0904 12:20:57.994942       1 node_info.go:227] imageStates is map[]
I0904 12:20:57.995058       1 node_info.go:227] imageStates is map[]
I0904 12:20:57.995130       1 node_info.go:227] imageStates is map[]
I0904 12:20:57.995195       1 cache.go:1455] "SnapShot for scheduling" jobNum=0 QueueNum=5 NodeNum=4
I0904 12:20:57.995222       1 cache.go:1458] "HyperNode snapShot for scheduling" tiers={} realNodesSet={} hyperNodesReadyToSchedule=false
I0904 12:20:57.995250       1 session.go:230] Open Session d5b2d3d4-edae-402b-a0cc-a510f5a32729 with <0> Job and <5> Queues
I0904 12:20:57.995271       1 session.go:233] Session d5b2d3d4-edae-402b-a0cc-a510f5a32729 operates with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:20:57.995809       1 sla.go:85] Enter sla plugin ...
I0904 12:20:57.995864       1 sla.go:154] Leaving sla plugin.
I0904 12:20:57.995885       1 overcommit.go:75] Enter overcommit plugin ...
I0904 12:20:57.995916       1 overcommit.go:142] Leaving overcommit plugin.
I0904 12:20:57.995960       1 drf.go:190] Total Allocatable cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00
I0904 12:20:57.996802       1 factory.go:59] Register preBinder predicates successfully
I0904 12:20:57.996925       1 capacity.go:108] The total resource is <cpu 36000.00, memory 42380476416.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00>
E0904 12:20:57.997024       1 capacity.go:612] Failed to check queue's hierarchical structure, error: queue <root> capability <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00> is less than its child queue <parent-a> capability <cpu 36000.00, memory 42380476416.00, hugepages-1Gi 0.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 8000.00, ephemeral-storage 1081101176832000.00>
I0904 12:20:57.997148       1 binpack.go:165] Enter binpack plugin ...
I0904 12:20:57.997184       1 binpack.go:183] resources [] record in weight but not found on any node
I0904 12:20:57.997201       1 binpack.go:167] Leaving binpack plugin. binpack.weight[1], binpack.cpu[1], binpack.memory[1], cpu[1], memory[1] ...
I0904 12:20:57.997218       1 network_topology_aware.go:83] Enter networkTopologyAwarePlugin plugin ...
I0904 12:20:57.997225       1 network_topology_aware.go:85] Leaving networkTopologyAware plugin ...
I0904 12:20:57.997249       1 allocate.go:62] Enter Allocate ...
I0904 12:20:57.997257       1 allocate.go:81] Try to allocate resource to 0 Queues
I0904 12:20:57.997265       1 allocate.go:83] Leaving Allocate ...
I0904 12:20:57.997283       1 backfill.go:59] Enter Backfill ...
I0904 12:20:57.997291       1 backfill.go:110] Leaving Backfill ...
I0904 12:20:57.997303       1 reclaim.go:47] Enter Reclaim ...
I0904 12:20:57.997308       1 reclaim.go:56] There are <0> Jobs and <5> Queues in total for scheduling.
I0904 12:20:57.997317       1 reclaim.go:234] Leaving Reclaim ...
I0904 12:20:57.997327       1 preempt.go:103] Enter Preempt ...
I0904 12:20:57.997340       1 preempt.go:270] Leaving Preempt ...
I0904 12:20:57.997387       1 session.go:289] Queue <q1> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:57.997434       1 session.go:296] Queue <q1> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:57.997441       1 session.go:289] Queue <q2> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:57.997451       1 session.go:296] Queue <q2> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:57.997456       1 session.go:289] Queue <root> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:57.997464       1 session.go:315] ssn.Queues[rootQueue].Queue.Spec.Deserved: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalDeserved: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Spec.Guarantee.Resource: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], totalGuarantee: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}], ssn.Queues[rootQueue].Queue.Status.Allocated: map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}], allocated: map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]
I0904 12:20:57.997485       1 session.go:323] Root queue deserved/guaranteed resource and allocated resource remains the same, no need to update the queue.
I0904 12:20:57.997492       1 session.go:289] Queue <default> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:57.997500       1 session.go:296] Queue <default> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:57.997506       1 session.go:289] Queue <parent-a> allocated resource: <map[cpu:{{0 -3} {<nil>}  DecimalSI} memory:{{0 0} {<nil>}  BinarySI}]>
I0904 12:20:57.997513       1 session.go:296] Queue <parent-a> allocated resource keeps equal, no need to update queue status <map[cpu:{{0 0} {<nil>} 0 DecimalSI} memory:{{0 0} {<nil>} 0 DecimalSI}]>.
I0904 12:20:57.997525       1 session.go:361] Session d5b2d3d4-edae-402b-a0cc-a510f5a32729 operated with TotalResource: <cpu 36000.00, memory 42380476416.00, hugepages-2Mi 0.00, pods 440.00, nvidia.com/A100 6000.00, ephemeral-storage 1081101176832000.00, hugepages-1Gi 0.00>, TotalDeserved: <cpu 0.00, memory 0.00>, TotalGuaranteed: <cpu 0.00, memory 0.00>
I0904 12:20:57.997531       1 session.go:375] Close Session d5b2d3d4-edae-402b-a0cc-a510f5a32729
I0904 12:20:57.997539       1 scheduler.go:133] End scheduling ...
